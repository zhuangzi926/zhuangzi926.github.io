<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>xinlu&#39;s blog</title>
  
  
  <link href="http://xinlu.cool/atom.xml" rel="self"/>
  
  <link href="http://xinlu.cool/"/>
  <updated>2022-04-08T09:34:37.276Z</updated>
  <id>http://xinlu.cool/</id>
  
  <author>
    <name>xinlu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>LXD命令速查表</title>
    <link href="http://xinlu.cool/Manuals/lxd-cheatsheet/"/>
    <id>http://xinlu.cool/Manuals/lxd-cheatsheet/</id>
    <published>2022-04-08T08:59:20.000Z</published>
    <updated>2022-04-08T09:34:37.276Z</updated>
    
    <content type="html"><![CDATA[<p>分门别类地整理了LXD的相关命令，在每种应用场景下给出示例。</p><span id="more"></span><h2 id="一、编辑lxd配置"><a href="#一、编辑lxd配置" class="headerlink" title="一、编辑lxd配置"></a>一、编辑lxd配置</h2><p>根据lxd即插即用的哲学，lxd的配置文件（profile）也是可以自由创建、修改、应用到容器上的。<br>其中default profile不可删除，初始化时即创建。<br>profile可以被用在多个instances上，一个instance也可以使用多个profile。<br>instance上的config会覆盖掉profile。</p><p>以下default profile为例，列举编辑profile的常用命令。<br>格式： </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lxc profile device add &lt;profile&gt; &lt;name&gt; &lt;type&gt; [key=value]...</span><br><span class="line">lxc profile set &lt;profile&gt; &lt;key&gt; &lt;value&gt;</span><br></pre></td></tr></table></figure><p>对应的config格式：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lxc config device add &lt;instance&gt; &lt;name&gt; &lt;type&gt; [key=value]...</span><br><span class="line">lxc config set &lt;instance&gt; &lt;key&gt; &lt;value&gt;</span><br></pre></td></tr></table></figure><p>导出某个profile的所有内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lxc profile show &lt;profile&gt;</span><br></pre></td></tr></table></figure><h3 id="1-配置CPU限制"><a href="#1-配置CPU限制" class="headerlink" title="1. 配置CPU限制"></a>1. 配置CPU限制</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc profile set default limits.cpu 32</span><br></pre></td></tr></table></figure><h3 id="2-配置内存限制"><a href="#2-配置内存限制" class="headerlink" title="2. 配置内存限制"></a>2. 配置内存限制</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc profile set default limits.memory 64GB</span><br></pre></td></tr></table></figure><h3 id="3-限制磁盘使用"><a href="#3-限制磁盘使用" class="headerlink" title="3. 限制磁盘使用"></a>3. 限制磁盘使用</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc storage list</span><br></pre></td></tr></table></figure><p>把容器中的目录mount到存储池上</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc profile device add default root disk pool=[存储池的名字] path=/</span><br></pre></td></tr></table></figure><p>限制根目录大小 &#x3D; 限制磁盘使用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc profile device set default root size 320GB</span><br></pre></td></tr></table></figure><h3 id="4-配置GPU（或者叫挂载GPU）"><a href="#4-配置GPU（或者叫挂载GPU）" class="headerlink" title="4. 配置GPU（或者叫挂载GPU）"></a>4. 配置GPU（或者叫挂载GPU）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc profile device add default gpu gpu</span><br></pre></td></tr></table></figure><h3 id="5-配置共享目录"><a href="#5-配置共享目录" class="headerlink" title="5. 配置共享目录"></a>5. 配置共享目录</h3><p>使容器内的用户具有对共享目录rwx的权限（有点危险）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc profile set default security.privileged true</span><br></pre></td></tr></table></figure><p>在宿主机上创建被共享的文件夹</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir /usr/local/shared-folder</span><br></pre></td></tr></table></figure><p>文件夹映射</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc profile device add default shared-folder \</span><br><span class="line"> disk source=/usr/local/shared-folder path=/usr/local/shared-folder</span><br></pre></td></tr></table></figure><h3 id="6-配置端口映射（只能对单个容器进行配置，不能搞profile）"><a href="#6-配置端口映射（只能对单个容器进行配置，不能搞profile）" class="headerlink" title="6. 配置端口映射（只能对单个容器进行配置，不能搞profile）"></a>6. 配置端口映射（只能对单个容器进行配置，不能搞profile）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc config device add &lt;ContainerName&gt; \ </span><br><span class="line"> port-ssh proxy \ </span><br><span class="line"> listen=tcp:0.0.0.0:20000 \ </span><br><span class="line"> connect=tcp:127.0.0.1:22</span><br></pre></td></tr></table></figure><h3 id="7-限制网络IO"><a href="#7-限制网络IO" class="headerlink" title="7. 限制网络IO"></a>7. 限制网络IO</h3><p>接上网桥</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc profile device add default eth0 \ </span><br><span class="line"> nic name=eth0 nictype=bridged parent=lxdbr0</span><br></pre></td></tr></table></figure><p>限制网络IO带宽</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc profile device set default eth0 \ </span><br><span class="line"> limits.ingress 100Mbit</span><br></pre></td></tr></table></figure><p>限制单个容器的网络IO带宽</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc config device override zhangshenyi eth0 \ </span><br><span class="line"> limits.ingress=1000Mbit</span><br></pre></td></tr></table></figure><p><a href="https://www.maketecheasier.com/limit-lxd-containers-resources/">一篇介绍lxd资源限制的博客</a><br><a href="https://lxd.readthedocs.io/en/latest/instances/">LXD官方文档-实例控制</a></p><h2 id="二、管理LXD镜像"><a href="#二、管理LXD镜像" class="headerlink" title="二、管理LXD镜像"></a>二、管理LXD镜像</h2><h3 id="1-添加清华镜像站点"><a href="#1-添加清华镜像站点" class="headerlink" title="1. 添加清华镜像站点"></a>1. 添加清华镜像站点</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc remote add tuna-images \ </span><br><span class="line"> https://mirrors.tuna.tsinghua.edu.cn/lxc-images/ \</span><br><span class="line"> --protocol=simplestreams --public</span><br></pre></td></tr></table></figure><h3 id="2-查看镜像列表"><a href="#2-查看镜像列表" class="headerlink" title="2. 查看镜像列表"></a>2. 查看镜像列表</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc image list tuna-images:</span><br></pre></td></tr></table></figure><h3 id="3-从镜像创建容器"><a href="#3-从镜像创建容器" class="headerlink" title="3. 从镜像创建容器"></a>3. 从镜像创建容器</h3><p>从清华镜像站点拉取编号为yyyyyyyy的镜像，在本地创建名为xxxxxx的容器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc launch tuna-images:yyyyyyyy xxxxxx</span><br></pre></td></tr></table></figure><h3 id="4-把当前容器打包生成镜像"><a href="#4-把当前容器打包生成镜像" class="headerlink" title="4. 把当前容器打包生成镜像"></a>4. 把当前容器打包生成镜像</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc stop &lt;ContainerName&gt;</span><br><span class="line">sudo lxc publish &lt;ContainerName&gt; --alias &lt;NewImageName&gt; --public</span><br></pre></td></tr></table></figure><h3 id="5-导出镜像到-tar文件"><a href="#5-导出镜像到-tar文件" class="headerlink" title="5. 导出镜像到.tar文件"></a>5. 导出镜像到.tar文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc image export [&lt;remote&gt;:]&lt;ImageName&gt; &lt;TargetFileName&gt;</span><br></pre></td></tr></table></figure><h3 id="6-从-tar文件中导入镜像"><a href="#6-从-tar文件中导入镜像" class="headerlink" title="6. 从.tar文件中导入镜像"></a>6. 从.tar文件中导入镜像</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc image import &lt;Tarball&gt; --alias &lt;NewImageName&gt; --public</span><br></pre></td></tr></table></figure><p><a href="https://manpages.ubuntu.com/manpages/artful/man1/lxc.image.1.html">ubuntu lxc image man page</a></p><h2 id="三、管理LXD容器实例"><a href="#三、管理LXD容器实例" class="headerlink" title="三、管理LXD容器实例"></a>三、管理LXD容器实例</h2><h3 id="1-基本操作"><a href="#1-基本操作" class="headerlink" title="1. 基本操作"></a>1. 基本操作</h3><p>列出所有实例</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc list</span><br></pre></td></tr></table></figure><p>开始&#x2F;停止实例</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc start/stop xxxxxx</span><br></pre></td></tr></table></figure><p>以root进入容器shell界面（从容器中退出只需要输入exit）（ctrl+a q）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc exec xxxxxx -- /bin/bash</span><br></pre></td></tr></table></figure><p>以普通用户进入容器shell界面</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc exec instancename -- su --login username</span><br></pre></td></tr></table></figure><h3 id="2-把现有容器打包成镜像"><a href="#2-把现有容器打包成镜像" class="headerlink" title="2. 把现有容器打包成镜像"></a>2. 把现有容器打包成镜像</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc publish --public &lt;ContainerName&gt; --alias=&lt;ImageName&gt;</span><br></pre></td></tr></table></figure><h2 id="四、lxdui的安装和管理"><a href="#四、lxdui的安装和管理" class="headerlink" title="四、lxdui的安装和管理"></a>四、lxdui的安装和管理</h2><h3 id="1-安装依赖"><a href="#1-安装依赖" class="headerlink" title="1. 安装依赖"></a>1. 安装依赖</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install -y git build-essential libssl-dev python3-venv python3-pip python3-dev zfsutils-linux bridge-utils</span><br><span class="line">sudo snap install lxd</span><br><span class="line">lxd init</span><br></pre></td></tr></table></figure><h3 id="2-拉源码，创建运行环境，跑setup"><a href="#2-拉源码，创建运行环境，跑setup" class="headerlink" title="2. 拉源码，创建运行环境，跑setup"></a>2. 拉源码，创建运行环境，跑setup</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/AdaptiveScale/lxdui.git</span><br><span class="line">cd lxdui</span><br><span class="line">python3 -m venv mytestenv</span><br><span class="line">source mytestenv/bin/activate</span><br><span class="line">python3 setup.py install</span><br></pre></td></tr></table></figure><h3 id="3-开启"><a href="#3-开启" class="headerlink" title="3. 开启"></a>3. 开启</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lxdui start</span><br></pre></td></tr></table></figure><p>访问界面： <a href="http://127.0.0.1:15151/">http://127.0.0.1:15151</a><br>初始登录账号密码： admin | admin</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;分门别类地整理了LXD的相关命令，在每种应用场景下给出示例。&lt;/p&gt;</summary>
    
    
    
    <category term="Manuals" scheme="http://xinlu.cool/categories/Manuals/"/>
    
    
    <category term="LXD" scheme="http://xinlu.cool/tags/LXD/"/>
    
  </entry>
  
  <entry>
    <title>Neural Attention Distillation Erasing Backdoor Triggers from Deep Neural Networks论文摘要</title>
    <link href="http://xinlu.cool/Papers/paper-nad/"/>
    <id>http://xinlu.cool/Papers/paper-nad/</id>
    <published>2021-09-14T02:33:29.000Z</published>
    <updated>2021-09-14T05:10:16.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h2><table><thead><tr><th>会议&#x2F;期刊</th><th>ICLR</th></tr></thead><tbody><tr><td>年份</td><td>2021</td></tr><tr><td>机构</td><td>西安电子科技大学</td></tr><tr><td>一作</td><td>Yige Li</td></tr><tr><td>领域</td><td>AI Security, Backdoor Attack, Backdoor Defense, Knowledge Distillation</td></tr></tbody></table><h2 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h2><p>本文结合注意力蒸馏方法与后门防御策略，提出了一种新的模型后门清除方法<a href="https://openreview.net/forum?id=9l0K4OM-oXE">Neural Attention Distillation（NAD）</a>。NAD仅需5%的训练集数据，先对backdoored model进行fine-tune，得到teacher，然后再把backdoored model当作student，使用注意力蒸馏方法，固定teacher并训练student。NAD能有效清除6种后门攻击的影响（BadNets、Trojan、Blend、CL、SIG、Refool），并能保持模型在正常数据上的准确率受影响较小。实验表明，NAD算法在ASR和ACC上都超过了fine-tune和剪枝。</p><span id="more"></span><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="已有工作"><a href="#已有工作" class="headerlink" title="已有工作"></a>已有工作</h3><p><strong>backdoor attack的背景recap</strong></p><ul><li>经典威胁模型<ul><li>收集到不可信的数据</li><li>下载到不可信的预训练模型</li></ul></li><li>攻击方式分类<ul><li>按是否直接修改label，分为poisoned-label attack和clean-label attack</li></ul></li><li>trigger pattern分类<ul><li>trigger pattern包括pixel、patch、sinusoidal strips、dynamic patterns、natural reflection、human imperceptible noise等等</li></ul></li><li>比较特殊的场景：训练集未知、联邦学习等</li></ul><p><strong>backdoor defense的challenge</strong></p><ul><li>检测后门样本：不可见的or利用reflection的后门样本很难在test阶段被检测到</li><li>重训练&#x2F;剪枝：很难完全清除后门，效果还很局限</li><li>检测trigger：即使还原出trigger，也需要后门清除算法</li></ul><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><h3 id="后门清除效果"><a href="#后门清除效果" class="headerlink" title="后门清除效果"></a>后门清除效果</h3><img src="https://blog-images-1258605293.cos.ap-shanghai.myqcloud.com/img/1631095442909-c2d84148-cc22-4f0a-8fde-03890a7d025d.png" style="zoom:67%;float:center" /><ul><li>Trojan经过NAD后还有19%的攻击成功率，还有提升空间</li><li>NAD对Trojan、Blend、CL这三种攻击方法的效果远远超过其他几种方法</li><li>经过NAD清除后的后门平均保留了7.22%的攻击效果，还有进步空间</li><li>NAD方法的另一大优势是牺牲的ACC指标最小，猜测这应该是KD的功劳，并且也要看KD阶段使用的数据集质量</li><li>MCR对complicated adversarial noises的后门攻击效果不好</li><li>fine-tuning时使用的data augmentation可能起到unlearning的作用</li><li>fine-pruning效果不好，原因可能是WRN-16-1的最后一层神经元数目太少，混杂了benign neurons和backdoored neurons，导致剪枝会影响ACC</li></ul><h3 id="fine-tune和KD阶段使用的数据量的影响"><a href="#fine-tune和KD阶段使用的数据量的影响" class="headerlink" title="fine-tune和KD阶段使用的数据量的影响"></a>fine-tune和KD阶段使用的数据量的影响</h3><img src="https://blog-images-1258605293.cos.ap-shanghai.myqcloud.com/img/1631099766371-ffc8572c-fd6f-411c-b3b8-80895299da3d.png" style="zoom:67%;float:center" /><h3 id="为什么Attention-Map比Feature-Map更好？"><a href="#为什么Attention-Map比Feature-Map更好？" class="headerlink" title="为什么Attention Map比Feature Map更好？"></a>为什么Attention Map比Feature Map更好？</h3><img src="https://blog-images-1258605293.cos.ap-shanghai.myqcloud.com/img/1631099899537-d1ef83af-13fa-467a-bc44-8ffd057991de.png" style="zoom:67%;float:center" /><img src="https://blog-images-1258605293.cos.ap-shanghai.myqcloud.com/img/1631100595186-79d0bfbe-9dc7-49ba-9da5-dd737fcebb9f.png" style="zoom:67%;float:center" /><ul><li>从图3可以看出，后门攻击中，attention map很明显会暴露出trigger region</li><li>从图11可以看出，trigger的信息在activation map中很分散</li><li>如果使用feature map而不是attention map，会导致information loss on the sample density in the space，并且降低了蒸馏效果</li></ul><blockquote><p>Directly aligning the feature maps could lead to an information loss on the sample density in the space, and this could lead to a decrement in the distillation performance (Zagoruyko &amp; Komodakis, 2017; Huang &amp; Wang, 2017; Lopez et al., 2019).</p></blockquote><img src="https://blog-images-1258605293.cos.ap-shanghai.myqcloud.com/img/1631100642522-5d11300a-2cb1-4a41-9a71-982a2a86b230.png" style="zoom:67%;float:center" /><ul><li>NAD方法中，使用attention map效果明显比activation map效果好</li><li>attention map中包含的trigger effect比feature map更加完整</li></ul><blockquote><p>It can thus provide an integrated measure of the overall trigger effect. On the contrary, the trigger effect may be scattered into different channels if we use the raw activation values directly.</p></blockquote><ul><li>attention map regularization的优化比feature map更加简单</li></ul><h3 id="与retrain-based方法对比"><a href="#与retrain-based方法对比" class="headerlink" title="与retrain-based方法对比"></a>与retrain-based方法对比</h3><img src="https://blog-images-1258605293.cos.ap-shanghai.myqcloud.com/img/1631100181700-70996d35-a134-43b1-ad41-aabc00b399a2.png" style="zoom:67%;float:center" /><ul><li>在CL攻击下，NAD方法比retrain-based方法效果更加好</li><li>retrain-based方法对CL攻击效果不好，retrain后ASR仍然有25%、31%，而NAD方法能将ASR降至9%</li><li>在BadNets攻击下，NAD方法与retrain-based方法效果差不多</li></ul><h3 id="使用不同的注意力计算方式对NAD性能的影响"><a href="#使用不同的注意力计算方式对NAD性能的影响" class="headerlink" title="使用不同的注意力计算方式对NAD性能的影响"></a>使用不同的注意力计算方式对NAD性能的影响</h3><img src="https://blog-images-1258605293.cos.ap-shanghai.myqcloud.com/img/1631100406653-c3cdb8d9-083b-4ad9-b033-b2897eeb1e87.png" style="zoom:67%;float:center;" /><p>$$A_{sum}^2$$​ 明显比其他三种更加好。</p><h3 id="防御简单的adaptive-attack"><a href="#防御简单的adaptive-attack" class="headerlink" title="防御简单的adaptive attack"></a>防御简单的adaptive attack</h3><img src="https://blog-images-1258605293.cos.ap-shanghai.myqcloud.com/img/1631100854872-8382094c-323a-4aef-a1f1-ca78d560082d.png" style="zoom:67%;float:center;" /><p>将trigger放在图像中央（CIFAR10数据集中，数据的重要信息一般都在正中间），与图像本身的attention重合，构成简单的adaptive attack。NAD对于这种攻击仍然有防御效果。</p><h3 id="模型架构的影响"><a href="#模型架构的影响" class="headerlink" title="模型架构的影响"></a>模型架构的影响</h3><img src="https://blog-images-1258605293.cos.ap-shanghai.myqcloud.com/img/1631103581047-4432a229-99ae-4474-bce1-0ad5e2ab487d.png" style="zoom:67%;float:center;" /><ul><li>将多种不同架构的teacher train from scratch（只用5%的训练数据），发现NAD对多种架构的WRN网络都适用</li><li>本文只在WRN架构下研究</li></ul><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p><strong>NAD的思想</strong>：使容易被trigger pattern影响的神经元（backdoored neurons）与只对正常representation有反应的神经元（benign neurons）“对齐”。<br>​</p><p><strong>NAD的主要challenge</strong></p><ul><li>如何定义proper attention representations（能区分开backdoored neurons和benign neurons）</li><li>如何定义attention distillation的loss function<br>​</li></ul><p><strong>定义attention map的计算方式</strong></p><img src="https://blog-images-1258605293.cos.ap-shanghai.myqcloud.com/img/1631095099665-6e201098-efd2-4ecd-9cbb-055717873093.png"  /><img src="https://blog-images-1258605293.cos.ap-shanghai.myqcloud.com/img/1631095110534-3c5bced6-4970-4f63-b561-6dff29b9e403.png"  /><p>其中，参数p可以提升backdoored neurons和benign neurons之间的分别，p越大，最大的神经元激活值的权重也就越大。btw，对attention map进行normalization非常重要，对蒸馏效果影响很大。<br>​</p><p><strong>定义注意力蒸馏的loss函数</strong></p><p><img src="https://blog-images-1258605293.cos.ap-shanghai.myqcloud.com/img/1631095299267-17b8d2e1-cfa9-4f81-8357-845162702902.png"></p><img src="https://blog-images-1258605293.cos.ap-shanghai.myqcloud.com/img/1631095310156-f5157a0d-9b12-4b59-a302-7091363c2f8b.png" style="float:center;" /><p>其中，D表示的是防御者拥有的数据集的子集，K表示ResNet中的Residual Group数量。</p><h2 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h2><ul><li>实验部分使用的模型架构单一，仅涉及WRN这一系列模型</li><li>实验效果非常依赖数据增强的tricks</li><li>由于fine-tune和知识蒸馏阶段所使用的训练数据受随机选取影响，复现结果的波动特别大</li></ul>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;基本信息&quot;&gt;&lt;a href=&quot;#基本信息&quot; class=&quot;headerlink&quot; title=&quot;基本信息&quot;&gt;&lt;/a&gt;基本信息&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;会议&amp;#x2F;期刊&lt;/th&gt;
&lt;th&gt;ICLR&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;年份&lt;/td&gt;
&lt;td&gt;2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机构&lt;/td&gt;
&lt;td&gt;西安电子科技大学&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;一作&lt;/td&gt;
&lt;td&gt;Yige Li&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;领域&lt;/td&gt;
&lt;td&gt;AI Security, Backdoor Attack, Backdoor Defense, Knowledge Distillation&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&quot;主要贡献&quot;&gt;&lt;a href=&quot;#主要贡献&quot; class=&quot;headerlink&quot; title=&quot;主要贡献&quot;&gt;&lt;/a&gt;主要贡献&lt;/h2&gt;&lt;p&gt;本文结合注意力蒸馏方法与后门防御策略，提出了一种新的模型后门清除方法&lt;a href=&quot;https://openreview.net/forum?id=9l0K4OM-oXE&quot;&gt;Neural Attention Distillation（NAD）&lt;/a&gt;。NAD仅需5%的训练集数据，先对backdoored model进行fine-tune，得到teacher，然后再把backdoored model当作student，使用注意力蒸馏方法，固定teacher并训练student。NAD能有效清除6种后门攻击的影响（BadNets、Trojan、Blend、CL、SIG、Refool），并能保持模型在正常数据上的准确率受影响较小。实验表明，NAD算法在ASR和ACC上都超过了fine-tune和剪枝。&lt;/p&gt;</summary>
    
    
    
    <category term="Papers" scheme="http://xinlu.cool/categories/Papers/"/>
    
    
    <category term="Machine Learning" scheme="http://xinlu.cool/tags/Machine-Learning/"/>
    
    <category term="Knowledge Distillation" scheme="http://xinlu.cool/tags/Knowledge-Distillation/"/>
    
    <category term="Backdoor Attacks" scheme="http://xinlu.cool/tags/Backdoor-Attacks/"/>
    
    <category term="Backdoor Mitigation" scheme="http://xinlu.cool/tags/Backdoor-Mitigation/"/>
    
  </entry>
  
  <entry>
    <title>SoK：The Faults in our ASRs论文摘要</title>
    <link href="http://xinlu.cool/Papers/paper-sok-faults-in-our-asrs/"/>
    <id>http://xinlu.cool/Papers/paper-sok-faults-in-our-asrs/</id>
    <published>2021-07-17T09:06:07.000Z</published>
    <updated>2021-07-17T09:09:41.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h2><table><thead><tr><th>会议&#x2F;期刊</th><th>S&amp;P</th></tr></thead><tbody><tr><td>年份</td><td>2021</td></tr><tr><td>机构</td><td>University of Florida</td></tr><tr><td>一作</td><td>Hadi Abdullah</td></tr><tr><td>领域</td><td>Speech Recognition, Speaker Recognition, Audio Adversarial Example</td></tr></tbody></table><h2 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h2><p><a href="https://arxiv.org/abs/2007.06622">本综述</a>将语音识别（Speech Recognition）和说话人识别（Speaker Identification）统称为Voice Processing Systems（VPS）。该综述对VSP的威胁模型进行分类，按分类整理了现有工作，经过大量测试证明，目前还无法实现恶意输入在VPS之间的迁移性。</p><span id="more"></span><h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h2><p><strong>ASR的典型应用场景有哪些？</strong></p><ul><li>个人助手（personal assistant，Google Home，Amazon Alexa，Siri）</li><li>电话监听系统（telephony surveillance systems）</li><li>会议转录服务（conferencing transcription services）</li></ul><p><strong>现代ASR系统的识别流程？</strong></p><ul><li>使用麦克风录下音频</li><li>预处理<ul><li>人声检测+去噪+低通滤波</li></ul></li><li>特征提取，例如MFCC</li><li>模型推理</li><li>对模型输出进行解码，得到文本</li></ul><p><strong>图像攻击方法无法在语音领域应用的原因有哪些？</strong></p><ul><li>ASR使用的预处理过程比图像复杂，主要使用了人类专家硬编码的信号处理算法，攻击者甚至可以利用预处理与人耳听觉的不一致，直接攻击预处理步骤，实现模型无关攻击</li><li>ASR使用序列模型来预测，预测结果与所有时间维度上的输入都有关，让攻击者必须考虑所有维度上的输入，攻击更加困难，基于梯度的攻击可能面临梯度消失或梯度爆炸问题</li><li>ASR的输出是文本，文本是离散数据，难以优化，图像分类模型可以使用gradient masking方法来防御，然而ASR使用的不可微分方法如beam search让此类防御不可行<ul><li>个人认为，文本的数据域非常庞大（取决于使用的词典大小）也是攻击难的一大原因</li></ul></li></ul><p><strong>对攻击者掌握的知识进行分类？</strong><br>将ASR有关的知识分成五个主要部分：任务、预处理、特征提取、模型推理、解码。</p><ul><li>white-box：攻击者知道所有部分的所有信息</li><li>grey-box：攻击者只知道一部分信息</li><li>black-box：攻击者只知道任务，例如知道英文语音识别任务，就可以知道模型在大规模英语语料数据集上训练过</li><li>no-box：攻击者不知道任何信息，例如，攻击电话监听系统时，攻击者甚至不知道ASR的具体任务是什么</li></ul><p><strong>语音对抗样本的传播媒介有哪些？</strong></p><ul><li>over-line：直接通过.wav文件传输，无损</li><li>over-air：空气传播，先录制后播放，考虑信号衰减和输入输出设备导致的损失</li><li>over-telephony-network：电话网络上传播，考虑编码、压缩、丢包导致的损失</li><li>over-others：例如.mp3压缩导致的损失</li></ul><p><strong>语音对抗样本对人耳听觉的影响有哪些？</strong></p><ul><li>inaudible：人耳听觉范围为20Hz-20kHz，超声波攻击（20kHz-10MHz）可以被硬件接收而人耳无感，硬件接收后会降采样到固定频率，所以软件方法无法检测超声波攻击</li><li>noisey：人耳听起来像噪声</li><li>clean：此类攻击将对抗扰动作为low-intensity perturbation嵌入原音频（例如一段音乐）当中，人耳察觉不到异常</li></ul><p><strong>关于迁移性</strong></p><ul><li>本文认为，语音对抗样本在不同模型间不具有迁移性，即使使用相同架构、相同训练集、相同参数训练出的模型也不具有迁移性。原因在于训练阶段GPU引入了不确定性</li><li>Commander Song将Kaldi上生成的对抗样本成功迁移到iFlytek上，这可能是因为iFlytek在预训练的Kaldi模型基础上fine-tune。语音对抗样本对fine-tune后的模型可能具有迁移性</li><li>作者使用不同随机数种子训练了8个一样的DeepSpeech ASR，在1个DeepSpeech ASR上使用C&amp;W&#x2F;PGD生成10000+个对抗音频，都无法迁移到另外7个DeepSpeech ASR上；而使用相同随机数种子后，还是不具有迁移性；这说明GPU引入的不确定机制导致了模型的不同，也表明语音对抗样本不具有迁移性（至少在DeepSpeech上）</li></ul>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;基本信息&quot;&gt;&lt;a href=&quot;#基本信息&quot; class=&quot;headerlink&quot; title=&quot;基本信息&quot;&gt;&lt;/a&gt;基本信息&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;会议&amp;#x2F;期刊&lt;/th&gt;
&lt;th&gt;S&amp;amp;P&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;年份&lt;/td&gt;
&lt;td&gt;2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机构&lt;/td&gt;
&lt;td&gt;University of Florida&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;一作&lt;/td&gt;
&lt;td&gt;Hadi Abdullah&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;领域&lt;/td&gt;
&lt;td&gt;Speech Recognition, Speaker Recognition, Audio Adversarial Example&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&quot;主要贡献&quot;&gt;&lt;a href=&quot;#主要贡献&quot; class=&quot;headerlink&quot; title=&quot;主要贡献&quot;&gt;&lt;/a&gt;主要贡献&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2007.06622&quot;&gt;本综述&lt;/a&gt;将语音识别（Speech Recognition）和说话人识别（Speaker Identification）统称为Voice Processing Systems（VPS）。该综述对VSP的威胁模型进行分类，按分类整理了现有工作，经过大量测试证明，目前还无法实现恶意输入在VPS之间的迁移性。&lt;/p&gt;</summary>
    
    
    
    <category term="Papers" scheme="http://xinlu.cool/categories/Papers/"/>
    
    
    <category term="Machine Learning" scheme="http://xinlu.cool/tags/Machine-Learning/"/>
    
    <category term="Adversarial Example" scheme="http://xinlu.cool/tags/Adversarial-Example/"/>
    
    <category term="Audio Adversarial Example" scheme="http://xinlu.cool/tags/Audio-Adversarial-Example/"/>
    
    <category term="Survey" scheme="http://xinlu.cool/tags/Survey/"/>
    
    <category term="ASR" scheme="http://xinlu.cool/tags/ASR/"/>
    
  </entry>
  
  <entry>
    <title>Exploring Targeted Universal Adversarial Perturbations to End-to-end ASR Models论文摘要</title>
    <link href="http://xinlu.cool/Papers/paper-targeted-universal-ae-e2e-asr/"/>
    <id>http://xinlu.cool/Papers/paper-targeted-universal-ae-e2e-asr/</id>
    <published>2021-07-08T06:18:41.000Z</published>
    <updated>2021-07-08T06:28:25.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h2><table><thead><tr><th>会议&#x2F;期刊</th><th>arxiv</th></tr></thead><tbody><tr><td>年份</td><td>2021</td></tr><tr><td>机构</td><td>Google</td></tr><tr><td>一作</td><td>Zhiyun Lu</td></tr><tr><td>领域</td><td>Audio Adversarial Example, Universal Adversarial Example, End-to-end ASR</td></tr></tbody></table><h2 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h2><p><a href="https://arxiv.org/abs/2104.02757">这篇文章</a>主要探索不同端到端模型架构对通用语音对抗样本的影响。在三种不同架构的e2e ASR上（CTC、Attention、RNN-T）训练universal perturbation，评估三种模型的鲁棒性。</p><p>提出了一种新的攻击思路，prepending attack，在对抗语音前追加对抗噪声，而不改变原语音。由于e2e模型具有良好的推理能力（尤其是LAS模型），因此很容易受这种攻击影响。</p><p>发现了Attention机制是鲁棒性低的原因，在对抗攻击场景下，Attention模型容易只考虑少数注入了对抗噪声的frame，而忽略掉其他部分。</p><p>发现CTC模型对universal perturbation非常鲁棒。Targeted universal attacks exist for both LAS and RNN-T, but not for CTC models.</p><span id="more"></span><h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h2><p><strong>为什么语音对抗样本比图像难？</strong>因为语音识别是序列识别（sequential predictions）。举例，语音untarget攻击会导致很高的WER，让用户发现大量与真实结果无关的识别文本，而图像untargeted攻击只会造成一次误分类。</p><p><strong>什么是universal perturbation？</strong>一个从训练集中学习得到的扰动向量，可以泛化（到其他数据），以高概率使任意音频被误识别。</p><p><strong>扰动的分类。</strong>将扰动分为additive和prepending（在头部追加）。additive攻击ASR的additive stability，prepending攻击ASR的causal stability。</p><p><strong>Additive Attack的结论：</strong></p><ul><li><strong>LAS模型特别容易受到攻击。</strong>在LAS上的对抗扰动使模型只关注某几个特定frame，而忽略其他frame，导致错误识别。Attention机制是LAS模型易受攻击的根源。</li><li><strong>CTC和RNN-T模型难以被攻击。</strong>只使用固定长度的扰动，很难生成任意长度的识别文本。</li></ul><p><strong>Prepending Attack的结论：</strong></p><ul><li><strong>LAS模型特别容易受到攻击。</strong>LAS模型上训练得到的扰动非常小（~-30dB），成功率接近100%。</li><li><strong>RNN-T模型更容易被prepending attack攻击。</strong>在prepending attack下，RNN-T模型上得到的扰动更小，攻击成功率更高。实验表明，对additive attack，音频长度超过4秒（刚好是扰动的长度）后，攻击成功率大幅下降，而对prepending attack，音频长度与攻击成功率之间关联性较弱。</li><li><strong>文本对实验结果的影响。</strong>观察结论表明，目标识别文本越短、词汇使用频率越高，攻击就越容易成功。</li></ul><p><strong>只使用一句话训练universal perturbation，效果不好。</strong>使用Librispeech中的一句话训练的对抗扰动平均成功率仅为0.7%（test-clean）、2.7%（test-other）。</p><p><strong>max-norm约束越强，成功率越低。</strong>无max-norm约束，，RNN-T上prepending attack成功率为<del>40%，4000时为</del>30%，2000时为~3%。</p><p><strong>untargeted universal attack比较容易，但还是会保留一定的正常文本。</strong>三种模型被攻击后的WER分别为LAS 76.0&#x2F;100.5、RNN-T 87.5&#x2F;100.6、CTC 106.1&#x2F;121.2。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;基本信息&quot;&gt;&lt;a href=&quot;#基本信息&quot; class=&quot;headerlink&quot; title=&quot;基本信息&quot;&gt;&lt;/a&gt;基本信息&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;会议&amp;#x2F;期刊&lt;/th&gt;
&lt;th&gt;arxiv&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;年份&lt;/td&gt;
&lt;td&gt;2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机构&lt;/td&gt;
&lt;td&gt;Google&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;一作&lt;/td&gt;
&lt;td&gt;Zhiyun Lu&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;领域&lt;/td&gt;
&lt;td&gt;Audio Adversarial Example, Universal Adversarial Example, End-to-end ASR&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&quot;主要贡献&quot;&gt;&lt;a href=&quot;#主要贡献&quot; class=&quot;headerlink&quot; title=&quot;主要贡献&quot;&gt;&lt;/a&gt;主要贡献&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2104.02757&quot;&gt;这篇文章&lt;/a&gt;主要探索不同端到端模型架构对通用语音对抗样本的影响。在三种不同架构的e2e ASR上（CTC、Attention、RNN-T）训练universal perturbation，评估三种模型的鲁棒性。&lt;/p&gt;
&lt;p&gt;提出了一种新的攻击思路，prepending attack，在对抗语音前追加对抗噪声，而不改变原语音。由于e2e模型具有良好的推理能力（尤其是LAS模型），因此很容易受这种攻击影响。&lt;/p&gt;
&lt;p&gt;发现了Attention机制是鲁棒性低的原因，在对抗攻击场景下，Attention模型容易只考虑少数注入了对抗噪声的frame，而忽略掉其他部分。&lt;/p&gt;
&lt;p&gt;发现CTC模型对universal perturbation非常鲁棒。Targeted universal attacks exist for both LAS and RNN-T, but not for CTC models.&lt;/p&gt;</summary>
    
    
    
    <category term="Papers" scheme="http://xinlu.cool/categories/Papers/"/>
    
    
    <category term="Machine Learning" scheme="http://xinlu.cool/tags/Machine-Learning/"/>
    
    <category term="Adversarial Example" scheme="http://xinlu.cool/tags/Adversarial-Example/"/>
    
    <category term="Audio Adversarial Example" scheme="http://xinlu.cool/tags/Audio-Adversarial-Example/"/>
    
    <category term="White-box Attack" scheme="http://xinlu.cool/tags/White-box-Attack/"/>
    
    <category term="End-to-end ASR" scheme="http://xinlu.cool/tags/End-to-end-ASR/"/>
    
  </entry>
  
  <entry>
    <title>Generating Robust Audio Adversarial Examples with Temporal Dependency论文摘要</title>
    <link href="http://xinlu.cool/Papers/paper-ipc/"/>
    <id>http://xinlu.cool/Papers/paper-ipc/</id>
    <published>2021-05-05T06:34:15.000Z</published>
    <updated>2021-07-08T06:23:53.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h1><table><thead><tr><th>会议&#x2F;期刊</th><th>IJCAI</th></tr></thead><tbody><tr><td>年份</td><td>2020</td></tr><tr><td>机构</td><td>华中科技大学</td></tr><tr><td>一作</td><td>Hongting Zhang</td></tr><tr><td>领域</td><td>Audio Adversarial Attack，Speech Recognition，White-box Attack</td></tr></tbody></table><h2 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h2><p>本文提出了一种新型白盒语音对抗攻击算法<a href="https://www.ijcai.org/proceedings/2020/438">Iterative Proportional Clipping（IPC）</a>，成功攻击了基于CNN的wav2letter++语音识别系统。该算法生成的对抗样本仍然保持了temporal dependency性质，temporal dependency based defense无法检测IPC算法生成的对抗样本。</p><p>本文提出了两种进一步优化对抗样本的方法，分别将对抗噪声隐藏到high-intensity和high-frequency band上，人耳实验表明两种优化方法确实提高了人耳隐蔽性。</p><span id="more"></span><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="早期工作"><a href="#早期工作" class="headerlink" title="早期工作"></a>早期工作</h3><p>白盒语音对抗攻击算法在技术上已经成熟，但还面临难以解决的不足之处：</p><ul><li>在音频的<strong>静音部分&#x2F;low-intensity部分</strong>引入了噪音，容易被人耳察觉</li><li>在音频的<strong>低频部分（300~3400Hz）</strong>部分引入了噪音，非常容易被人耳感知，这也是人说话声音的主要频带</li><li>破坏了正常音频的<strong>temporal dependency</strong>性质，容易被检测</li></ul><p>IPC算法并没有提出重大的技术创新，而只是从temporal dependency这个侧面着手，破解了基于TD的防御手段，让生成的音频仍保持了TD性质。</p><p>早期工作中，生成对抗音频所需时间较长（小时级），而IPC算法只需要3~15分钟就能生成一条对抗音频。</p><h3 id="灵感来源"><a href="#灵感来源" class="headerlink" title="灵感来源"></a>灵感来源</h3><p>在对抗样本的生成过程中，往往施加的扰动越大，攻击成功率就越高，但音频质量会变得越低。之前的方法都会将扰动限制在<strong>固定的范围</strong>内，但音频质量仍然很糟糕。IPC算法认为生成对抗样本的优化过程应该是个data-related optimization，所以限制的不是扰动的绝对值，而是扰动&#x2F;原语音信号的比例。<strong>按固定比例限制扰动大小</strong>的方法保持了音频的TD性质。</p><h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2><p>这篇文章之前<a href="https://openreview.net/forum?id=HJgFW6EKvH">被ICLR拒了</a>，拒稿理由合情合理。</p><h2 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h2><h3 id="白盒优化目标函数"><a href="#白盒优化目标函数" class="headerlink" title="白盒优化目标函数"></a>白盒优化目标函数</h3><p>$$\begin{array}{l}<br>\text { minimize } \lambda_{1} \cdot \operatorname{Loss}(f(\phi(x+\delta)), t)+\lambda_{2}|\delta|<em>{2}^{2} \<br>\text { s.t. }\left|\frac{\delta</em>{i}}{x_{i}}\right|&lt;B, i \in[n]<br>\end{array}$$<br>其中，常数B限制了每个扰动与原信号的比例上界。如果B增大，噪声的L2 norm增大，优化所需的epoch减小。</p><p>IPC算法只要求使用的语音预处理方法是可微分、可逆向的，例如 <code>torch.fft</code> 和 <code>torch.rfft</code> 。本文在实验部分把wav2letter++用pytorch重写了一遍。</p><h3 id="关于Temporal-Dependency"><a href="#关于Temporal-Dependency" class="headerlink" title="关于Temporal Dependency"></a>关于Temporal Dependency</h3><ul><li>TD包含了temporal closeness，period，trend这三个方面</li><li>cross-correlation coefficient指标可以用来衡量TD</li><li>基于TD的防御手段：把对抗音频按不同比例切割，切割后的音频仍然能被识别成目标文本的一部分，就是正常音频，反之就很有可能是对抗音频<ul><li>IPC算法得到的对抗音频被切割后，得到的部分音频的WER和CER低于Opt方法</li><li>这说明IPC攻击对temporal dependency based defense鲁棒</li></ul></li></ul><h3 id="增强人耳隐蔽性"><a href="#增强人耳隐蔽性" class="headerlink" title="增强人耳隐蔽性"></a>增强人耳隐蔽性</h3><p>本文增加隐蔽性的方法比较简单直接。</p><ul><li>先将音频切分成high-intensity部分和low- intensity部分，然后只对high-intensity部分进行IPC攻击，之后再拼接起来<ul><li>疑问：为什么这种剪拼操作没有破坏temporal dependency？</li></ul></li><li>梯度方向传播时，冻结3500<del>8000Hz以外的频段，梯度只在3500</del>8000Hz内反向传播（只需要修改预处理步骤中的梯度反向传播逻辑即可）</li><li>本文的人耳实验比较粗糙，只选择了20个志愿者做调研，但和其他方法的对比效果显著</li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;基本信息&quot;&gt;&lt;a href=&quot;#基本信息&quot; class=&quot;headerlink&quot; title=&quot;基本信息&quot;&gt;&lt;/a&gt;基本信息&lt;/h1&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;会议&amp;#x2F;期刊&lt;/th&gt;
&lt;th&gt;IJCAI&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;年份&lt;/td&gt;
&lt;td&gt;2020&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机构&lt;/td&gt;
&lt;td&gt;华中科技大学&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;一作&lt;/td&gt;
&lt;td&gt;Hongting Zhang&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;领域&lt;/td&gt;
&lt;td&gt;Audio Adversarial Attack，Speech Recognition，White-box Attack&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&quot;主要贡献&quot;&gt;&lt;a href=&quot;#主要贡献&quot; class=&quot;headerlink&quot; title=&quot;主要贡献&quot;&gt;&lt;/a&gt;主要贡献&lt;/h2&gt;&lt;p&gt;本文提出了一种新型白盒语音对抗攻击算法&lt;a href=&quot;https://www.ijcai.org/proceedings/2020/438&quot;&gt;Iterative Proportional Clipping（IPC）&lt;/a&gt;，成功攻击了基于CNN的wav2letter++语音识别系统。该算法生成的对抗样本仍然保持了temporal dependency性质，temporal dependency based defense无法检测IPC算法生成的对抗样本。&lt;/p&gt;
&lt;p&gt;本文提出了两种进一步优化对抗样本的方法，分别将对抗噪声隐藏到high-intensity和high-frequency band上，人耳实验表明两种优化方法确实提高了人耳隐蔽性。&lt;/p&gt;</summary>
    
    
    
    <category term="Papers" scheme="http://xinlu.cool/categories/Papers/"/>
    
    
    <category term="Machine Learning" scheme="http://xinlu.cool/tags/Machine-Learning/"/>
    
    <category term="Adversarial Example" scheme="http://xinlu.cool/tags/Adversarial-Example/"/>
    
    <category term="Audio Adversarial Example" scheme="http://xinlu.cool/tags/Audio-Adversarial-Example/"/>
    
    <category term="White-box Attack" scheme="http://xinlu.cool/tags/White-box-Attack/"/>
    
  </entry>
  
  <entry>
    <title>zkLedger Privacy-Preserving Auditing for Distributed Ledger论文摘要</title>
    <link href="http://xinlu.cool/Papers/paper-zkledger/"/>
    <id>http://xinlu.cool/Papers/paper-zkledger/</id>
    <published>2021-04-25T03:37:21.000Z</published>
    <updated>2021-04-25T03:51:26.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h2><table><thead><tr><th>会议&#x2F;期刊</th><th>NSDI</th></tr></thead><tbody><tr><td>年份</td><td>2018</td></tr><tr><td>机构</td><td>MIT Media Lab</td></tr><tr><td>一作</td><td>Neha Narula</td></tr><tr><td>领域</td><td>Blockchain，Zero Knowledge Proof，Auditing</td></tr></tbody></table><h2 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h2><p>本文提出了一种<a href="https://www.usenix.org/conference/nsdi18/presentation/narula">支持对链上密文数据进行实时审计的区块链系统zkledger</a>。zkledger上记录着多个银行间进行场外交易的交易记录，链上记录的交易内容是加密的。通过zkledger提出的审计协议，审计方可以实时地对任意银行进行质询，以验证银行间的交易行为符合监管当局的规定和法律要求。zkledger的证明机制确保银行无法向审计方撒谎，也无法合谋转移资产。</p><span id="more"></span><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="为什么要用区块链平台做审计？"><a href="#为什么要用区块链平台做审计？" class="headerlink" title="为什么要用区块链平台做审计？"></a>为什么要用区块链平台做审计？</h3><p>传统审计方式的缺点：</p><ul><li>劳累、耗时，而且监管方没有办法实时地获取信息</li><li>审计方可能出错，造成巨大损失</li></ul><p>区块链审计的优点：</p><ul><li>减少验证（审计方的人力消耗）和协调（审计方和被审计方的交互）的开销</li><li>支持实时验证</li><li>区块链本身的优势：避免单点故障、匿名性、不可伪造、不可抵赖……</li></ul><h3 id="已有的区块链平台做审计有哪些缺陷？"><a href="#已有的区块链平台做审计有哪些缺陷？" class="headerlink" title="已有的区块链平台做审计有哪些缺陷？"></a>已有的区块链平台做审计有哪些缺陷？</h3><p>早期工作（不支持加密数据的区块链审计系统）的缺点：</p><ul><li>可能暴露交易方的关系</li><li>缺乏对隐私信息（GDPR规定的隐私信息、知识产权等）的保护</li></ul><p>支持加密数据的区块链审计方法：</p><ul><li>要么只用区块链记录交易的hash，而导致无法对链上数据进行审计</li><li>要么在链上记录加密数据，但可能暴露交易图，被攻击后可能被注入恶意交易记录</li><li>以上两种方法都不支持实时审计</li></ul><h2 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h2><h3 id="平台"><a href="#平台" class="headerlink" title="平台"></a>平台</h3><p>本文认为，审计本身的作用是，引入被信任的第三方来证明自己的行为合法合规。因此，zkledger假设该区块链平台可以运行在某个受信任的第三方上，节点之间的通信或与外部的通信在点对点加密信道上完成。</p><p>zkledger假设系统的参与方既包括投资银行Bank1，Bank2，Bank3，…，Bankn，又包括审计方Auditor。其中，Auditor的角色是不定的，Bank也可以承担Auditor的职责。系统内的节点允许动态地增加&#x2F;减少。</p><p>zkledger的Bank参与方允许向区块链平台发起交易，Auditor参与方允许对其他Bank发起质询，并将质询结果与链上数据对比，确保Bank没有撒谎。另外，zkledger还允许外部用户Depositor从Bank中取钱&#x2F;向Bank中存钱，而内部的参与方却不能修改某项资产的总量（没有外部输入输出的情况下，内部资产既不能凭空增加，也不能凭空消失）。</p><h3 id="交易"><a href="#交易" class="headerlink" title="交易"></a>交易</h3><p>在审计业务中，区块链作为交易数据的分布式账本，应该记录的是资产法定保管权的变更，而不是所有权的变更。</p><p><strong>一条zkledger的交易表示为：Banki向Bankj转移v股t资产。</strong>而在zkledger链上记录的交易信息里，交易的参与方和资产数量是隐藏的，而交易发生的时间和资产类型是公开的。另外，交易的拓扑顺序也是隐藏的。</p><p>zkledger使用<strong>Pedersen Commitments</strong>来对交易的资产数量进行加密。Pedersen Commitments满足additively comitment的性质。大概可以表示为，对资产数量v（非负整数）和随机数r，用以下方式加密：</p><p>$$cm :&#x3D; COMM(v, r) &#x3D; g^v h^r$$</p><p>zkledger中所有的交易记录合在一起，可以看做是以交易为行，以Bank为列的表，这种设计下，在表中查询某Bank的资产持有量会非常方便（相比比特币采用的UTXO机制，zkledger的方法更加适合审计场景）。</p><p>虽然每笔交易一般只与两个Bank有关（spender Bank和receive Bank，其中spender Bank负责向区块链发起交易），但在每个zkledger的交易行中，会包含所有Bank的entry和所有Bank的证明信息（因为不能暴露交易的参与方）。</p><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><p>当交易由某个Bank发起并对外广播后，其他节点需要验证交易的合法性和准确性，通过验证的交易才能被加到链上。</p><p><strong>Proof of Balance</strong>：由于交易不能创建新的资产、也不能销毁现有的资产，因此节点需要验证交易内的总资产变化之和为0。</p><p><strong>Proof of Assets</strong>：交易的spender Bank手中已有的资产必须要&gt;&#x3D;此次交易所花费的资产，这一操作可以通过遍历spender Bank的column里所有对应资产之和来计算出spender Bank账上的资产余额。</p><p><strong>Range Proof</strong>：交易的资产数量要比密码体制规定的取模运算的底数小，防止恶意节点利用计算溢出导致资产的总量发生变化。</p><h3 id="审计"><a href="#审计" class="headerlink" title="审计"></a>审计</h3><p>审计行为和交易的广播、验证行为都涉及节点之间的交互，为了节省交互行为的开销，zkledger采用了<strong>Non-interactive Zero-knowledge Proof（NIZK）</strong>技术，在每笔交易行中的每个entry上加入多个proof来保证交易的准确性和完整性。</p><p>在zkledger上，审计协议可以保证Bank无法向Auditor隐藏已有的交易记录，因为Auditor可以访问table中Bank对应的整个列。而且Bank之间难以做到合谋，因为Auditor可以检查过去任意时刻的记录，而合谋掩盖资产转移的行为也只能掩盖一时。</p><p><strong>审计在数学上可以被归纳为，对某项资产数据进行求和、滑动平均、方差、标准差、比例等运算。</strong>zkledger采用的Pedersen Commitments天然支持加减法运算。每种审计操作可以看做是多个加减法运算通过乘除组合在一起。其中，加减法运算在链上，由Auditor和Bank之间的交互来完成，并且与链上数据对比来验证，而乘除运算由Auditor在本地完成。（这一段是我在强行解释，目前还完全不懂零知识证明orz）</p><p><strong>Token机制</strong>：由于记账操作只需要spender来完成，因此可能有恶意的spender在未告知receiver的情况下进行交易，从而导致receiver的本地数据与链上数据不一致。为防止这种情况，zkledger要求spender在交易中，为每个Bank对应的entry都增加一个公共可见的token，这样的话其他bank就可以通过该token来核查自己在交易后的资产变化&#x2F;资产总量。</p><p><strong>Proof of Consistency</strong>：审计行为需要Auditor和Bank之间的交互，而Bank并不想让Auditor知道自己每笔交易的资产转移数目的细节，只想让Auditor知道最后运算得到的结果（可以理解为，如果Auditor向知道sum&#x3D;v1+v2+v3+…+vn，但是Bank只会帮Auditor算好sum，并不想让Auditor知道v1、v2、v3…的具体值）。为了达到这个目的，bank就不能把它所使用的随机数r告诉Auditor，而只会把自己过去每笔相关交易所使用的随机数r的和暴露给Auditor，因此在每个Bank的entry中的token项会被利用起来，token中蕴含了随机数的和的相关性质。为了防止恶意节点伪造这个信息，还需要在entry中引入一个新的证明，证明token中蕴含的随机数和之前使用过的随机数是一致的。</p><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p>为了提高审计过程的效率，zkledger为每个节点都设计了cache，cache中存储了节点所属的Bank当前的资产余额信息，以及Bank参与的交易信息。当Auditor向Bank发起质询时，Bank可以利用cache快速回答。</p><p>zkledger在工程实现上还引入了Map-Reduce的方法。因为Auditor可能想知道Bank平均每笔交易的信息，而Bank无法直接证明是否具体参与了某项交易。因此，审计过程被分成map和reduce两阶段。以下假设Auditor想知道Bank参与的交易总数。</p><p><strong>map阶段</strong>：Bank对自己是否参与某笔交易做出NIZK证明。</p><p><strong>reduce阶段</strong>：Bank在本地计算出NIZK证明的同态加密之和，并且只公开该证明内蕴含的交易总数信息。</p><p>之后，Bank将参与的交易信息、NIZK证明、参与交易的数目和随机数r发送给Auditor，Auditor负责与链上数据对比，验证准确性。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;基本信息&quot;&gt;&lt;a href=&quot;#基本信息&quot; class=&quot;headerlink&quot; title=&quot;基本信息&quot;&gt;&lt;/a&gt;基本信息&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;会议&amp;#x2F;期刊&lt;/th&gt;
&lt;th&gt;NSDI&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;年份&lt;/td&gt;
&lt;td&gt;2018&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机构&lt;/td&gt;
&lt;td&gt;MIT Media Lab&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;一作&lt;/td&gt;
&lt;td&gt;Neha Narula&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;领域&lt;/td&gt;
&lt;td&gt;Blockchain，Zero Knowledge Proof，Auditing&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&quot;主要贡献&quot;&gt;&lt;a href=&quot;#主要贡献&quot; class=&quot;headerlink&quot; title=&quot;主要贡献&quot;&gt;&lt;/a&gt;主要贡献&lt;/h2&gt;&lt;p&gt;本文提出了一种&lt;a href=&quot;https://www.usenix.org/conference/nsdi18/presentation/narula&quot;&gt;支持对链上密文数据进行实时审计的区块链系统zkledger&lt;/a&gt;。zkledger上记录着多个银行间进行场外交易的交易记录，链上记录的交易内容是加密的。通过zkledger提出的审计协议，审计方可以实时地对任意银行进行质询，以验证银行间的交易行为符合监管当局的规定和法律要求。zkledger的证明机制确保银行无法向审计方撒谎，也无法合谋转移资产。&lt;/p&gt;</summary>
    
    
    
    <category term="Papers" scheme="http://xinlu.cool/categories/Papers/"/>
    
    
    <category term="Blockchain" scheme="http://xinlu.cool/tags/Blockchain/"/>
    
    <category term="Auditing" scheme="http://xinlu.cool/tags/Auditing/"/>
    
    <category term="Zero-knowledge Proof" scheme="http://xinlu.cool/tags/Zero-knowledge-Proof/"/>
    
  </entry>
  
  <entry>
    <title>A Geometry-Inspired Decision-Based Attack论文摘要</title>
    <link href="http://xinlu.cool/Papers/paper-qfool-attack/"/>
    <id>http://xinlu.cool/Papers/paper-qfool-attack/</id>
    <published>2021-03-24T05:57:05.000Z</published>
    <updated>2021-03-24T06:04:18.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h2><table><thead><tr><th><strong>会议&#x2F;期刊</strong></th><th>ICCV</th></tr></thead><tbody><tr><td><strong>年份</strong></td><td>2019</td></tr><tr><td><strong>机构</strong></td><td>EPFL</td></tr><tr><td><strong>一作</strong></td><td>Yujia Liu</td></tr><tr><td><strong>领域</strong></td><td>Adversarial Example, Decision-based Black-box Attack</td></tr></tbody></table><h2 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h2><p>本文提出了一种新型<a href="https://arxiv.org/abs/1903.10826">黑盒对抗样本生成算法qFool</a>。该算法不依赖模型输出的概率分布，仅<strong>利用Top-1预测结果</strong>就能构造出对抗样本。qFool算法的特点是<strong>查询次数较少</strong>，其变种qFool-subspace算法还能<strong>将对抗样本限制在输入的低频子空间中</strong>，在<strong>计算上更加高效</strong>。</p><span id="more"></span><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="早期工作"><a href="#早期工作" class="headerlink" title="早期工作"></a>早期工作</h3><p>对抗样本攻击算法根据攻击设定可分为白盒与黑盒两种。黑盒攻击假设攻击者不知道模型的内部细节（架构、参数、损失、梯度…），仅仅知道模型的输出结果。黑盒攻击又可以细分为Score-based和Decision-based。Scored-based攻击假设攻击者能知道模型输出的各类别概率分布，而Decision-based攻击假设攻击者只知道模型输出的Top1预测结果。</p><p>Decision-based黑盒攻击的早期工作包括Additive Gaussian Attack、Boundary Attack等。Additive Gaussian Attack生成的对抗样本对人眼来说太过于明显。Boundary Attack利用神经网络的决策边界的几何性质来构造对抗样本，方法颇为巧妙。Boundary Attack的另一大主要贡献还在于确立了<strong>黑盒攻击领域最主流的技术框架</strong>：先找到原始对抗样本，再用逼近法找到边界对抗样本，然后利用边界对抗样本的种种性质来寻找新的对抗样本，之后再逼近、寻找、…以此循环往复。</p><p>在技术路线上，Decision-based黑盒攻击的难点在于缺少模型的梯度信息（个人认为梯度方向和所谓模型决策边界信息在黑盒对抗领域其实是一回事），而<strong>模型的逆梯度方向是构造对抗样本的关键</strong>。目前已知的解决这一问题的方法包括Transfer-based和Sample-based。Transfer-based方法根据对抗样本在不同模型之间的迁移性，假设不同模型之间的梯度方向相似，先在本地训练替代模型，然后利用替代模型的梯度来<strong>代替未知的目标模型梯度</strong>。Sample-based方法利用模型决策边界附近的一些特殊性质，<strong>构造边界附近的梯度估计量</strong>，然后用蒙特卡洛采样法来<strong>计算出梯度的估计</strong>。</p><p>已有的Decision-based黑盒攻击方法的主要缺陷在于<strong>query次数过多</strong>，生成一张对抗样本图片普遍需要10000+次查询操作，这在实际攻击场景中是不现实的。在“减少query次数”这一方向上已经有了一些探索性的工作，例如引入主动学习框架、对特征进行筛选和降维等。</p><p>本文提出的qFool算法是Decision-based黑盒攻击领域在2019年的重要工作。qFool一方面继承了Boundary Attack的攻击框架，另一方面引入子空间采样的方法创新性地解决了查询次数过高的难题。在实验部分，qFool算法在攻击Google商业图片识别服务时仅用了~1500次查询。</p><h3 id="灵感来源"><a href="#灵感来源" class="headerlink" title="灵感来源"></a>灵感来源</h3><p>该算法的灵感来源于一篇发表于NIPS2016的对抗样本理论工作：Robustness of classifiers: from adversarial to random noise。早期工作中指出，对抗样本附近的决策边界的曲面很小。</p><blockquote><p>Fawzi et al. [7] have shown that the decision boundary has a quite small curvature in the vicinity of adversarial examples.</p></blockquote><p>根据这一发现，如果在对抗样本附近的决策边界上找到“边界对抗样本”，那么<strong>对抗样本的梯度方向与邻近区域的边界对抗样本的梯度方向几乎一样</strong>。</p><p>因此，只要找到了边界对抗样本（较容易），就可以依循梯度方向来找到附近的对抗样本（较困难）。（把难题简单化）</p><h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2><p>从查询效率上看，qFool超过了经典的Boundary Attack算法，仅利用~1500次查询就成功地攻击了Google商业图片识别服务。</p><p>从实验成果上看，qFool用实验证明了边界对抗样本附近的梯度和邻域内的对抗样本梯度几乎一样的性质，并且验证了在子空间内采样生成对抗扰动这条降维的技术路线确实可行。</p><p>2020年的很多黑盒攻击的工作在方案的复杂性和理论的严密性上超越了qFool算法。</p><h2 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h2><h3 id="算法框架"><a href="#算法框架" class="headerlink" title="算法框架"></a>算法框架</h3><p>这里只关心适用最广泛的targeted attack场景，伪代码如下：</p><p>输入：原始图片 <code>x_0</code>，目标图片 <code>x_t</code>，每次更新估计量所需的查询次数 <code>nu</code>，控制内循环查询次数的超参数 <code>threshold</code><br>输出：对抗样本 <code>x_adv</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">二分搜索寻找边界对抗样本</span><br><span class="line"><span class="keyword">while</span> 已消耗查询次数 &lt; 总查询次数：</span><br><span class="line">为本轮迭代分配查询次数</span><br><span class="line"><span class="keyword">while</span> 对抗样本更新幅度满足预设条件 <span class="keyword">and</span> 总查询次数未耗尽：</span><br><span class="line">    在边界对抗样本上施加随机扰动（可以在频率子空间上施加扰动），查询 nu 次</span><br><span class="line">        利用内部循环产生的所有查询结果来构造梯度的估计量</span><br><span class="line">        新对抗样本 = 边界对抗样本 + 步长 * 梯度的估计量</span><br><span class="line">        二分搜索，更新新对抗样本</span><br><span class="line">    边界对抗样本 = 新对抗样本</span><br></pre></td></tr></table></figure><p>算法中需要详细分析的有三点：</p><ul><li>怎么估计边界对抗样本上的梯度？</li><li>总查询次数如何分配？</li><li>如何在子空间上进行采样？</li></ul><h3 id="梯度的估计"><a href="#梯度的估计" class="headerlink" title="梯度的估计"></a>梯度的估计</h3><p>假设算法每轮迭代时向模型查询n次，那么每次构造n个随机噪声向量，采样后进行归一化，</p><p>$${\mathbf{\eta}_i} \sim N(0, \mathbf{1}_n)$$</p><p>将噪声叠加到边界对抗样本P上，得到n个查询结果，</p><p>$$z_i &#x3D; \left{ \begin{array}{rcl}<br>-1 &amp; f(\mathcal{P}+\mathbf{\eta}_i)&#x3D;f(\mathbf{x}_0) \<br>+1 &amp; f(\mathcal{P}+\mathbf{\eta}_i) \neq f(\mathbf{x}_0)<br>\end{array}\right.<br>, ;;; i&#x3D;1,2,…,n$$</p><p>构造边界对抗样本附近的梯度的估计量，</p><p>$$\nabla f(\mathcal{x}<em>0) \approx \nabla f(\mathcal{P}) \approx \mathbf{\xi}<br>&#x3D; \frac{\sum^n</em>{i&#x3D;1}{z_i \mathbf{\eta}<em>i}}<br>{|\sum^n</em>{i&#x3D;1}{z_i \mathbf{\eta}_i}|_2}$$</p><h3 id="查询次数的分配策略"><a href="#查询次数的分配策略" class="headerlink" title="查询次数的分配策略"></a>查询次数的分配策略</h3><p>在理想的情况下，采样次数 <code>n</code> 充分大，采样得到的随机向量在决策边界两遍分布均匀，这样的话，算法利用 <code>n</code> 次查询得到的结果构造的统计量就能精确估计梯度。</p><p>但考虑到实际情况中，用户并不知道 <code>n</code> 的合适大小，采样得到的随机向量也可能分布并不充分均匀，就会为后续的梯度估计步骤引入误差，或者产生很大的对抗扰动。</p><p>论文还指出，初始对抗样本与原始样本之间的距离对最终生成的对抗样本质量有很大影响，因此算法更希望在前期找到尽可能好的对抗样本。（意味着前几轮的查询总次数更多）</p><p>为了避免以上情况，qFool算法提出了一种渐进的、贪心的分配策略：</p><ul><li>固定每次查询&#x2F;采样数目为 <code>nu</code></li><li>多次查询组成算法的一轮迭代 （每轮迭代的查询次数 &#x3D; 查询次数 * <code>nu</code>）</li><li>每轮迭代中，控制生成的扰动大小，控制方法是尽可能生成距离边界对抗样本更近的对抗样本</li><li>迭代轮数受查询的总次数限制</li></ul><p>迭代进行的判定条件具体如下，</p><p>$$\frac{|x^{(i)}_{adv} - \mathcal{P}<em>i|}{n^{(i)}}<br>\leq<br>\epsilon ;; \frac{|x^{(i-1)}</em>{adv} - \mathcal{P}<em>i|}{n^{(i-1)}}<br>;;;;<br>and<br>;;;;<br>\sum^i</em>{j&#x3D;0}{n^{(j)}} &lt; n$$</p><h3 id="子空间采样"><a href="#子空间采样" class="headerlink" title="子空间采样"></a>子空间采样</h3><p>本论文对图像进行离散余弦变换（DCT），变换后的频率图的左上部分表示的是原图的低频部分。</p><p>qFool算法在低频部分截取维度大小为 <code>m</code> 的子空间，在这个空间范围内施加对抗扰动，然后用反离散余弦变换（IDCT）还原成对抗图片。</p><p>缩小维度让采样得到的随机噪声在决策边界的分布更加均匀，根据随机噪声估计得到的梯度方向也就更加精确，最终可以让生成的对抗扰动更小、更不易被察觉。在subspace内采样所需的查询次数更少。</p><p>相比之下，在full space内采样得到的噪声分布得极为稀疏，沿决策边界均匀分布的可能性也更低。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;基本信息&quot;&gt;&lt;a href=&quot;#基本信息&quot; class=&quot;headerlink&quot; title=&quot;基本信息&quot;&gt;&lt;/a&gt;基本信息&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;会议&amp;#x2F;期刊&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;ICCV&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;年份&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;2019&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;机构&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;EPFL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;一作&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Yujia Liu&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;领域&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Adversarial Example, Decision-based Black-box Attack&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&quot;主要贡献&quot;&gt;&lt;a href=&quot;#主要贡献&quot; class=&quot;headerlink&quot; title=&quot;主要贡献&quot;&gt;&lt;/a&gt;主要贡献&lt;/h2&gt;&lt;p&gt;本文提出了一种新型&lt;a href=&quot;https://arxiv.org/abs/1903.10826&quot;&gt;黑盒对抗样本生成算法qFool&lt;/a&gt;。该算法不依赖模型输出的概率分布，仅&lt;strong&gt;利用Top-1预测结果&lt;/strong&gt;就能构造出对抗样本。qFool算法的特点是&lt;strong&gt;查询次数较少&lt;/strong&gt;，其变种qFool-subspace算法还能&lt;strong&gt;将对抗样本限制在输入的低频子空间中&lt;/strong&gt;，在&lt;strong&gt;计算上更加高效&lt;/strong&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="Papers" scheme="http://xinlu.cool/categories/Papers/"/>
    
    
    <category term="Machine Learning" scheme="http://xinlu.cool/tags/Machine-Learning/"/>
    
    <category term="Adversarial Example" scheme="http://xinlu.cool/tags/Adversarial-Example/"/>
    
    <category term="Black-box Attack" scheme="http://xinlu.cool/tags/Black-box-Attack/"/>
    
  </entry>
  
  <entry>
    <title>A Gift from Knowledge Distillation Fast Optimization, Network Minimization and Transfer Learning论文摘要</title>
    <link href="http://xinlu.cool/Papers/paper-a-gift-from-knowledge-distillation/"/>
    <id>http://xinlu.cool/Papers/paper-a-gift-from-knowledge-distillation/</id>
    <published>2021-03-08T13:33:20.000Z</published>
    <updated>2021-03-24T05:53:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文提出了一种新的卷积网络权重初始化方法，它的思路是利用FSP矩阵来表示相邻两层输出之间的关系，这种关系能告诉我们“神经网络解决问题的思路”，然后训练学生网络来最小化FSP矩阵的L2距离，以此初始化学生网络权重，之后再接着训练。该方法在cifar10、cifar100数据集上被证明具有收敛快、精度高、适于迁移学习的效果。</p><span id="more"></span><h2 id="一、基本信息"><a href="#一、基本信息" class="headerlink" title="一、基本信息"></a>一、基本信息</h2><table><thead><tr><th>会议&#x2F;期刊</th><th>CVPR</th></tr></thead><tbody><tr><td>年份</td><td>2017</td></tr><tr><td>机构</td><td>KAIST</td></tr><tr><td>一作</td><td>Junho Yim，Donggyu Joo，Junmo Kim</td></tr><tr><td>领域</td><td>Knowledge Distillation，Transfer Learning</td></tr></tbody></table><h2 id="二、做了什么？针对什么应用场景？"><a href="#二、做了什么？针对什么应用场景？" class="headerlink" title="二、做了什么？针对什么应用场景？"></a>二、做了什么？针对什么应用场景？</h2><p>本文提出了一种新的卷积网络权重初始化方法，它的思路是利用FSP矩阵来表示相邻两层输出之间的关系，这种关系能告诉我们“神经网络解决问题的思路”，然后训练学生网络来minimize L2(FSP_teacher, FSP_student)，以此初始化学生网络权重，之后再接着训练。该方法在cifar10、cifar100数据集上被证明具有收敛快、精度高、适于迁移学习的效果。</p><p>主要针对场景：<br>    1）手上有一个超大的模型，但部署环境不支持计算量&#x2F;存储&#x2F;功耗，因此需要训练一个小一点的模型or多个小型模型的集成，<br>    2）手上有一个预训练模型，但新任务样本量较少、从头训练效果不好，因此需要在新任务上进行fine-tune，<br>    3）追求模型的快速收敛，需要好的初始化策略，</p><h2 id="三、这么做有什么好处？（纵向比较）"><a href="#三、这么做有什么好处？（纵向比较）" class="headerlink" title="三、这么做有什么好处？（纵向比较）"></a>三、这么做有什么好处？（纵向比较）</h2><p>第一次从“flow of solving problems”的角度看待知识蒸馏，具有启发意义。（之前的方法过于注重让student模仿</p><p>将知识蒸馏技术引入了迁移学习领域。</p><h2 id="四、为什么做这个工作？（横向比较）"><a href="#四、为什么做这个工作？（横向比较）" class="headerlink" title="四、为什么做这个工作？（横向比较）"></a>四、为什么做这个工作？（横向比较）</h2><p>vs 普通的KD（Romero&#x2F;FitNets）：</p><ul><li><p>其他知识蒸馏方法只追求student模仿teacher的结果输出&#x2F;中间层输出，只重视结果而不重视解决问题的过程，</p></li><li><p>训练过程低效，本方法多个模块可以独立训练，效果仍然很好，</p></li><li><p>不利于产生迁移性好的学生网络，因为没有学习过程只强调模仿</p></li></ul><p>vs 其他快速收敛的方法：选择一个好的初始化策略能使深度网络优化地更快，选择一个好的优化器能使深度网络更易于达到全局&#x2F;局部最优</p><ul><li><p>simple init：Gaussian noise、Xavier</p></li><li><p>complicated init：he normal、he uniform</p></li><li><p>optimizer：sgd、adam</p></li></ul><h2 id="五、方法上有什么创新之处？（实验方法-x2F-评价指标-x2F-谋篇布局-x2F-制图）"><a href="#五、方法上有什么创新之处？（实验方法-x2F-评价指标-x2F-谋篇布局-x2F-制图）" class="headerlink" title="五、方法上有什么创新之处？（实验方法&#x2F;评价指标&#x2F;谋篇布局&#x2F;制图）"></a>五、方法上有什么创新之处？（实验方法&#x2F;评价指标&#x2F;谋篇布局&#x2F;制图）</h2><p>核心问题：</p><ol><li>如何定义teacher网络所含的信息？ &#x3D;&gt; FSP矩阵</li><li>如何让student网络学习到teacher所含信息？ &#x3D;&gt; 最小化两个网络的FSP矩阵距离</li><li>如何减少students之前的关联性、引入差异性？（好做集成分类器） &#x3D;&gt; 打乱teacher网络的通道，生成新的FSP matrices</li><li>如何比较初始化策略 vs 简单的知识迁移？&#x3D;&gt; 用相同的架构做kd，一种init student&#x3D;trained teacher，另一种init student&#x3D;FSP trained(trained  teacher)</li><li>怎么证明收敛更快？&#x3D;&gt; student只用 1&#x2F;3 的迭代次数，达到和teacher相似的精确度</li></ol><h2 id="六、思路上有什么创新之处？（新发现-x2F-新论断-x2F-新猜想）"><a href="#六、思路上有什么创新之处？（新发现-x2F-新论断-x2F-新猜想）" class="headerlink" title="六、思路上有什么创新之处？（新发现&#x2F;新论断&#x2F;新猜想）"></a>六、思路上有什么创新之处？（新发现&#x2F;新论断&#x2F;新猜想）</h2><ul><li>定义了一种high level knowledge &#x3D;&gt; flow of solving problems &#x3D;&gt; relationship between outputs of 2 connected layers</li><li>借鉴了Gramian matrix的思想（A neural algorithm of artistic style），提出了FSP矩阵（flow of solving problems）</li></ul><h2 id="七、有什么我可以借鉴的？"><a href="#七、有什么我可以借鉴的？" class="headerlink" title="七、有什么我可以借鉴的？"></a>七、有什么我可以借鉴的？</h2><p>对CIFAR10数据集，可以先padding到40x40再训练。</p><h2 id="八、缺点有哪些？"><a href="#八、缺点有哪些？" class="headerlink" title="八、缺点有哪些？"></a>八、缺点有哪些？</h2><p>语言描述过于累赘，实验部分思路不够清晰。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文提出了一种新的卷积网络权重初始化方法，它的思路是利用FSP矩阵来表示相邻两层输出之间的关系，这种关系能告诉我们“神经网络解决问题的思路”，然后训练学生网络来最小化FSP矩阵的L2距离，以此初始化学生网络权重，之后再接着训练。该方法在cifar10、cifar100数据集上被证明具有收敛快、精度高、适于迁移学习的效果。&lt;/p&gt;</summary>
    
    
    
    <category term="Papers" scheme="http://xinlu.cool/categories/Papers/"/>
    
    
    <category term="Machine Learning" scheme="http://xinlu.cool/tags/Machine-Learning/"/>
    
    <category term="Knowledge Distillation" scheme="http://xinlu.cool/tags/Knowledge-Distillation/"/>
    
  </entry>
  
  <entry>
    <title>HopSkipJumpAttack论文分析</title>
    <link href="http://xinlu.cool/Papers/paper-hsja/"/>
    <id>http://xinlu.cool/Papers/paper-hsja/</id>
    <published>2021-01-19T07:36:29.000Z</published>
    <updated>2021-03-24T05:53:30.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1904.02144">HopSkipJumpAttack</a>是发表于2020年S&amp;P的论文，提出了一种新型黑盒对抗攻击的方法，利用采样+逼近的思路来生成对抗样本，理论基础完备，实验效果达到了SOTA。</p><span id="more"></span><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><h3 id="被攻击模型的定义"><a href="#被攻击模型的定义" class="headerlink" title="被攻击模型的定义"></a>被攻击模型的定义</h3><p>定义神经网络为以下函数</p><p>$$F: \mathbb{R}^d \rightarrow \mathbb{R}^m$$</p><p>函数的输入为区间[0, 1]上的d维向量</p><p>$$x \in [0, 1]^d$$</p><p>函数的输出为[0, 1]上的m维概率分布向量，满足全概率公式</p><p>$$y \in \Delta_m :&#x3D; {y \in [0, 1]^m : | :  \Sigma^m_{c&#x3D;1} : y_c &#x3D; 1}$$</p><p>m同时也是神经网络输出类别的总个数，c用来指代任意一个类别，神经网络输出的所有类别标签的集合即为</p><p>$$[m] &#x3D; {1,…,m}$$</p><p>将函数的输出写成向量的形式为</p><p>$$y &#x3D; (F_1(x),…,F_m(x))$$</p><p>基于以上函数的分类器可以表示为</p><p>$$C(x) :&#x3D; \underset{c \in [m]}{\operatorname{argmax}}F_c (x)$$</p><h3 id="对抗攻击的定义"><a href="#对抗攻击的定义" class="headerlink" title="对抗攻击的定义"></a>对抗攻击的定义</h3><p>untarget attack的目标是让分类器的输出类别从</p><p>$$c^* :&#x3D; C(x^*)$$</p><p>变成与原来类别不同的任何类别</p><p>$$c \in [m] - {c^*}$$</p><p>targeted attack的目标是让分类器的输出类别变成某个预先定义好的类别</p><p>$$c^{\dagger} \in [m] - {c^*}$$</p><p>定义函数S，S与攻击者的攻击目标有关，可以判定当前生成的对抗样本是否满足攻击目标</p><p>$$S_{x^*}(x’):&#x3D; \left { \begin{array}{rcl}<br>\operatorname{max}<em>{c \neq c^*} F_c(x’)-F</em>{c^*}(x’) &amp; (Untargeted) \<br>F_{c^\dagger}(x’)-\operatorname{max}_{c \neq c^\dagger}F_c(x’) &amp; (Targeted)<br>\end{array}\right.$$</p><p>对于任意对抗样本x’而言，只要满足S(x’)&gt;0，就可以认为攻击成功</p><h3 id="边界上的对抗样本集合"><a href="#边界上的对抗样本集合" class="headerlink" title="边界上的对抗样本集合"></a>边界上的对抗样本集合</h3><p>当S(x’)&#x3D;0时，对抗攻击正好处在成功与失败的边界上，定义边界上的对抗样本构成的集合为</p><p>$$bd(S_{x^*}):&#x3D;{ z \in [0, 1]^d : | : S_{x^*}(z)&#x3D;0 }$$</p><h3 id="攻击成功的判定函数"><a href="#攻击成功的判定函数" class="headerlink" title="攻击成功的判定函数"></a>攻击成功的判定函数</h3><p>构造sign函数如下</p><p>$$\phi_{x^*}(x’):&#x3D;\operatorname{sign}(S_{x^*}(x’))&#x3D; \left { \begin{array}{rcl}<br>1 &amp; if ; S_{x^*}(x’)&gt;0 \<br>-1 &amp; otherwise<br>\end{array}\right.$$</p><p>当sign函数取值为+1时，对抗样本攻击即为成功。</p><p>为了实现攻击的隐蔽性，攻击者最终的目标是找到与原始样本距离最小的对抗样本，距离函数一般取0、2、无穷范数。</p><p>$$\operatorname{min}<em>{x’};d(x’, x^*) ;;;; s.t.  \phi</em>{x^*}(x’)&#x3D;1$$</p><h2 id="算法框架"><a href="#算法框架" class="headerlink" title="算法框架"></a>算法框架</h2><h3 id="迭代更新"><a href="#迭代更新" class="headerlink" title="迭代更新"></a>迭代更新</h3><p>HSJA算法可以用数学公式描述如下<br>$$x_{t+1} &#x3D; \alpha_t x^* + (1 - \alpha_t)<br>{ x_t + \xi_t \frac{\nabla S_{x^*}(x_t)}{||\nabla S_{x^*}(x_t)||_2} }$$</p><p>其中涉及的关键步骤有：</p><ul><li>用<strong>二分搜索</strong>来选取合适的alpha，让新对抗样本逼近边界</li><li>在边界上，用<strong>Monte Carlo采样</strong>得到函数S的梯度的估计，生成对抗扰动</li><li>用<strong>Geometric Progression</strong>来控制扰动的大小，更新对抗样本</li><li>继续用<strong>二分搜索</strong>来选取合适的alpha，让新对抗样本逼近边界</li><li>……</li></ul><h3 id="步长选择"><a href="#步长选择" class="headerlink" title="步长选择"></a>步长选择</h3><p>把梯度估计线性叠加到对抗样本上的公式描述如下</p><p>$$\tilde{x}_t :&#x3D; x_t + \xi_t v_t (x_t, \delta_t)$$</p><p>$$v_t(x_t, \delta_t) &#x3D; \left { \begin{array}{rcl}<br>\widehat{\nabla S}(x_t, \delta_t) &#x2F; ||\widehat{\nabla S}(x_t, \delta_t)||_2 &amp; if ;; p &#x3D; 2 \<br>\operatorname{sign}(\widehat{\nabla S}(x_t, \delta_t)) &amp; if ;; p &#x3D; \infty<br>\end{array}<br>\right.$$</p><p>该迭代算法的收敛性与步长的选择直接相关，HSJA将步长初始化如下，如果更新后的对抗样本攻击失败，那么步长减半，以此类推。</p><p>$$\xi_t :&#x3D; ||x_t - x^*||_p &#x2F; \sqrt{t}$$</p><h2 id="算法细节"><a href="#算法细节" class="headerlink" title="算法细节"></a>算法细节</h2><h3 id="Lp-projection"><a href="#Lp-projection" class="headerlink" title="Lp-projection"></a>Lp-projection</h3><p>与大多数主流算法相似，HSJA算法给对抗样本到原始样本的距离增加了限制，不能大于epsilon。距离函数取Lp范数，p&#x3D;2或inf。</p><p>给定对抗样本x，Lp-projection步骤的目的是在对抗样本x上进行裁剪，裁剪后得到的新对抗样本y既要满足到原始样本的距离限制，又要距离原来的对抗样本x尽可能地近。</p><p>Lp-projection步骤在p&#x3D;1, 2, …, 无穷时都有通解，但本算法重新构造了通解，以便后续进行二分搜索。以下分别为L2和Linf两种情况下的映射公式。</p><p>当p&#x3D;2时，映射公式如下</p><p>$$\Pi_{x^*,\alpha_t}^2 (x) :&#x3D;<br>\underset{||y-x^*||_2 \leqslant \alpha_t}{\operatorname{argmin}}<br>||y-x||_2 &#x3D;<br>\alpha_t x^* + (1-\alpha_t)x$$</p><p>当p&#x3D;inf时，映射公式如下，值得注意的是，x和x*都是向量，而此处新定义的c是常数。</p><p>$$\Pi_{x^*, \alpha}^\infty (x) :&#x3D;<br>\operatorname{max}{\operatorname{min}{x, x^*+c}, x^*-c} ;; (modified)$$</p><p>$$c :&#x3D; \alpha||x - x^*||_\infty$$</p><p><strong>原论文在此处的公式可能有误，已知c是个非负数，那么x<em>与x</em>+c的比较就失去了意义，以下给出原论文上的无穷范数映射公式</strong></p><p>$$\Pi_{x^*, \alpha}^\infty (x)_i :&#x3D;<br>\operatorname{max}{\operatorname{min}{x_i^*, x_i^*+c}, x_i-c}$$</p><p>无论p&#x3D;2还是inf，alpha的概念都是统一的：越接近0就离原始样本越近，越接近0就离对抗样本越近。利用概念上的统一性，后续在对alpha在区间[0, 1]上做二分搜索时，也更加方便。</p><p>开源代码库<a href="https://github.com/bethgelab/foolbox/blob/master/foolbox/attacks/hop_skip_jump.py">foolbox</a>给出了Lp-projection的实现，如下所示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_project</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self, originals: ep.Tensor, perturbed: ep.Tensor, epsilons: ep.Tensor</span></span><br><span class="line"><span class="params"></span>) -&gt; ep.Tensor:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Clips the perturbations to epsilon and returns the new perturbed</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        originals: A batch of reference inputs.</span></span><br><span class="line"><span class="string">        perturbed: A batch of perturbed inputs.</span></span><br><span class="line"><span class="string">        epsilons: A batch of norm values to project to.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        A tensor like perturbed but with the perturbation clipped to epsilon.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    epsilons = atleast_kd(epsilons, originals.ndim)</span><br><span class="line">    <span class="keyword">if</span> self.constraint == <span class="string">&quot;linf&quot;</span>:</span><br><span class="line">        perturbation = perturbed - originals</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ep.clip does not support tensors as min/max</span></span><br><span class="line">        clipped_perturbed = ep.where(</span><br><span class="line">            perturbation &gt; epsilons, originals + epsilons, perturbed</span><br><span class="line">        )</span><br><span class="line">        clipped_perturbed = ep.where(</span><br><span class="line">            perturbation &lt; -epsilons, originals - epsilons, clipped_perturbed</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> clipped_perturbed</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">1.0</span> - epsilons) * originals + epsilons * perturbed</span><br></pre></td></tr></table></figure><h3 id="梯度估计"><a href="#梯度估计" class="headerlink" title="梯度估计"></a>梯度估计</h3><h4 id="估计的成立条件"><a href="#估计的成立条件" class="headerlink" title="估计的成立条件"></a>估计的成立条件</h4><p>HSJA算法需要对函数S在第t次迭代生成的对抗样本xt上求梯度。若要使这一梯度可被估计，需要满足以下假设条件</p><ul><li>函数S<strong>二阶可导</strong>，并且满足<strong>局部Lipschitz约束</strong>，x0是初始对抗样本</li></ul><p>$$\exists L&gt;0, ;;<br>\forall x,y \in {z:||z-x^*||_2 \leqslant ||x_0 - x^*||_2 }, $$</p><p>$$||\nabla S_{x^*}(x) - \nabla S_{x^*}(y)||_2 \leqslant L||x-y||_2$$</p><ul><li>如果对抗样本xt刚好<strong>处于边界</strong>，即S(xt)&#x3D;0，那么函数S在xt上的导数一定<strong>存在下界</strong>，并且<strong>下界大于0</strong></li></ul><p>$$\exists \tilde{C} &gt; 0, ;; \forall z \in bd(S_{x^*})$$</p><p>$$|| \nabla S_{x^*}(z) || &gt; \tilde{C}$$</p><ul><li>如果要用对抗样本xt与初始样本x*的差来做函数S梯度的<strong>无偏估计</strong>（即下面的函数r&#x3D;1），那么xt必须要处于HSJA算法优化过程中的<strong>驻点</strong>上</li></ul><p>$$\begin{align}<br>r(x_t, x^*) :&amp;&#x3D; cos \angle (x_t - x^*, \nabla S_{x^*}(x_t)) \<br>&amp; &#x3D; \frac{&lt;x_t - x^*, \nabla S_{x^*}(x_t)&gt;}{||x_t - x^*||<em>2 || \nabla S</em>{x^*}(x_t)||_2}<br>\end{align}$$</p><ul><li>在上述假设都成立的情况下，在HSJA算法优化过程中<strong>选取合适的步长</strong>，可以保证算法得到的对抗样本xt最终收敛至驻点</li></ul><p>$$\xi_t &#x3D; || x_t - x^* ||_2 t^{-q} ;;;; for ; q \in (\frac{1}{2},1)$$</p><p>$$0 \leqslant 1 - r(x_t, x^*) \leqslant ct^{q-1} ;;;; for ; t&#x3D;1,2,…$$</p><p>以上分别为步长更新公式和步长对函数r的限制，具体证明过程里用到了二阶泰勒估计。</p><p>上述估计方法也可以推广到p&#x3D;inf的情况。</p><h4 id="渐进无偏估计量"><a href="#渐进无偏估计量" class="headerlink" title="渐进无偏估计量"></a>渐进无偏估计量</h4><p>对任意位于边界上的xt，可以用以下Monte Carlo采样得到的统计量来估计函数S的梯度<br>$$\widetilde{\nabla S}(x_t, \delta) :&#x3D;<br>\frac{1}{B} \sum_{b&#x3D;1}^{B} \phi_{x^*}(x_t+\delta u_b)u_b, $$</p><p>$$ x_t \in bd(S_{x^*}) $$</p><p>$$ i.i.d. ;{u_b}_{b&#x3D;1}^B \sim U(-1, 1)^d $$</p><p>随机变量ub是独立同分布的d维随机向量，服从均匀分布，B表示样本容量，也是Monte Carlo采样的次数。</p><p>由于引入了delta，导致该估计量是有偏的，但偏差具有下界，可表示为</p><p>$$\cos \angle (\mathbb{E}[ \widetilde{\nabla S} (x_t, \delta)], \nabla S_{x^*}(x_t)) \geqslant<br>1 - \frac{9 L^2 \delta^2 d^2}{8||\nabla S(x_t)||_2^2}$$</p><p>以上估计量的渐进无偏性可表示为</p><p>$$\lim_{\delta \rightarrow 0} \cos \angle (\mathbb{E}[ \widetilde{\nabla S} (x_t, \delta)], \nabla S_{x^*}(x_t))&#x3D;1$$</p><p>一般取delta为1&#x2F;d，之后会给出一个偏差更小的delta选取方法。</p><h4 id="方差更小的估计量"><a href="#方差更小的估计量" class="headerlink" title="方差更小的估计量"></a>方差更小的估计量</h4><p>由于实验误差的存在，xt不一定恰好在边界上，delta也不总是为0，因此采样得到的新样本在边界两边常常是分布不均匀的，这会产生难以忽视的误差。</p><p>因此HSJA算法提出了一个新的方差更小的估计量。和之前的估计量一样，新估计量也是渐进无偏的。新估计量表示如下</p><p>$$\begin{align}<br>\overline{\phi_{x^*}} &amp; :&#x3D; \frac{1}{B} \sum_{b&#x3D;1}^{B} \phi_{x^*}(x_t + \delta u_b)<br>\ \widehat{\nabla S}(x_t, \delta) &amp;:&#x3D; \frac{1}{B-1} \sum_{b&#x3D;1}^{B} (\phi_{x^*}(x_t+\delta u_b) - \overline{\phi_{x^*}})u_b<br>\end{align}$$</p><p>方差上界的证明部分略去。</p><h4 id="Monte-Carlo采样方法的实现"><a href="#Monte-Carlo采样方法的实现" class="headerlink" title="Monte Carlo采样方法的实现"></a>Monte Carlo采样方法的实现</h4><p>开源代码库<a href="https://github.com/bethgelab/foolbox/blob/master/foolbox/attacks/hop_skip_jump.py">foolbox</a>给出了该梯度估计方法的实现，与原论文的代码仓库相比实现更加简洁，但思路比较难理解。</p><p>首先，生成随机张量rv并单位化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> self.constraint == <span class="string">&quot;l2&quot;</span>:</span><br><span class="line">    rv = ep.normal(x_advs, noise_shape)</span><br><span class="line"><span class="keyword">elif</span> self.constraint == <span class="string">&quot;linf&quot;</span>:</span><br><span class="line">    rv = ep.uniform(x_advs, low=-<span class="number">1</span>, high=<span class="number">1</span>, shape=noise_shape)</span><br><span class="line">rv /= atleast_kd(ep.norms.l2(flatten(rv, keep=<span class="number">1</span>), -<span class="number">1</span>), rv.ndim) + <span class="number">1e-12</span></span><br></pre></td></tr></table></figure><p>然后生成扰动图片，即x_adv+delta*rv，图片的值域必须被裁剪到[0, 1]之间。<br>foolbox库要求用户在实例化对象时指明输入的上下界，之后会把所有的输入张量都缩放到[0, 1]之间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scaled_rv = atleast_kd(ep.expand_dims(delta, <span class="number">0</span>), rv.ndim) * rv</span><br><span class="line">perturbed = ep.expand_dims(x_advs, <span class="number">0</span>) + scaled_rv</span><br><span class="line">perturbed = ep.clip(perturbed, <span class="number">0</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>从扰动图片中还原出采样得到的rv，这一步其实有点巧妙，隐式地对采样得到的rv的大小进行了裁剪。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rv = (perturbed - x_advs) / delta</span><br></pre></td></tr></table></figure><p>接下来的步骤需要对pytorch的张量condition操作有一定了解，但这段代码的目的是很明确的，只要生成的扰动图片攻击成功了，multipliers中该扰动图片就对应为1，否则对应为-1。</p><p>perturbed的形状为：<code>(step_size, batch_size, C, H, W)</code>。</p><p>decision的形状为：<code>(step_size, batch_size)</code>，类型为<code>bool</code>。</p><p>multipliers最终的形状为：<code>(step_size, batch_size)</code>，攻击成功对应为1，攻击失败对应为-1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">multipliers_list: <span class="type">List</span>[ep.Tensor] = []</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(steps):</span><br><span class="line">    decision = is_adversarial(perturbed[step])</span><br><span class="line">    multipliers_list.append(</span><br><span class="line">        ep.where(</span><br><span class="line">            decision,</span><br><span class="line">            ep.ones(x_advs, (<span class="built_in">len</span>(x_advs,))),</span><br><span class="line">            -ep.ones(x_advs, (<span class="built_in">len</span>(decision,))),</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line"><span class="comment"># (steps, bs, ...)</span></span><br><span class="line">multipliers = ep.stack(multipliers_list, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>代码还精炼地实现了减少方差的操作，如果所有采样得到的随机扰动都攻击成功&#x2F;都攻击失败，那么multipliers值不变，否则就需要减去均值来减少估计的方差。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vals = ep.where(</span><br><span class="line">    ep.<span class="built_in">abs</span>(ep.mean(multipliers, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)) == <span class="number">1</span>,</span><br><span class="line">    multipliers,</span><br><span class="line">    multipliers - ep.mean(multipliers, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>),</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>最后求出梯度的估计量，并单位化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grad = ep.mean(atleast_kd(vals, rv.ndim) * rv, axis=<span class="number">0</span>)</span><br><span class="line">grad /= ep.norms.l2(atleast_kd(flatten(grad), grad.ndim)) + <span class="number">1e-12</span></span><br></pre></td></tr></table></figure><h3 id="选择合适的扰动大小"><a href="#选择合适的扰动大小" class="headerlink" title="选择合适的扰动大小"></a>选择合适的扰动大小</h3><p>HSJA论文中这部分证明比较硬核，我所学知识有限，实在无法理解。大概意思是控制扰动大小的参数delta与估计误差有很大关系，因此需要谨慎选择。</p><p>常量gamma的值在论文中并没有，而是作为经验参数，默认为1.0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">select_delta</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self, originals: ep.Tensor, distances: ep.Tensor, step: <span class="built_in">int</span></span></span><br><span class="line"><span class="params"></span>) -&gt; ep.Tensor:</span><br><span class="line">    result: ep.Tensor</span><br><span class="line">    <span class="keyword">if</span> step == <span class="number">0</span>:</span><br><span class="line">        result = <span class="number">0.1</span> * ep.ones_like(distances)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        d = np.prod(originals.shape[<span class="number">1</span>:])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.constraint == <span class="string">&quot;linf&quot;</span>:</span><br><span class="line">            theta = self.gamma / (d * d)</span><br><span class="line">            result = d * theta * distances</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            theta = self.gamma / (d * np.sqrt(d))</span><br><span class="line">            result = np.sqrt(d) * theta * distances</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h3 id="二分搜索逼近边界"><a href="#二分搜索逼近边界" class="headerlink" title="二分搜索逼近边界"></a>二分搜索逼近边界</h3><p>上述梯度估计的重要前提之一是对抗样本xt要刚好处于边界，如果并不处于边界的话，就需要用二分搜索来逼近边界。</p><p>HSJA算法将Lp-projection与二分搜索相结合。在Lp-projection中，参数alpha的值越大，新对抗样本距离原始样本就越远，alpha值越小，新对抗样本距离原始样本就越近。</p><p>以下结合代码来理解该二分搜索的步骤，初始时，设置alpha的上界、下界分别为0、1。（Linf时上界不可能超过当前无穷范数距离，因此上界初始化为Linf的值）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> self.constraint == <span class="string">&quot;linf&quot;</span>:</span><br><span class="line">    highs = linf(originals, perturbed)</span><br><span class="line">    thresholds = highs * self.gamma / (d * d)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    highs = ep.ones(perturbed, <span class="built_in">len</span>(perturbed))</span><br><span class="line">    thresholds = self.gamma / (d * math.sqrt(d))</span><br><span class="line">lows = ep.zeros_like(highs)</span><br></pre></td></tr></table></figure><p>当新对抗样本攻击成功时，将上界调低一点；当新对抗样本攻击失败时，将下界调高一点。如果上下界差距超过预先定义的thresholds就停止搜索。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> ep.<span class="built_in">any</span>(highs - lows &gt; thresholds):</span><br><span class="line">    mids = (lows + highs) / <span class="number">2</span></span><br><span class="line">    mids_perturbed = self._project(originals, perturbed, mids)</span><br><span class="line">    is_adversarial_ = is_adversarial(mids_perturbed)</span><br><span class="line"></span><br><span class="line">    highs = ep.where(is_adversarial_, mids, highs)</span><br><span class="line">    lows = ep.where(is_adversarial_, lows, mids)</span><br></pre></td></tr></table></figure><p>以上步骤中有一个注意点：用变量highs中存储的所有alpha值来做Lp-projection，都可以攻击成功。利用这个trick，把最终生成的对抗样本再通过highs进行Lp-projection，确保输出的对抗样本都能攻击成功。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">res = self._project(originals, perturbed, highs)</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1904.02144&quot;&gt;HopSkipJumpAttack&lt;/a&gt;是发表于2020年S&amp;amp;P的论文，提出了一种新型黑盒对抗攻击的方法，利用采样+逼近的思路来生成对抗样本，理论基础完备，实验效果达到了SOTA。&lt;/p&gt;</summary>
    
    
    
    <category term="Papers" scheme="http://xinlu.cool/categories/Papers/"/>
    
    
    <category term="Machine Learning" scheme="http://xinlu.cool/tags/Machine-Learning/"/>
    
    <category term="Adversarial Example" scheme="http://xinlu.cool/tags/Adversarial-Example/"/>
    
    <category term="Black-box Attack" scheme="http://xinlu.cool/tags/Black-box-Attack/"/>
    
  </entry>
  
  <entry>
    <title>实验室服务器虚拟环境配置日志</title>
    <link href="http://xinlu.cool/Manuals/server-configuration/"/>
    <id>http://xinlu.cool/Manuals/server-configuration/</id>
    <published>2020-12-30T07:36:29.000Z</published>
    <updated>2021-07-08T06:22:37.000Z</updated>
    
    <content type="html"><![CDATA[<p>使用LXD虚拟化技术为实验室服务器配置多用户隔离运行环境。</p><span id="more"></span><h2 id="服务器监控netdata配置"><a href="#服务器监控netdata配置" class="headerlink" title="服务器监控netdata配置"></a>服务器监控netdata配置</h2><ul><li><p><a href="https://learn.netdata.cloud/docs/get">netdata一行命令安装</a></p></li><li><p><a href="https://learn.netdata.cloud/docs/agent/packaging/installer/methods/manual">netdata依赖库安装</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bash &lt;(curl -Ss https://my-netdata.io/kickstart.sh) --stable-channel --disable-telemetry</span><br><span class="line">sudo apt-get install zlib1g-dev uuid-dev libuv1-dev liblz4-dev libjudy-dev libssl-dev libelf-dev libmnl-dev gcc make git autoconf autoconf-archive autogen automake pkg-config curl python cmake</span><br></pre></td></tr></table></figure><ul><li>后续管理命令</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl <span class="built_in">enable</span> netdata <span class="comment"># 注册系统服务</span></span><br><span class="line">sudo systemctl start/stop/status netdata <span class="comment"># 启动/暂停/查看</span></span><br><span class="line"><span class="built_in">cat</span> /etc/netdata/netdata.conf <span class="comment"># 查看配置文件</span></span><br><span class="line">sudo sh /usr/libexec/netdata/netdata-uninstaller.sh <span class="comment"># 卸载</span></span><br><span class="line">sudo sh /usr/libexec/netdata/netdata-updater.sh <span class="comment"># 更新（默认每天更新）</span></span><br></pre></td></tr></table></figure><ul><li><a href="https://github.com/coraxx/netdata_nv_plugin">n卡监控插件</a>，<a href="https://github.com/coraxx/netdata_nv_plugin">配置文件更新</a></li></ul><h2 id="容器管理LXD配置"><a href="#容器管理LXD配置" class="headerlink" title="容器管理LXD配置"></a>容器管理LXD配置</h2><h3 id="安装容器管理系统lxd、文件系统zfs、网络桥接工具bridge-utils"><a href="#安装容器管理系统lxd、文件系统zfs、网络桥接工具bridge-utils" class="headerlink" title="安装容器管理系统lxd、文件系统zfs、网络桥接工具bridge-utils"></a>安装容器管理系统<code>lxd</code>、文件系统<code>zfs</code>、网络桥接工具<code>bridge-utils</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo snap install lxd</span><br><span class="line">sudo apt install zfsutils-linux bridge-utils</span><br></pre></td></tr></table></figure><h3 id="初始化lxd"><a href="#初始化lxd" class="headerlink" title="初始化lxd"></a>初始化<code>lxd</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">sudo lxd init</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下为初始化配置</span></span><br><span class="line"></span><br><span class="line">Would you like to use LXD clustering? (<span class="built_in">yes</span>/no) [default=no]:<span class="comment"># 单机部署，不用集群</span></span><br><span class="line">Do you want to configure a new storage pool? (<span class="built_in">yes</span>/no) [default=<span class="built_in">yes</span>]:<span class="comment"># 在SSD上新建zfs存储池</span></span><br><span class="line">Name of the new storage pool [default=default]: lxd<span class="comment"># 命名存储池</span></span><br><span class="line">Name of the storage backend to use (btrfs, ceph, <span class="built_in">dir</span>, lvm, zfs) [default=zfs]:<span class="comment"># zfs是坠吼的</span></span><br><span class="line">Create a new ZFS pool? (<span class="built_in">yes</span>/no) [default=<span class="built_in">yes</span>]:<span class="comment"># 二次确认</span></span><br><span class="line">Would you like to use an existing block device? (<span class="built_in">yes</span>/no) [default=no]:<span class="comment"># 试过点yes，没成功，那算了</span></span><br><span class="line">Size <span class="keyword">in</span> GB of the new loop device (1GB minimum) [default=100GB]: 360GB<span class="comment"># 比SSD总容量小一点就行</span></span><br><span class="line">Would you like to connect to a MAAS server? (<span class="built_in">yes</span>/no) [default=no]:<span class="comment"># no</span></span><br><span class="line">Would you like to create a new <span class="built_in">local</span> network bridge? (<span class="built_in">yes</span>/no) [default=<span class="built_in">yes</span>]:<span class="comment"># 建立容器到主机之间的桥接机制</span></span><br><span class="line">Would you like to configure LXD to use an existing bridge or host interface? (<span class="built_in">yes</span>/no) [default=no]:<span class="comment"># no</span></span><br><span class="line">Name of the existing bridge or host interface:<span class="comment"># 命名虚拟桥接网卡</span></span><br><span class="line">Would you like LXD to be available over the network? (<span class="built_in">yes</span>/no) [default=no]:<span class="comment"># 不要暴露容器，访问容器只用端口映射</span></span><br><span class="line">Would you like stale cached images to be updated automatically? (<span class="built_in">yes</span>/no) [default=<span class="built_in">yes</span>]<span class="comment"># 定期更新镜像</span></span><br><span class="line">Would you like a YAML <span class="string">&quot;lxd init&quot;</span> preseed to be printed? (<span class="built_in">yes</span>/no) [default=no]:<span class="comment"># 不保存初始配置</span></span><br></pre></td></tr></table></figure><h3 id="配置lxd的默认profile"><a href="#配置lxd的默认profile" class="headerlink" title="配置lxd的默认profile"></a>配置<code>lxd</code>的默认<code>profile</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc profile edit default</span><br></pre></td></tr></table></figure><h3 id="配置示例（yaml格式）"><a href="#配置示例（yaml格式）" class="headerlink" title="配置示例（yaml格式）"></a>配置示例（yaml格式）</h3><p>注意，块设备<code>nvidia-uvm</code>对容器内访问显卡驱动非常重要</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">config:</span></span><br><span class="line">  <span class="attr">limits.cpu:</span> <span class="string">&quot;32&quot;</span></span><br><span class="line">  <span class="attr">limits.memory:</span> <span class="string">64GB</span></span><br><span class="line">  <span class="attr">security.nesting:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">  <span class="attr">security.privileged:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">Default</span> <span class="string">LXD</span> <span class="string">profile</span></span><br><span class="line"><span class="attr">devices:</span></span><br><span class="line">  <span class="attr">eth0:</span></span><br><span class="line">    <span class="attr">limits.ingress:</span> <span class="string">200Mbit</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">eth0</span></span><br><span class="line">    <span class="attr">nictype:</span> <span class="string">bridged</span></span><br><span class="line">    <span class="attr">parent:</span> <span class="string">lxdbr0</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">nic</span></span><br><span class="line">  <span class="attr">gpu:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">gpu</span></span><br><span class="line">  <span class="attr">nvidia-uvm:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/dev/nvidia-uvm</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">unix-char</span></span><br><span class="line">  <span class="attr">root:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">    <span class="attr">pool:</span> <span class="string">default</span></span><br><span class="line">    <span class="attr">size:</span> <span class="string">30GB</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">disk</span></span><br><span class="line">  <span class="attr">shared-folder:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/usr/local/shared-folder</span></span><br><span class="line">    <span class="attr">source:</span> <span class="string">/usr/local/shared-folder</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">disk</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">used_by:</span> []</span><br></pre></td></tr></table></figure><h3 id="从清华大学镜像加速站点拉取最新的ubuntu-18-04系统镜像"><a href="#从清华大学镜像加速站点拉取最新的ubuntu-18-04系统镜像" class="headerlink" title="从清华大学镜像加速站点拉取最新的ubuntu 18.04系统镜像"></a>从清华大学镜像加速站点拉取最新的<code>ubuntu 18.04</code>系统镜像</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc remote add tuna-images https://mirrors.tuna.tsinghua.edu.cn/lxc-images/ --protocol=simplestreams --public</span><br><span class="line">sudo lxc image list tuna-images:<span class="comment"># 显示可供下载的镜像列表</span></span><br><span class="line">sudo lxc launch tuna-images:&lt;<span class="built_in">hash</span>&gt; &lt;ContianerName&gt;<span class="comment"># 从清华镜像站点拉取镜像，在本地创建容器</span></span><br></pre></td></tr></table></figure><h3 id="安装容器监控设施lxdui，并注册为系统服务"><a href="#安装容器监控设施lxdui，并注册为系统服务" class="headerlink" title="安装容器监控设施lxdui，并注册为系统服务"></a>安装容器监控设施<code>lxdui</code>，并注册为系统服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install -y git build-essential libssl-dev python3-venv python3-pip python3-dev zfsutils-linux bridge-utils</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/AdaptiveScale/lxdui.git</span><br><span class="line"><span class="built_in">cd</span> lxdui</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下用root用户安装（不嫌麻烦的话可以新建一个用户组来管理lxdui）</span></span><br><span class="line"></span><br><span class="line">sudo su</span><br><span class="line">pip3 install .</span><br><span class="line">su &lt;PreviousUserName&gt;</span><br></pre></td></tr></table></figure><p>参考<a href="https://medium.com/@benmorel/creating-a-linux-service-with-systemd-611b5c8b91d6">注册Linux系统服务教程</a>、<a href="https://github.com/AdaptiveScale/lxdui/blob/master/lxdui.service">lxdui官方参考unit文件</a>，创建<code>/etc/systemd/system/lxdui.service</code>文件</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[Unit]</span></span><br><span class="line"><span class="attr">Description</span>=Web UI for the native Linux container technology LXD/LXC</span><br><span class="line"><span class="attr">After</span>=network.target snapd.service</span><br><span class="line"><span class="attr">Requires</span>=snapd.service</span><br><span class="line"></span><br><span class="line"><span class="section">[Service]</span></span><br><span class="line"><span class="attr">Type</span>=simple</span><br><span class="line"><span class="attr">Restart</span>=always</span><br><span class="line"><span class="attr">RestartSec</span>=<span class="number">10</span></span><br><span class="line"><span class="attr">User</span>=root</span><br><span class="line"><span class="attr">PIDFile</span>=/run/lxdui/lxdui.pid</span><br><span class="line"><span class="attr">ExecStart</span>=/usr/local/bin/lxdui start</span><br><span class="line"><span class="attr">ExecStop</span>=/usr/local/bin/lxdui stop</span><br><span class="line"></span><br><span class="line"><span class="section">[Install]</span></span><br><span class="line"><span class="attr">WantedBy</span>=multi-user.target</span><br></pre></td></tr></table></figure><p>启动服务，默认用户名<code>admin</code>，默认密码<code>admin</code>，默认端口<code>15151</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl <span class="built_in">enable</span> lxdui</span><br><span class="line">sudo systemctl start lxdui</span><br><span class="line">sudo ufw allow from &lt;SubnetIPAddress&gt;/&lt;LengthOfSubnetMask&gt; to any port 15151</span><br></pre></td></tr></table></figure><h2 id="配置模板容器GPU环境"><a href="#配置模板容器GPU环境" class="headerlink" title="配置模板容器GPU环境"></a>配置模板容器GPU环境</h2><h3 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc <span class="built_in">exec</span> &lt;ContainerName&gt; -- su --login &lt;UserName&gt;</span><br></pre></td></tr></table></figure><h3 id="配置sudo免密码"><a href="#配置sudo免密码" class="headerlink" title="配置sudo免密码"></a>配置<code>sudo</code>免密码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo su root</span><br><span class="line">visudo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在用户权限配置文件中加以下行</span></span><br><span class="line"></span><br><span class="line">&lt;UserName&gt; ALL=(ALL) NOPASSWD: NOPASSWD: ALL</span><br></pre></td></tr></table></figure><h3 id="参考tuna官方使用帮助，切换apt源到清华大学镜像加速站点"><a href="#参考tuna官方使用帮助，切换apt源到清华大学镜像加速站点" class="headerlink" title="参考tuna官方使用帮助，切换apt源到清华大学镜像加速站点"></a>参考<a href="https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/">tuna官方使用帮助</a>，切换<code>apt</code>源到清华大学镜像加速站点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">cp</span> /etc/apt/sources.list /etc/apt/sources.list.bak</span><br><span class="line">sudo vi /etc/apt/sources.list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下为新的apt源url列表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预发布软件源，不建议启用</span></span><br><span class="line"><span class="comment"># deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse</span></span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse</span></span><br></pre></td></tr></table></figure><h3 id="下载显卡驱动、CUDA-10-1安装包、cuDNN-7-6-5压缩包"><a href="#下载显卡驱动、CUDA-10-1安装包、cuDNN-7-6-5压缩包" class="headerlink" title="下载显卡驱动、CUDA 10.1安装包、cuDNN 7.6.5压缩包"></a>下载显卡驱动、<code>CUDA 10.1</code>安装包、<code>cuDNN 7.6.5</code>压缩包</h3><p><a href="https://www.nvidia.com/en-us/drivers/unix/linux-amd64-display-archive/">NVIDIA Driver Linux x86_64 Archive</a></p><p><a href="https://developer.nvidia.com/cuda-toolkit-archive">CUDA Archive</a></p><p><a href="https://developer.nvidia.com/rdp/cudnn-archive">cuDNN Archive</a></p><h3 id="参考官方文档，配置CUDA-10-1"><a href="#参考官方文档，配置CUDA-10-1" class="headerlink" title="参考官方文档，配置CUDA 10.1"></a>参考<a href="https://docs.nvidia.com/cuda/archive/10.1/">官方文档</a>，配置<code>CUDA 10.1</code></h3><p>检查<code>GPU</code>硬件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install pciutils</span><br><span class="line">lspci | grep -i nvidia</span><br></pre></td></tr></table></figure><p>检查<code>Linux</code>发行版</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">uname</span> -m &amp;&amp; <span class="built_in">cat</span> /etc/*release</span><br></pre></td></tr></table></figure><p>检查<code>gcc</code>是否安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gcc --version</span><br><span class="line">sudo apt install build-essential manpages-dev<span class="comment"># 安装gcc，g++，make以及相关文档</span></span><br></pre></td></tr></table></figure><p>安装<code>Ubuntu</code>系统的内核依赖</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install linux-headers-$(<span class="built_in">uname</span> -r)</span><br></pre></td></tr></table></figure><p>从下载好的可执行文件安装显卡驱动、<code>CUDA 10.1</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo sh NVIDIA-Linux-x86_64-&lt;DirverVersion&gt;.run --no-kernel-module</span><br><span class="line">sudo sh cuda_&lt;CUDAVersion&gt;_linux.run --no-drm</span><br></pre></td></tr></table></figure><p>添加环境变量到<code>~/.bashrc</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bashrc</span><br><span class="line"></span><br><span class="line"><span class="comment"># CUDA 10.1</span></span><br><span class="line">PATH=/usr/local/cuda-10.1/bin:/usr/local/cuda-10.1/NsightCompute-2019.1<span class="variable">$&#123;PATH:+:<span class="variable">$&#123;PATH&#125;</span>&#125;</span></span><br><span class="line">LD_LIBRARY_PATH=/usr/local/cuda-10.1/lib64<span class="variable">$&#123;LD_LIBRARY_PATH:+:<span class="variable">$&#123;LD_LIBRARY_PATH&#125;</span>&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure><p>最后，检查驱动版本和<code>CUDA</code>版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> /proc/driver/nvidia/version</span><br><span class="line">nvcc -V</span><br></pre></td></tr></table></figure><p>**[Optional]**编译示例代码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> &lt;SampleRootPath&gt;</span><br><span class="line"><span class="built_in">cd</span> 1_Utilities/deviceQuery</span><br><span class="line">make</span><br><span class="line">./deviceQuery</span><br></pre></td></tr></table></figure><p>**[Optional]**开启<code>persistent</code>模式</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /usr/bin/nvidia-persistenced --verbose</span><br></pre></td></tr></table></figure><h3 id="参考官方文档，配置cuDNN-7-6-5"><a href="#参考官方文档，配置cuDNN-7-6-5" class="headerlink" title="参考官方文档，配置cuDNN 7.6.5"></a>参考<a href="https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn_765/cudnn-install/index.html">官方文档</a>，配置<code>cuDNN 7.6.5</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> &lt;CudnnPath&gt;</span><br><span class="line">tar -xzvf cudnn-&lt;CudnnVersion&gt;.tgz</span><br><span class="line">sudo <span class="built_in">cp</span> cuda/include/cudnn.h /usr/local/cuda/include</span><br><span class="line">sudo <span class="built_in">cp</span> cuda/lib64/libcudnn* /usr/local/cuda/lib64</span><br><span class="line">sudo <span class="built_in">chmod</span> a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*</span><br></pre></td></tr></table></figure><h2 id="配置模板容器Python环境"><a href="#配置模板容器Python环境" class="headerlink" title="配置模板容器Python环境"></a>配置模板容器Python环境</h2><h3 id="下载Python-3-7-9源代码"><a href="#下载Python-3-7-9源代码" class="headerlink" title="下载Python 3.7.9源代码"></a>下载<code>Python 3.7.9</code>源代码</h3><p><a href="https://www.python.org/downloads/">Python Source Code Download Page</a></p><h3 id="解压、安装依赖"><a href="#解压、安装依赖" class="headerlink" title="解压、安装依赖"></a>解压、安装依赖</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf Python-3.7.9.tgz</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install -y gcc make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-dev</span><br></pre></td></tr></table></figure><h3 id="配置编译参数"><a href="#配置编译参数" class="headerlink" title="配置编译参数"></a>配置编译参数</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> Python-3.7.9</span><br><span class="line">./configure --prefix=/usr/local/python3.7 --enable-optimizations</span><br></pre></td></tr></table></figure><h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo make -j 32 &amp;&amp; sudo make install</span><br></pre></td></tr></table></figure><h3 id="添加环境变量"><a href="#添加环境变量" class="headerlink" title="添加环境变量"></a>添加环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bashrc</span><br><span class="line"></span><br><span class="line"><span class="comment"># Python 3.7</span></span><br><span class="line">PATH=/usr/local/python3.7/bin<span class="variable">$&#123;PATH:+:<span class="variable">$&#123;PATH&#125;</span>&#125;</span></span><br><span class="line">PATH=/home/ubuntu/.local/bin<span class="variable">$&#123;PATH:+:<span class="variable">$&#123;PATH&#125;</span>&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line">sudo <span class="built_in">chown</span> -R &lt;UserName&gt; ~/.local</span><br></pre></td></tr></table></figure><h3 id="配置清华大学镜像加速站点pip源"><a href="#配置清华大学镜像加速站点pip源" class="headerlink" title="配置清华大学镜像加速站点pip源"></a>配置清华大学镜像加速站点<code>pip</code>源</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python3.7 -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pip -U --user</span><br><span class="line">python3.7 -m pip config <span class="built_in">set</span> global.index-url https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"></span><br><span class="line"><span class="comment"># 阿里云可能更快一点</span></span><br><span class="line">python3.7 -m pip config <span class="built_in">set</span> global.index-url https://mirrors.aliyun.com/pypi/simple</span><br></pre></td></tr></table></figure><h3 id="举例：如何在用户空间下通过pip安装包（没有必要就不要sudo）"><a href="#举例：如何在用户空间下通过pip安装包（没有必要就不要sudo）" class="headerlink" title="举例：如何在用户空间下通过pip安装包（没有必要就不要sudo）"></a>举例：如何在用户空间下通过<code>pip</code>安装包（没有必要就不要<code>sudo</code>）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3.7 -m pip install numpy virtualenv --user --no-cache-dir</span><br></pre></td></tr></table></figure><h3 id="举例：如何在项目文件夹内配置虚拟环境"><a href="#举例：如何在项目文件夹内配置虚拟环境" class="headerlink" title="举例：如何在项目文件夹内配置虚拟环境"></a>举例：如何在项目文件夹内配置虚拟环境</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">python3.7 -m virtualenv ./.venv/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 激活虚拟环境</span></span><br><span class="line"><span class="built_in">source</span> ./venv/bin/activate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在虚拟环境中运行程序</span></span><br><span class="line">python &lt;PythonFileName&gt;.py</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在虚拟程序中安装包</span></span><br><span class="line">python -m pip install numpy --no-cache-dir</span><br><span class="line"></span><br><span class="line"><span class="comment"># 退出虚拟环境</span></span><br><span class="line">deactivate</span><br></pre></td></tr></table></figure><h3 id="安装pytorch和tensorflow"><a href="#安装pytorch和tensorflow" class="headerlink" title="安装pytorch和tensorflow"></a>安装<code>pytorch</code>和<code>tensorflow</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3.7 -m pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html --user --no-cache-dir</span><br><span class="line">python3.7 -m pip install tensorflow-gpu==2.3.1 --user --no-cache-dir</span><br></pre></td></tr></table></figure><h3 id="测试是否能用GPU"><a href="#测试是否能用GPU" class="headerlink" title="测试是否能用GPU"></a>测试是否能用<code>GPU</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(torch.cuda.is_available())</span><br><span class="line"><span class="built_in">print</span>(torch.cuda.device_count())</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="built_in">print</span>(tf.test.is_gpu_available())</span><br></pre></td></tr></table></figure><h2 id="一键添加-x2F-删除用户脚本"><a href="#一键添加-x2F-删除用户脚本" class="headerlink" title="一键添加&#x2F;删除用户脚本"></a>一键添加&#x2F;删除用户脚本</h2><h3 id="导出模板容器为镜像"><a href="#导出模板容器为镜像" class="headerlink" title="导出模板容器为镜像"></a>导出模板容器为镜像</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc stop &lt;ContainerName&gt;</span><br><span class="line">sudo lxc publish &lt;ContainerName&gt; --<span class="built_in">alias</span> &lt;NewImageName&gt; --public</span><br></pre></td></tr></table></figure><h3 id="服务器端添加用户脚本"><a href="#服务器端添加用户脚本" class="headerlink" title="服务器端添加用户脚本"></a>服务器端添加用户脚本</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;用户名是： &quot;</span><span class="variable">$1</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;该用户的ssh端口是： &quot;</span><span class="variable">$2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从配好的镜像文件中启动新的容器</span></span><br><span class="line">sudo lxc launch &lt;ImageName&gt; <span class="variable">$1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 必须等待容器网络配置好，否则无法安装openssh</span></span><br><span class="line"><span class="built_in">sleep</span> 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># 挂载固态硬盘</span></span><br><span class="line"><span class="keyword">if</span> [ ! -d /mnt/data/<span class="variable">$&#123;1&#125;</span> ] ; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">mkdir</span> /mnt/data/<span class="variable">$&#123;1&#125;</span>/</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">sudo lxc config device add <span class="variable">$1</span> data disk <span class="built_in">source</span>=/mnt/data/<span class="variable">$&#123;1&#125;</span>/ path=/mnt/data</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;成功挂载固态硬盘！&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建存放对称秘钥的文件夹</span></span><br><span class="line"><span class="keyword">if</span> [ ! -d /home/<span class="variable">$&#123;ServerUserName&#125;</span>/keys ] ; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">mkdir</span> /home/<span class="variable">$&#123;ServerUserName&#125;</span>/keys</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -d /usr/local/shared-folder/keys ] ; <span class="keyword">then</span></span><br><span class="line">sudo <span class="built_in">mkdir</span> /usr/local/shared-folder/keys</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装容器中的openssh</span></span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo apt update</span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo apt install -y openssh-server</span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo service ssh start</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;容器内的ssh服务已启动！&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 备份原来的sshd配置</span></span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo <span class="built_in">cp</span> /etc/ssh/sshd_config /etc/ssh/sshd_config.bak</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加上写入权限</span></span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo <span class="built_in">chmod</span> a+w /etc/ssh/sshd_config</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写入新的sshd配置</span></span><br><span class="line">sshd_config=<span class="string">&quot;Port <span class="variable">$&#123;2&#125;</span></span></span><br><span class="line"><span class="string">AddressFamily any</span></span><br><span class="line"><span class="string">ListenAddress 0.0.0.0</span></span><br><span class="line"><span class="string">ListenAddress ::</span></span><br><span class="line"><span class="string">PubkeyAuthentication yes</span></span><br><span class="line"><span class="string">AuthorizedKeysFile      .ssh/authorized_keys</span></span><br><span class="line"><span class="string">PasswordAuthentication no</span></span><br><span class="line"><span class="string">Subsystem       sftp    /usr/lib/openssh/sftp-server</span></span><br><span class="line"><span class="string">AllowUsers ubuntu</span></span><br><span class="line"><span class="string">UsePAM yes&quot;</span></span><br><span class="line"></span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sh -c <span class="string">&quot;cat&gt;/etc/ssh/sshd_config&lt;&lt;EOF</span></span><br><span class="line"><span class="string"><span class="variable">$&#123;sshd_config&#125;</span></span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 恢复文件权限</span></span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo <span class="built_in">chmod</span> 644 /etc/ssh/sshd_config</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;已生成新的sshd配置文件！&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在宿主机上生成rsa-2048密钥</span></span><br><span class="line">ssh-keygen -b 2048 -t rsa -f /home/&lt;UserName&gt;/keys/id_rsa_<span class="variable">$1</span> -q -N <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;新密钥已生成！&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 把公钥拷贝到共享目录下</span></span><br><span class="line">sudo <span class="built_in">chmod</span> a+r /home/&lt;UserName&gt;/keys/id_rsa_<span class="variable">$1</span></span><br><span class="line">sudo <span class="built_in">cp</span> /home/&lt;UserName&gt;/keys/id_rsa_<span class="variable">$1</span>.pub /usr/local/shared-folder/keys/id_rsa_<span class="variable">$1</span>.pub</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;公钥已写入共享目录下！&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 把公钥写入.ssh文件夹下</span></span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo <span class="built_in">mkdir</span> /home/ubuntu/.ssh</span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo <span class="built_in">touch</span> /home/ubuntu/.ssh/authorized_keys</span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo <span class="built_in">chmod</span> a+w /home/ubuntu/.ssh/authorized_keys</span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sh -c <span class="string">&quot;sudo cat /usr/local/shared-folder/keys/id_rsa_<span class="variable">$1</span>.pub &gt;&gt; /home/ubuntu/.ssh/authorized_keys&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 恢复.ssh目录的属主和文件权限</span></span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo <span class="built_in">chown</span> -R ubuntu /home/ubuntu/.ssh</span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo <span class="built_in">chmod</span> 700 /home/ubuntu/.ssh</span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo <span class="built_in">chmod</span> 644 /home/ubuntu/.ssh/authorized_keys</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;公钥已写入.ssh文件夹！&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启ssh服务</span></span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo service ssh restart</span><br><span class="line"></span><br><span class="line"><span class="comment"># 端口映射</span></span><br><span class="line">sudo lxc config device add <span class="variable">$1</span> port-ssh proxy listen=tcp:0.0.0.0:<span class="variable">$2</span> connect=tcp:127.0.0.1:<span class="variable">$2</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;容器内的ssh服务和端口配置完成！&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启防火墙</span></span><br><span class="line">sudo ufw allow <span class="variable">$2</span>/tcp</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;防火墙端口<span class="variable">$2</span>已放通！&quot;</span></span><br></pre></td></tr></table></figure><h3 id="管理员PC端添加用户脚本"><a href="#管理员PC端添加用户脚本" class="headerlink" title="管理员PC端添加用户脚本"></a>管理员PC端添加用户脚本</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;用户名是： &quot;</span><span class="variable">$1</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;该用户的ssh端口是： &quot;</span><span class="variable">$2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从远端服务器下载私钥</span></span><br><span class="line">scp -P &lt;PortNumber&gt; &lt;UserName&gt;@&lt;ServerIPAddress&gt;:/home/&lt;UserName&gt;/keys/id_rsa_<span class="variable">$1</span> /home/&lt;LocalUserName&gt;/keys/id_rsa_<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ssh密钥权限是600，切记切记 :)</span></span><br><span class="line">sudo <span class="built_in">chmod</span> 600 /home/&lt;LocalUserName&gt;/keys/id_rsa_<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 尝试连接</span></span><br><span class="line">ssh -i /home/&lt;LocalUserName&gt;/keys/id_rsa_<span class="variable">$1</span> ubuntu@&lt;ServerIPAddress&gt; -p <span class="variable">$2</span></span><br></pre></td></tr></table></figure><h3 id="服务器端删除用户脚本"><a href="#服务器端删除用户脚本" class="headerlink" title="服务器端删除用户脚本"></a>服务器端删除用户脚本</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;即将删除容器 <span class="variable">$1</span> 相关配置，端口号 <span class="variable">$2</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除本地保存的秘钥</span></span><br><span class="line"><span class="built_in">rm</span> /home/&lt;UserName&gt;/keys/id_rsa_<span class="variable">$1</span>*</span><br><span class="line">sudo <span class="built_in">rm</span> /usr/local/shared-folder/keys/id_rsa_<span class="variable">$1</span>*</span><br><span class="line"></span><br><span class="line"><span class="comment"># 暂停容器</span></span><br><span class="line">sudo lxc stop <span class="variable">$1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除容器</span></span><br><span class="line">sudo lxc delete <span class="variable">$1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除防火墙规则</span></span><br><span class="line">sudo ufw delete allow <span class="variable">$2</span>/tcp</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;容器已经删除！&quot;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;使用LXD虚拟化技术为实验室服务器配置多用户隔离运行环境。&lt;/p&gt;</summary>
    
    
    
    <category term="Manuals" scheme="http://xinlu.cool/categories/Manuals/"/>
    
    
    <category term="LXD" scheme="http://xinlu.cool/tags/LXD/"/>
    
    <category term="Netdata" scheme="http://xinlu.cool/tags/Netdata/"/>
    
    <category term="CUDA" scheme="http://xinlu.cool/tags/CUDA/"/>
    
    <category term="Tensorflow" scheme="http://xinlu.cool/tags/Tensorflow/"/>
    
    <category term="Pytorch" scheme="http://xinlu.cool/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>以std::mutex为基础，探索线程间共享数据的方法</title>
    <link href="http://xinlu.cool/Reading-Notes/cppconcurrency-2/"/>
    <id>http://xinlu.cool/Reading-Notes/cppconcurrency-2/</id>
    <published>2020-07-21T04:17:37.000Z</published>
    <updated>2021-07-08T06:27:37.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>多线程编程的优势之一在于线程间共享数据的开销很小。</p><p>“灵活地在线程间共享数据，最大化地利用并发处理优势“，听起来很美好，实际上处处是坑。</p><span id="more"></span><ul><li>多个线程对同一个数据结构的读写操作，如果处理不好，就会出现“脏读”、“幻读”等bug（借用数据库中的概念）；</li><li>使用锁机制来保护共享的数据，如果多个线程分别持有不同的锁，却互相请求对方持有的锁，就会出现“死锁”bug（极难复现调试）；</li><li>锁的粒度设计太大，就无法充分利用多线程并发的速度优势；</li><li>锁的粒度设计太小，出现bug的可能性也随之增加，逼迫程序员付出大量心智成本；</li></ul><p>C++ Concurrency in Action认为，使用多线程共享数据的坑主要有两个：</p><ul><li>problematic race condition</li><li>deadlock</li></ul><p>如何利用C++ STL和boost中的facilities来规避大坑、并且设计出良好的代码结构，是这里讨论的重点。</p><h2 id="Race-Condition"><a href="#Race-Condition" class="headerlink" title="Race Condition"></a>Race Condition</h2><p>如果数据是read-only的，那么多线程操作不会带来任何问题，但如果可读可写，那么多线程读写的顺序就会带来一系列问题（毕竟，不加锁的情况下，没法控制多个并发线程执行顺序），这里就引入了“线程竞态”（race condition）的概念。</p><h3 id="什么是race-condition，它会给多线程编程带来什么？"><a href="#什么是race-condition，它会给多线程编程带来什么？" class="headerlink" title="什么是race condition，它会给多线程编程带来什么？"></a>什么是race condition，它会给多线程编程带来什么？</h3><p>如果多个线程执行同一操作的结果依赖于多个线程的执行顺序（顺序不同，结果不同），那么这就叫race condition。</p><p>race condition并不一定是坏事，多个用户线程的竞争用在抢票系统、抢红包系统上就没有问题。真正有问题的是<strong>problematic race condition</strong>。C++标准中定义的<strong>data race</strong>就是一种problematic race condition，它表示并发地对同一个对象进行修改，这是一个undefined behavior。</p><p>problematic race condition常常发生在一个操作要修改多个数据的情形下。例如，在删除双向链表中的一个元素时，我们需要对三个链表元素（节点a、待删除节点b、节点c）进行操作，那么在删除的过程中，</p><ol><li>必然会先破坏原有数据结构（节点a的后指针指向节点c，但节点c的前指针还指向待删除的节点b），</li><li>然后再恢复数据结构（节点a、c相连，但节点b的前指针和后指针还没变），</li><li>最后进行删除操作（delete 节点b），</li></ol><p>在这一过程中，其他线程可能在删除操作尚未结束时读取到错误的链表数据。</p><h3 id="如何防止problematic-race-condition"><a href="#如何防止problematic-race-condition" class="headerlink" title="如何防止problematic race condition"></a>如何防止problematic race condition</h3><p>C++ Concurrency in Action介绍了三种防止problematic race condition的方法：</p><ol><li>在数据结构外包裹一层保护机制（protection mechanism）</li><li>修改数据结构的接口，让修改操作原子化（indivisible）</li><li>把修改操作当做“事务”（transaction）来处理，实现all-or-nothing的效果</li></ol><p>利用 <code>std::mutex</code> 的相关机制，可以灵活地选用方法1或方法2，来设计出线程安全的数据结构。</p><h3 id="线程安全的list"><a href="#线程安全的list" class="headerlink" title="线程安全的list"></a>线程安全的list</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;list&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line">std::list&lt;<span class="type">int</span>&gt; some_list;</span><br><span class="line">std::mutex some_mutex;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">add_to_list</span><span class="params">(<span class="type">int</span> new_value)</span> </span>&#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">guard</span><span class="params">(some_mutex)</span></span>;</span><br><span class="line">    some_list.<span class="built_in">push_back</span>(new_value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">list_contains</span><span class="params">(<span class="type">int</span> value_to_find)</span> </span>&#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">guard</span><span class="params">(some_mutex)</span></span>;</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">find</span>(some_list.<span class="built_in">begin</span>(), some_list.<span class="built_in">end</span>(), value_to_find) </span><br><span class="line">        != some_list.<span class="built_in">end</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，被保护的数据结构是 <code>some_list</code> ，<code>some_mutex</code> 被用来标识临界区代码。</p><p>如果某个线程对 <code>some_mutex</code> 上锁，那么其他线程只能等待这个线程解锁，否则无法执行 <code>some_mutex</code> 对应的临界区代码。这样就起到了保护 <code>some_list</code> 内数据不被同时读写的效果。</p><p><code>std::lock_guard&lt;&gt;</code> 对象充分利用了RAII的特性，对象初始化后就上锁，对象被析构时自动解锁，不需要程序员来手动lock和unlock。这是一种好的编程习惯，尽可能地解放程序员，把mutex上锁的周期与另一个对象的生命周期绑定。</p><p>因为C++语言的灵活性，<code>std::mutex</code> 的锁机制并不是一劳永逸的，</p><ul><li>如果被保护的数据被指针传递、引用传递到临界区以外后，就不再受到保护，</li><li>如果临界区代码需要调用用户自定义的函数（恶意地取出数据地址），那么 <code>std::mutex</code> 也无法起到保护作用。</li></ul><h3 id="线程安全的stack"><a href="#线程安全的stack" class="headerlink" title="线程安全的stack"></a>线程安全的stack</h3><p>在讨论线程安全的stack前，有必要回顾一下 <code>std::stack</code> 在设计时避开的坑：为什么 <code>.pop()</code> 操作不返回栈顶元素，而需要让用户先调用 <code>.top()</code> 取出栈顶元素，再 <code>.pop()</code> 出栈？</p><p>为了节约篇幅，这里不作讨论，直接放上结论：</p><ul><li>如果 <code>.pop()</code> 操作允许返回栈顶元素的值，那么必然要把该元素的值copy出来，</li><li>那么，<code>auto a = s.pop()</code> 操作实际上分成了两步：<ul><li>修改 <code>s</code> 的数据结构，去掉栈顶元素，</li><li>调用栈顶元素的 <code>copy assignment operator</code> ，给 <code>a</code> 赋值，</li></ul></li><li>大坑在第二步：如果给 <code>a</code> 赋值的操作 <strong>抛出异常</strong> ，那么就会出现 <strong>栈顶元素已经抛出，但是无法返回</strong> 的情形，那么相当于我们白白丢失了栈顶元素（既不在栈里，也不在栈外），而且没有人知道它的值是啥，这个错误甚至是无法补救的，</li><li>为了防止这个大坑，标准库的设计者把出栈操作设计成两步，让用户先读取，后出栈，</li></ul><p>因此，在 <code>std::stack</code> 的基础上设计线程安全的栈，就是要给 <code>.top() + .pop()</code> 套一层保护机制，既要保护多线程读取的安全性、又要考虑拷贝操作的脆弱性。</p><p>比较直观的方法是逼迫用户只使用copy&#x2F;move操作不会抛出异常的类，这种方法局限性比较大。以下两种方法更加自然一些。</p><p><strong>方法一：返回一个 <code>std::shared_ptr&lt;&gt;</code></strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">std::mutex some_mutex;</span><br><span class="line">std::stack&lt;T&gt; data;</span><br><span class="line"></span><br><span class="line"><span class="function">std::shared_ptr&lt;T&gt; <span class="title">pop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">guard</span><span class="params">(some_mutex)</span></span>;</span><br><span class="line">    <span class="keyword">if</span> (data.<span class="built_in">empty</span>()) <span class="keyword">throw</span> <span class="built_in">empty_stack</span>();</span><br><span class="line">    <span class="function">std::shared ptr&lt;T&gt; <span class="type">const</span> <span class="title">res</span><span class="params">(std::make_shared&lt;T&gt;(data.top()))</span></span>;</span><br><span class="line">    data.<span class="built_in">pop</span>();</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种方法相当于避开了“拷贝-销毁”的流程，始终只保留一个对象。</p><p><strong>方法二：引用传递</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">pop</span><span class="params">(T&amp; value)</span> </span>&#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">guard</span><span class="params">(some_mutex)</span></span>;</span><br><span class="line">    <span class="keyword">if</span> (data.<span class="built_in">empty</span>()) <span class="keyword">throw</span> <span class="built_in">empty_stack</span>();</span><br><span class="line">    value = data.<span class="built_in">top</span>();</span><br><span class="line">    data.<span class="built_in">pop</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>引用传递的好处是如果copy过程抛出了异常，那么stack就不会被修改。坏处是用户需要提前构造好一个空对象。</p><h2 id="Dead-Lock"><a href="#Dead-Lock" class="headerlink" title="Dead Lock"></a>Dead Lock</h2><p>死锁是一种非常有趣的bug，多个线程在持有锁的同时互相请求对方持有的锁，程序就卡死在这里。</p><p>这个概念第一次在操作系统中学习到，当时探讨了避免死锁、检测死锁、消除死锁的方法，但是在多线程编程中，最好还是从代码设计上根本性地杜绝死锁的产生，毕竟死锁的debug相当相当困难。</p><h3 id="如何防止代码产生死锁？"><a href="#如何防止代码产生死锁？" class="headerlink" title="如何防止代码产生死锁？"></a>如何防止代码产生死锁？</h3><p>死锁一般产生于一个操作需要对多个mutex上锁的场景。C++ Concurrency in Action给出了四条避免死锁的编程指南：</p><ol><li>不要给已经上锁的部分再加锁，</li><li>上锁后避免调用用户自定义的函数，</li><li>如果需要给多个mutex上锁，那就要保证每次操作时加锁的顺序一致，</li><li>将代码按层次切分，每个层次加不同的锁，确保一个固定的顺序（例如，从高层次锁-&gt;低层次锁，否则报错），</li></ol><p>避免死锁需要类的设计者和类的使用者严格地自律、遵守规则。</p><p>以下探讨如何利用C++ STL和Boost的facilities来设计无死锁的代码。</p><h3 id="线程安全的swap-v1-0"><a href="#线程安全的swap-v1-0" class="headerlink" title="线程安全的swap v1.0"></a>线程安全的swap v1.0</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">friend</span> <span class="type">void</span> <span class="title">swap</span><span class="params">(X&amp; lhs, X&amp; rhs)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (&amp;lhs == &amp;rhs) <span class="keyword">return</span>;</span><br><span class="line">    std::<span class="built_in">lock</span>(lhs.m, rhs.m);</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock_a</span><span class="params">(lhs.m, std::adopt_lock)</span></span>;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock_a</span><span class="params">(rhs.m, std::adopt_lock)</span></span>;</span><br><span class="line">    <span class="built_in">swap</span>(lhs.some_detail, rhs.some_detail);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>std::lock() </code>的上锁操作是原子化的，能同时对多个mutex上锁。</p><p>把 <code>std::adopt_lock</code> 作为参数传入 <code>std::lock_guard&lt;&gt;</code> ，就是告诉 <code>lock_a</code> ， <code>lock_b</code> 只需要获得当前mutex的拥有权，不要再给mutex上锁。</p><p>如果 <code>std::lock()</code> 对任何一个mutex上锁失败，那么已经上锁的部分会被释放，实现all-or-nothing的效果。</p><h3 id="层次锁"><a href="#层次锁" class="headerlink" title="层次锁"></a>层次锁</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">hierarchical_mutex <span class="title">high_level_mutex</span><span class="params">(<span class="number">10000</span>)</span></span>;</span><br><span class="line"><span class="function">hierarchical_mutex <span class="title">low_level_mutex</span><span class="params">(<span class="number">5000</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">do_low_level_stuff</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">low_level_func</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;hierarchical_mutex&gt; <span class="title">lk</span><span class="params">(low_level_mutex)</span></span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">do_low_level_stuff</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">do_high_level_stuff</span><span class="params">(<span class="type">int</span> some_param)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">high_level_func</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;hierarchical_mutex&gt; <span class="title">lk</span><span class="params">(high_level_mutex)</span></span>;</span><br><span class="line">    <span class="built_in">do_high_level_stuff</span>(<span class="built_in">low_level_func</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>把代码分层次，用不同的mutex来控制不同层次的锁。</p><p>当低层次mutex被锁时，高层次mutex不能再上锁，否则在runtime报错。</p><p>10000，5000指的是layer number（第几层），数字越大越先上锁。</p><p>这个 <code>hierarchical_mutex</code> 是自定义的，实现代码比较冗长，这里不展开了。实现的核心是三个变量：</p><ul><li>常量hierarchy_value保存本mutex的层号</li><li>thread_local static变量保存本线程当前运行的层号</li><li>变量previous_hierarchy_value储存本线程之前的层号</li></ul><h3 id="线程安全的swap-v2-0"><a href="#线程安全的swap-v2-0" class="headerlink" title="线程安全的swap v2.0"></a>线程安全的swap v2.0</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">friend</span> <span class="type">void</span> <span class="title">swap</span><span class="params">(X&amp; lhs, X&amp; rhs)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (&amp;lhs == &amp;rhs)<span class="keyword">return</span>;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lock_a</span><span class="params">(lhs.m, std::defer_lock)</span></span>;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lock_b</span><span class="params">(rhs.m, std::defer_lock)</span></span>;</span><br><span class="line">    std::<span class="built_in">lock</span>(lock_a, lock_b);</span><br><span class="line">    <span class="built_in">swap</span>(lhs.some_detail, rhs.some_detail);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>std::unique_lock</code> 可以不拥有mutex（传入 <code>std::defer_lock</code> 参数），只在需要的时候请求对指定的mutex上锁。</p><p>如果 <code>std::unique_lock</code> 拥有mutex，那么析构时unlock，否则，析构时一定不unlock。</p><p><code>std::unique_lock</code> 对mutex的拥有权可以用过 <code>.owns_lock()</code> 来查询。</p><p><code>std::unique_lock</code> 是典型的可movable不可copyable的类，可以灵活使用它的move semantics来转移mutex的所有权，范例如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">get_lock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">extern</span> std::mutex some_mutex;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lk</span><span class="params">(some_mutex)</span></span>;</span><br><span class="line">    <span class="built_in">prepare_data</span>();</span><br><span class="line">    <span class="keyword">return</span> lk;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">process_data</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lk</span><span class="params">(get_lock())</span></span>;</span><br><span class="line">    <span class="built_in">do_something</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>std::unique_lock</code> 支持灵活地lock与unlock操作，例如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">get_and_process_data</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">my_lock</span><span class="params">(the_mutex)</span></span>;</span><br><span class="line">    some_class data_to_process = <span class="built_in">get_next_data_chunk</span>();</span><br><span class="line">    my_lock.<span class="built_in">unlock</span>();</span><br><span class="line">    result_type result = <span class="built_in">process</span>(data_to_process);</span><br><span class="line">    my_lock.<span class="built_in">lock</span>();</span><br><span class="line">    <span class="built_in">write_result</span>(data_to_process, result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="选择合适的锁粒度"><a href="#选择合适的锁粒度" class="headerlink" title="选择合适的锁粒度"></a>选择合适的锁粒度</h2><p>锁的粒度取决于两个因素：</p><ol><li>上锁的时间长短</li><li>对哪些操作上锁</li></ol><p>一般来说，最佳的上锁时长 &#x3D; 完成指定操作的最小时长。</p><p>另外，应该尽可能避免在已经上锁的情况下进行文件IO或者请求另一个锁（耗时过长）；上锁时长必须覆盖整个操作过程，否则就会产生race condition。</p><h2 id="其他保护数据的机制"><a href="#其他保护数据的机制" class="headerlink" title="其他保护数据的机制"></a>其他保护数据的机制</h2><h3 id="线程安全的对象初始化"><a href="#线程安全的对象初始化" class="headerlink" title="线程安全的对象初始化"></a>线程安全的对象初始化</h3><p>有些对象的初始化操作开销很大，需要耗费很长时间，比如数据库的connection初始化。针对这类对象，我们可以把它们设置成lazy initialization的，不需要的时候（离线访问本地缓存）只要维护一个空的 <code>std::shared_ptr&lt;&gt;</code> 指针，需要的时候（连接远程数据库同步）再给它 <code>new</code> 一个新的对象。</p><p>但在多线程编程中，麻烦就来了：</p><ul><li>对象可能还没初始化、也可能正在初始化过程中、也可能刚刚初始化完毕，而其他线程并不知道，</li><li>如果多个线程对同一个指针执行 <code>new</code> 操作，就可能出现 <strong>data race</strong> （undefined behavior），</li><li>如果要把“对象是否已经被初始化or正在被初始化”这个flag信息在多个线程之间同步，就要引入一个线程安全的bool变量，</li></ul><p>C++ 标准考虑到了这一麻烦之处，并提供了 <code>std::once_flag</code> 和 <code>std::call_once</code> 来实现线程安全的对象初始化。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">std::shared_ptr&lt;some_resource&gt; resource_ptr;</span><br><span class="line">std::once_flag resource_flag;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init_resource</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    resource_ptr.<span class="built_in">reset</span>(<span class="keyword">new</span> some_resource);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::<span class="built_in">call_once</span>(resource_flag, init_resource);</span><br><span class="line">    resource_ptr-&gt;<span class="built_in">do_something</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="线程安全的局部静态变量初始化"><a href="#线程安全的局部静态变量初始化" class="headerlink" title="线程安全的局部静态变量初始化"></a>线程安全的局部静态变量初始化</h3><p>局部的static类型变量在C&#x2F;C++语言中是很有意思的存在，当程序第一次执行到变量声明代码时，该变量即被创建，此后一直不销毁。</p><p>但在多线程编程中，这一特性也引来一个棘手之处：如果多个线程并发执行，怎么保证局部static类型变量只被初始化一次？</p><p>许多古老的C++编译器在这一点上都束手无策，幸好，<strong>C++11强制保证了local static variable的初始化是线程安全的</strong> ，当第一个线程开始初始化时，其他线程自动hang住等待，并且保证只会初始化一次。</p><h3 id="共享锁和排它锁"><a href="#共享锁和排它锁" class="headerlink" title="共享锁和排它锁"></a>共享锁和排它锁</h3><p>对象的读和写频率并不一定是相等的，针对读多写少的对象，我们完全可以允许多个线程对它进行并发地“读“，而只允许一个线程对它进行“写”（此时不允许其他线程读or写）。不难看出，这种情况下读写操作的权重是不一样的，我们需要用两种不同的锁来限制并发读写的权限。</p><p>这里就引入了“共享锁”（shared lock）和“排它锁”（exclusive lock）的概念（数据库中第一次学到）：</p><ul><li>如果任何线程持有共享锁，其他线程对排它锁的请求被阻塞，直到所有的共享锁被释放，</li><li>如果任何线程有排它锁，其他线程就不能再请求排它锁or共享锁，直到排它锁被释放，</li></ul><p>C++ STL暂时还没有共享锁的实现，但可以使用boost库中的 <code>boost::shared_lock&lt;boost::shared_mutex&gt;</code>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;boost/thread/shared_mutex.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">dns_entry</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">dns_cache</span> &#123;</span><br><span class="line">    std::map&lt;std::string, dns_entry&gt; entries;</span><br><span class="line">    <span class="keyword">mutable</span> boost::shared_mutex entry_mutex;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">dns_entry <span class="title">find_entry</span><span class="params">(std::string <span class="type">const</span> &amp;domain)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">        <span class="function">boost::shared_lock&lt;boost::shared_mutex&gt; <span class="title">lk</span><span class="params">(entry_mutex)</span></span>;</span><br><span class="line">        std::map&lt;std::string, dns_entry&gt;::const_iterator <span class="type">const</span> it = entries.<span class="built_in">find</span>(domain);</span><br><span class="line">        <span class="keyword">return</span> (it == entries.<span class="built_in">end</span>()) ? <span class="built_in">dns_entry</span>(): it-&gt;second;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">update_or_add_entry</span><span class="params">(std::string <span class="type">const</span> &amp;domain, dns_entry <span class="type">const</span> &amp;dns_details)</span> </span>&#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;boost::shared_mutex&gt; <span class="title">lk</span><span class="params">(entry_mutex)</span></span>;</span><br><span class="line">        entries[domain] = dns_details;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>在以上代码中，</p><ul><li><code>boost::shared_lock&lt;boost::shared_mutex&gt;</code> 实现了对共享锁的加锁，</li><li><code>std::lock_guard&lt;boost::shared_mutex&gt;</code> 实现了对排它锁的加锁。</li></ul><h3 id="可重入的mutex"><a href="#可重入的mutex" class="headerlink" title="可重入的mutex"></a>可重入的mutex</h3><p>C++ STL提供了 <code>std::recursive_mutex</code> ，支持一个线程对它上n次锁，但该线程必须释放n次锁后，其他线程才能对它上锁。</p><p>尽可能不要使用可重入的mutex，这是一种糟糕的设计。</p><h2 id="总结与思考：关于lock-guard和unique-lock"><a href="#总结与思考：关于lock-guard和unique-lock" class="headerlink" title="总结与思考：关于lock_guard和unique_lock"></a>总结与思考：关于lock_guard和unique_lock</h2><p>为了厘清一些叙述上的模糊，有必要再把一些概念拎出来说清楚，以下是我自己的理解。</p><p><strong>为什么要使用它们？</strong></p><p>mutex提供了lock和unlock的操作，程序员的确可以直接对mutex加锁，但是在复杂代码中，unlock操作需要考虑很多情况（异常处理等），使用lock_guard和unique_lock将unlock的控制权交给了析构函数，解放了程序员。</p><p><strong>它们如何与某个mutex绑定？</strong></p><p>lock_guard和unique_lock在初始化时，就与参数中传入的mutex相互绑定（associated）。</p><p><strong>它们如何获得某个mutex的所有权？</strong></p><ul><li><p>对lock_guard来说，在初始化时就获得了mutex的所有权；</p></li><li><p>对unique_lock来说，</p><ul><li>如果初始化时不传入其他参数，即获得mutex的所有权，</li><li>如果初始化时传入 <code>std::defer_lock</code> ，那么只相互绑定，不获取所有权，</li></ul></li></ul><p><strong>它们如何对绑定的mutex加锁？</strong></p><ul><li>对lock_guard来说，有两种加锁方式，<ul><li>先使用 <code>std::lock()</code> 或其他方式加锁，然后初始化lock_guard对象，并传入额外参数 <code>std::adopt_lock</code> 表示只获取所有权，不重复加锁，</li><li>在初始化时不传入额外参数，直接绑定+获取所有权+加锁，</li></ul></li><li>对unique_lock来说，也有两种加锁方式，<ul><li>在初始化时不传入额外参数，直接绑定+获取所有权+加锁，</li><li>在初始化时传入额外参数 <code>std::defer_lock</code> ，表示只相互绑定，不获取所有权，不加锁，之后再使用 <code>std::lock()</code> 或者 <code>.lock()</code> 方法进行加锁（加锁的同时也获得了所有权），</li></ul></li></ul><p><strong>它们如何对绑定的mutex解锁？</strong></p><ul><li>对lock_guard来说，析构时自动对拥有的mutex解锁，</li><li>对unique_lock来说，<ul><li>析构时，如果unique_lock拥有mutex的所有权，那么自动解锁，</li><li>析构时，如果unique_lock不拥有mutex的所有权，那么不解锁，</li><li>程序员可以手动对已经上锁的unique_lock调用 <code>.unlock()</code> ，调用完后解锁+丧失所有权。</li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;多线程编程的优势之一在于线程间共享数据的开销很小。&lt;/p&gt;
&lt;p&gt;“灵活地在线程间共享数据，最大化地利用并发处理优势“，听起来很美好，实际上处处是坑。&lt;/p&gt;</summary>
    
    
    
    <category term="Reading Notes" scheme="http://xinlu.cool/categories/Reading-Notes/"/>
    
    
    <category term="C++" scheme="http://xinlu.cool/tags/C/"/>
    
    <category term="Concurrency" scheme="http://xinlu.cool/tags/Concurrency/"/>
    
    <category term="C++ Concurrency in Action" scheme="http://xinlu.cool/tags/C-Concurrency-in-Action/"/>
    
  </entry>
  
  <entry>
    <title>调包侠工具箱：tf.data.Dataset</title>
    <link href="http://xinlu.cool/API-References/tf-data-Dataset/"/>
    <id>http://xinlu.cool/API-References/tf-data-Dataset/</id>
    <published>2020-06-29T07:36:29.000Z</published>
    <updated>2021-03-24T05:55:53.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="这是个啥？"><a href="#这是个啥？" class="headerlink" title="这是个啥？"></a>这是个啥？</h2><ul><li>tf.data.Dataset包含数据集导入、预处理、导出的高级api</li><li>适用于数据量可以分批导入内存的场景</li><li>可以通过简单的api实现流水线处理</li><li><strong>这货本质是个封装程度非常高的IO Adapter</strong></li></ul><span id="more"></span><h2 id="Dataset创建"><a href="#Dataset创建" class="headerlink" title="Dataset创建"></a>Dataset创建</h2><h3 id="与导入操作有关的api"><a href="#与导入操作有关的api" class="headerlink" title="与导入操作有关的api"></a>与导入操作有关的api</h3><ul><li>从<code>python list</code>导入</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset = tf.data.Dataset.from_tensor_slices([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><ul><li>从<code>txt</code>文件导入</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dataset = tf.data.TextLineDataset([</span><br><span class="line">  <span class="string">&quot;file1.txt&quot;</span>, </span><br><span class="line">  <span class="string">&quot;file2.txt&quot;</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure><ul><li>从<code>TFRecord</code>导入</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dataset = tf.data.TFRecordDataset([</span><br><span class="line">    <span class="string">&quot;file1.tfrecords&quot;</span>, </span><br><span class="line">    <span class="string">&quot;file2.tfrecords&quot;</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure><ul><li>从多文件导入（正则表达式）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset = tf.data.Dataset.list_files(<span class="string">&quot;/path/*.txt&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li>其他导入方式<ul><li><code>tf.data.FixedLengthRecordDataset</code></li><li><code>tf.data.Dataset.from_generator</code></li></ul></li></ul><h3 id="一些优雅的导入姿势"><a href="#一些优雅的导入姿势" class="headerlink" title="一些优雅的导入姿势"></a>一些优雅的导入姿势</h3><ul><li>导入一个tuple</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Slicing a tuple of 1D tensors produces tuple elements containing scalar tensors.</span></span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices((</span><br><span class="line">  [<span class="number">1</span>, <span class="number">2</span>], </span><br><span class="line">  [<span class="number">3</span>, <span class="number">4</span>], </span><br><span class="line">  [<span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">))</span><br><span class="line"><span class="built_in">list</span>(dataset.as_numpy_iterator())</span><br><span class="line"><span class="comment"># [(1, 3, 5), (2, 4, 6)]</span></span><br></pre></td></tr></table></figure><ul><li>导入两个tuple</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Two tensors can be combined into one Dataset object.</span></span><br><span class="line">features = tf.constant([[<span class="number">1</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">1</span>], [<span class="number">3</span>, <span class="number">3</span>]]) <span class="comment"># ==&gt; 3x2 tensor</span></span><br><span class="line">labels = tf.constant([<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;A&#x27;</span>]) <span class="comment"># ==&gt; 3x1 tensor</span></span><br><span class="line">dataset = Dataset.from_tensor_slices((features, labels))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Both the features and the labels tensors can be converted</span></span><br><span class="line"><span class="comment"># to a Dataset object separately and combined after.</span></span><br><span class="line">features_dataset = Dataset.from_tensor_slices(features)</span><br><span class="line">labels_dataset = Dataset.from_tensor_slices(labels)</span><br><span class="line">dataset = Dataset.<span class="built_in">zip</span>((features_dataset, labels_dataset))</span><br></pre></td></tr></table></figure><h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><h3 id="Dataset级别的api"><a href="#Dataset级别的api" class="headerlink" title="Dataset级别的api"></a>Dataset级别的api</h3><ul><li><code>.apply()</code><ul><li><p>Args:</p><ul><li>transformation func, from Dataset to Dataset</li></ul></li><li><p>Rets:</p><ul><li>a new Dataset</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dataset_fn</span>(<span class="params">ds</span>):</span><br><span class="line">  <span class="keyword">return</span> ds.<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x &lt; <span class="number">5</span>)</span><br><span class="line">dataset = dataset.apply(dataset_fn)</span><br></pre></td></tr></table></figure><ul><li><code>.batch()</code><ul><li>Args:<ul><li>batch_size</li><li>drop_remainder&#x3D;False</li></ul></li><li>新Dataset输出的数据新增一个维度，大小为batch_size</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset = dataset.batch(<span class="number">3</span>, drop_remainder=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><ul><li><code>.shard()</code><ul><li>Args:<ul><li>num_shards</li><li>index</li></ul></li><li>Rets:<ul><li>一个新的Dataset，只包含原Dataset的<code>1/num_shards</code>数据，而且数据在原Dataset中的下标<code>% num_shards = index</code></li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset_B = dataset_A.shard(num_shards=<span class="number">3</span>, index=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><ul><li><code>.concatenate()</code><ul><li>Args:<ul><li>another Dataset</li></ul></li><li>Rets:<ul><li>a new Dataset</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">4</span>)  <span class="comment"># ==&gt; [ 1, 2, 3 ]</span></span><br><span class="line">b = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">4</span>, <span class="number">8</span>)  <span class="comment"># ==&gt; [ 4, 5, 6, 7 ]</span></span><br><span class="line">ds = a.concatenate(b)</span><br><span class="line"><span class="comment"># ==&gt; [ 1, 2, 3, 4, 5, 6, 7 ]</span></span><br></pre></td></tr></table></figure><ul><li><code>Dataset.zip()</code><ul><li>Args:<ul><li>(Dataset, Dataset, …)</li></ul></li><li>Rets:<ul><li>a new Dataset</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">4</span>)  <span class="comment"># ==&gt; [ 1, 2, 3 ]</span></span><br><span class="line">b = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">4</span>, <span class="number">7</span>)  <span class="comment"># ==&gt; [ 4, 5, 6 ]</span></span><br><span class="line">ds = tf.data.Dataset.<span class="built_in">zip</span>((a, b))</span><br><span class="line"><span class="comment"># ==&gt; [(1, 4), (2, 5), (3, 6)]</span></span><br></pre></td></tr></table></figure><h3 id="字段级别的api"><a href="#字段级别的api" class="headerlink" title="字段级别的api"></a>字段级别的api</h3><ul><li><code>.filter()</code><ul><li>Args:<ul><li>predicate(func)</li></ul></li><li>Rets:<ul><li>a new Dataset, element by predicate is True</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset = dataset.<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x &lt; <span class="number">3</span>)</span><br></pre></td></tr></table></figure><ul><li><code>.map()</code><ul><li>Args:<ul><li>map_func</li><li>num_parallel_calls(&#x3D;<code>tf.data.experimental.AUTOTUNE</code>)</li><li>deterministic</li></ul></li><li>Rets:<ul><li>a new Dataset</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset = Dataset.<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>)  <span class="comment"># ==&gt; [ 1, 2, 3, 4, 5 ]</span></span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x + <span class="number">1</span>)</span><br></pre></td></tr></table></figure><ul><li><code>interleave()</code><ul><li>Args:<ul><li>map_func</li><li>cycle_length&#x3D;AUTOTUNE</li><li>block_length&#x3D;1</li><li>num_parallel_calls(&#x3D;<code>tf.data.experimental.AUTOTUNE</code>)</li><li>deterministic&#x3D;None</li></ul></li><li>Rets:<ul><li>a new Dataset</li></ul></li></ul></li></ul><p>如何理解：</p><ol><li>遍历原Dataset，用<code>map_func</code>函数处理每个字段，该过程并行度由<code>cycle_length</code>控制</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设cycle_length = 3</span></span><br><span class="line">[map_func(x1), map_func(x2), map_func(x3)] </span><br><span class="line">  =&gt; [res1, res2, res3] </span><br><span class="line">  =&gt; cycle1</span><br><span class="line"></span><br><span class="line">[map_func(x4), map_func(x5), map_func(x6)] </span><br><span class="line">  =&gt; [res4, res5, res6] </span><br><span class="line">  =&gt; cycle2</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">==&gt; cycles = [cycle1, cycle2, cycle3, ...]</span><br></pre></td></tr></table></figure><ol start="2"><li>遍历cycles，取每个cycle的<code>block_length</code>个元素后，换下一个cycle继续读取，环形遍历直到所有元素都被取出</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设block_length = 2</span></span><br><span class="line"></span><br><span class="line">cycle1 =&gt; [res1, res2]</span><br><span class="line">cycle2 =&gt; [res4, res5]</span><br><span class="line"></span><br><span class="line">cycle1 =&gt; [res3]</span><br><span class="line">cycle2 =&gt; [res6]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终结果被flatten</span></span><br><span class="line">==&gt; [res1, res2, res4, res5, res3, res6]</span><br></pre></td></tr></table></figure><ol start="3"><li>最终获得flatten后的新Dataset</li></ol><h2 id="Dataset导出"><a href="#Dataset导出" class="headerlink" title="Dataset导出"></a>Dataset导出</h2><ul><li><code>.prefetch()</code><ul><li>Args:<ul><li>buffer_size</li></ul></li><li>Rets:<ul><li>a new Dataset</li></ul></li></ul></li></ul><p>官方建议在所有Dataset的处理结束后加上<code>.prefetch()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预取两个字段</span></span><br><span class="line">dataset = dataset.prefetch(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预取两个batch</span></span><br><span class="line">dataset = dataset.batch(<span class="number">20</span>).prefetch(<span class="number">2</span>)</span><br></pre></td></tr></table></figure><ul><li><code>.shuffle()</code><ul><li>Args:<ul><li>buffer_size</li><li>seed&#x3D;None</li><li>reshuffle_each_iteration&#x3D;None</li></ul></li><li>Rets:<ul><li>a new Dataset</li></ul></li></ul></li></ul><p>官方建议<code>buffer_size</code> &gt;&#x3D; Dataset数据量</p><ul><li><code>.enumerate()</code><ul><li>Args:<ul><li>start&#x3D;0</li></ul></li><li>Rets:<ul><li>a new Dataset，每个输出结果多了一个表示索引的维度</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">dataset = tf.data.Dataset.from_tensor_slices([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">dataset = dataset.<span class="built_in">enumerate</span>(start=<span class="number">5</span>)</span><br><span class="line"><span class="keyword">for</span> element <span class="keyword">in</span> dataset.as_numpy_iterator():</span><br><span class="line">  <span class="built_in">print</span>(element)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(5, 1)</span></span><br><span class="line"><span class="string">(6, 2)</span></span><br><span class="line"><span class="string">(7, 3)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><ul><li><code>.as_numpy_iterator()</code><ul><li>Rets:<ul><li>a new Dataset</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dataset = tf.data.Dataset.from_tensor_slices([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="keyword">for</span> element <span class="keyword">in</span> dataset.as_numpy_iterator():</span><br><span class="line">  <span class="built_in">print</span>(element)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">1</span></span><br><span class="line"><span class="string">2</span></span><br><span class="line"><span class="string">3</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;这是个啥？&quot;&gt;&lt;a href=&quot;#这是个啥？&quot; class=&quot;headerlink&quot; title=&quot;这是个啥？&quot;&gt;&lt;/a&gt;这是个啥？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;tf.data.Dataset包含数据集导入、预处理、导出的高级api&lt;/li&gt;
&lt;li&gt;适用于数据量可以分批导入内存的场景&lt;/li&gt;
&lt;li&gt;可以通过简单的api实现流水线处理&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;这货本质是个封装程度非常高的IO Adapter&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="API References" scheme="http://xinlu.cool/categories/API-References/"/>
    
    
    <category term="Machine Learning" scheme="http://xinlu.cool/tags/Machine-Learning/"/>
    
    <category term="TensorFlow" scheme="http://xinlu.cool/tags/TensorFlow/"/>
    
    <category term="Keras" scheme="http://xinlu.cool/tags/Keras/"/>
    
  </entry>
  
  <entry>
    <title>C++并发：从std::thread()开始</title>
    <link href="http://xinlu.cool/Reading-Notes/cppconcurrency-1/"/>
    <id>http://xinlu.cool/Reading-Notes/cppconcurrency-1/</id>
    <published>2020-06-19T20:43:36.000Z</published>
    <updated>2020-06-30T16:48:23.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="lt-thread-gt-头文件的作用"><a href="#lt-thread-gt-头文件的作用" class="headerlink" title="&lt;thread&gt;头文件的作用"></a><code>&lt;thread&gt;</code>头文件的作用</h2><p><code>&lt;thread&gt;</code>  是C++11新引入标准库基础设施，提供对多线程操作的支持。</p><p>我们可以用 <code>std::thread</code> 来控制线程的创建、运行、回收。</p><p>学习 <code>std::thread</code> 的用法是了解C++多线程编程的第一步。</p><span id="more"></span><h2 id="构造std-thread对象"><a href="#构造std-thread对象" class="headerlink" title="构造std::thread对象"></a>构造<code>std::thread</code>对象</h2><ul><li>方法一：传入函数对象</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">background_task</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">        <span class="built_in">do_something</span>();</span><br><span class="line">        <span class="built_in">do_something_else</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">background_task f;</span><br><span class="line"><span class="function">std::thread <span class="title">my_thread</span><span class="params">(f)</span></span>;</span><br></pre></td></tr></table></figure><p><strong>在这种情况下，函数对象先被 <code>copy</code> 到 <code>std::thread</code> 对象的内部，然后再传参、被调用</strong></p><ul><li>方法二：传入lambda表达式（也是callable对象）</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::thread <span class="title">my_thread</span><span class="params">([]&#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    do_something();</span></span></span><br><span class="line"><span class="params"><span class="function">    do_something_else();</span></span></span><br><span class="line"><span class="params"><span class="function">&#125;)</span></span></span><br></pre></td></tr></table></figure><ul><li>方法三：传入函数指针和参数</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">f</span><span class="params">(<span class="type">int</span> i)</span></span>;</span><br><span class="line">std::<span class="built_in">thread</span>(f, <span class="number">3</span>);</span><br></pre></td></tr></table></figure><ul><li>方法四：传入对象的成员函数</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">X</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">do_lengthy_work</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">X my_x;</span><br><span class="line"><span class="function">std::thread <span class="title">t</span><span class="params">(&amp;X::do_lengthy_work, &amp;my_x)</span></span>;<span class="comment">// 后面可以加上一系列参数，如果需要的话</span></span><br></pre></td></tr></table></figure><h2 id="std-thread成员函数"><a href="#std-thread成员函数" class="headerlink" title="std::thread成员函数"></a><code>std::thread</code>成员函数</h2><h3 id="join"><a href="#join" class="headerlink" title=".join()"></a><code>.join()</code></h3><p><strong>作用：</strong></p><ul><li>等待线程执行完毕</li><li>清除对象内部与具体线程相关的内存，当前对象将不再和任何线程相关联</li><li>只能调用一次 <code>.join()</code> ，调用后 <code>.joinable()</code> 将永远返回 <code>false</code></li></ul><p><strong>例子：</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (t.<span class="built_in">joinable</span>()) &#123;</span><br><span class="line">    t.<span class="built_in">join</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="detach"><a href="#detach" class="headerlink" title=".detach()"></a><code>.detach()</code></h3><p><strong>作用：</strong></p><ul><li>把线程放在后台运行，线程的所有权和控制权交给 <code>C++ Runtime Library</code></li><li>当前对象将不再和任何线程相关联</li><li>调用后 <code>.joinable()</code> 将永远返回 <code>false</code></li></ul><h2 id="thread-function传参可能遇到的问题"><a href="#thread-function传参可能遇到的问题" class="headerlink" title="thread function传参可能遇到的问题"></a>thread function传参可能遇到的问题</h2><h3 id="问题一：传入临时的callable对象，编译器会误以为是函数声明"><a href="#问题一：传入临时的callable对象，编译器会误以为是函数声明" class="headerlink" title="问题一：传入临时的callable对象，编译器会误以为是函数声明"></a>问题一：传入临时的callable对象，编译器会误以为是函数声明</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Wrong</span></span><br><span class="line"><span class="function">std::thread <span class="title">my_thread</span><span class="params">(background_task())</span></span></span><br></pre></td></tr></table></figure><p><strong>解决方案：</strong>用圆括号或者花括号加以说明</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Correct</span></span><br><span class="line"><span class="function">std::thread <span class="title">my_thread</span><span class="params">((background_task()))</span></span>;</span><br><span class="line">std::thread my_thread&#123;<span class="built_in">background_task</span>()&#125;;</span><br></pre></td></tr></table></figure><h3 id="问题二：因为传指针or局部变量的引用，导致thread-function可能访问已经被销毁的内容"><a href="#问题二：因为传指针or局部变量的引用，导致thread-function可能访问已经被销毁的内容" class="headerlink" title="问题二：因为传指针or局部变量的引用，导致thread function可能访问已经被销毁的内容"></a>问题二：因为传指针or局部变量的引用，导致thread function可能访问已经被销毁的内容</h3><p><strong>解决方案：</strong></p><ul><li>把需要使用的临时变量<code>copy</code>到<code>std::thread</code>内部，不要和局部上下文共享临时变量</li><li>使用<code>RAII</code>（资源获取即初始化）</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">thread_guard</span> &#123;</span><br><span class="line">    std::thread &amp;t;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// Constructor</span></span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">thread_guard</span><span class="params">(std::thread &amp;t_)</span>: t(t_) &#123;</span>&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Destructor</span></span><br><span class="line">    ~<span class="built_in">thread_guard</span>() &#123;</span><br><span class="line">        <span class="keyword">if</span> (t.<span class="built_in">joinable</span>()) &#123;</span><br><span class="line">            t.<span class="built_in">join</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Copy Constructor</span></span><br><span class="line">    <span class="built_in">thread_guard</span>(<span class="type">const</span> thread_guard &amp;) = <span class="keyword">delete</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Copy-assignment Operator</span></span><br><span class="line">    thread_guard&amp; <span class="keyword">operator</span>=(<span class="type">const</span> thread_guard &amp;) = <span class="keyword">delete</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">func</span>; <span class="comment">// a callable object</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> f &#123;</span><br><span class="line">    <span class="type">int</span> some_local_stats = <span class="number">0</span>;</span><br><span class="line">    <span class="function">func <span class="title">my_func</span><span class="params">(some_local_stats)</span></span>;</span><br><span class="line">    <span class="function">std::thread <span class="title">t</span><span class="params">(my_func)</span></span>;</span><br><span class="line">    <span class="function">thread_guard <span class="title">g</span><span class="params">(t)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">do_something_in_current_thread</span>();<span class="comment">// 函数返回时，自动调用thread_guard的析构函数，等待线程join</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="问题三：因为传指针or局部变量的引用，导致在thread-function入参时因强制类型转换而访问已经被销毁的内容"><a href="#问题三：因为传指针or局部变量的引用，导致在thread-function入参时因强制类型转换而访问已经被销毁的内容" class="headerlink" title="问题三：因为传指针or局部变量的引用，导致在thread function入参时因强制类型转换而访问已经被销毁的内容"></a>问题三：因为传指针or局部变量的引用，导致在thread function入参时因强制类型转换而访问已经被销毁的内容</h3><p>理解这个问题之前，需要先梳理一下 <code>std::thread</code> 对象创建后发生了什么：</p><ol><li>原线程：调用 <code>std::thread</code> 的构造函数or拷贝赋值运算符</li><li>原线程：一个callable对象和它的参数被拷贝到新创建的 <code>std::thread</code> 内部</li><li>新线程：之前被拷贝的一系列参数，现在被传入callable对象（发生强制类型转换）</li><li>新线程：调用callable对象</li><li>……</li></ol><p>其中，第3步发生在新线程内，我们只知道它发生在第2步之后，却不知道具体的发生时间。</p><p>如果第3步发生时，原线程已经退出了相关上下文，那么新线程在传参时，可能对已经被销毁的内容进行类型转换操作。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">f</span><span class="params">(<span class="type">int</span> i, <span class="type">const</span> std::string &amp;s)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">oops</span><span class="params">(<span class="type">int</span> some_param)</span> </span>&#123;</span><br><span class="line">    <span class="type">char</span> buffer[<span class="number">1024</span>];</span><br><span class="line">    <span class="built_in">sprintf</span>(buffer, <span class="string">&quot;%i&quot;</span>, some_param);</span><br><span class="line">    <span class="function">std::thread <span class="title">t</span><span class="params">(f, <span class="number">3</span>, buffer)</span></span>;<span class="comment">// const char*类型的buffer被转换成std::string的时机是未知的</span></span><br><span class="line">    t.<span class="built_in">detach</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>解决方案：</strong>由程序员显式完成传参操作，避免出现类型转换</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">not_oops</span><span class="params">(<span class="type">int</span> some_param)</span> </span>&#123;</span><br><span class="line">    <span class="type">char</span> buffer[<span class="number">1024</span>];</span><br><span class="line">    <span class="built_in">sprintf</span>(buffer, <span class="string">&quot;%i&quot;</span>, some_param);</span><br><span class="line">    <span class="function">std::thread <span class="title">t</span><span class="params">(f, <span class="number">3</span>, std::string(buffer))</span></span>;<span class="comment">// 避免类型转换</span></span><br><span class="line">    t.<span class="built_in">detach</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="问题四：callable对象的参数要求传引用，但实际传入的是内部拷贝对象的引用（无法对原来的对象进行修改）"><a href="#问题四：callable对象的参数要求传引用，但实际传入的是内部拷贝对象的引用（无法对原来的对象进行修改）" class="headerlink" title="问题四：callable对象的参数要求传引用，但实际传入的是内部拷贝对象的引用（无法对原来的对象进行修改）"></a>问题四：callable对象的参数要求传引用，但实际传入的是内部拷贝对象的引用（无法对原来的对象进行修改）</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">update_data_for_widget</span><span class="params">(widget_id w, widget_data &amp;data)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">oops_again</span><span class="params">(widget_id w)</span> </span>&#123;</span><br><span class="line">    widget_data data;</span><br><span class="line">    <span class="function">std::thread <span class="title">t</span><span class="params">(update_data_for_widget, w, data)</span></span>;<span class="comment">// 传入的data被拷贝，拷贝后的临时data的引用被传入update函数</span></span><br><span class="line">    <span class="built_in">display_status</span>();</span><br><span class="line">    t.<span class="built_in">join</span>();</span><br><span class="line">    <span class="built_in">process_widget_data</span>(data);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>解决方案：</strong>使用 <code>std::ref()</code> 声明传引用</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::thread <span class="title">t</span><span class="params">(update_data_for_widget, w, std::ref(data))</span></span>;</span><br></pre></td></tr></table></figure><h2 id="使用上的技巧"><a href="#使用上的技巧" class="headerlink" title="使用上的技巧"></a>使用上的技巧</h2><h3 id="Trick-1：传入只可move不可copy的对象"><a href="#Trick-1：传入只可move不可copy的对象" class="headerlink" title="Trick 1：传入只可move不可copy的对象"></a>Trick 1：传入只可move不可copy的对象</h3><p>在这种情况下，如果原对象是无名的临时对象，那么 <code>move</code> 操作是自动完成的。</p><p>如果原对象是命名对象（左值引用），那就需要用 <code>std::move()</code> 来将它转换成（右值引用），之后的的拷贝就自动是 <code>move</code> 完成的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">process_big_object</span><span class="params">(std::unique_ptr&lt;big_object&gt;)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">std::unique_ptr&lt;big_object&gt; <span class="title">p</span><span class="params">(<span class="keyword">new</span> big_object)</span></span>;<span class="comment">// std::unique_ptr是典型的不可copy只能move对象，std::thread也是</span></span><br><span class="line">p-&gt;<span class="built_in">prepare_data</span>(<span class="number">42</span>);</span><br><span class="line"><span class="function">std::thread <span class="title">t</span><span class="params">(process_big_object, std::move(p))</span></span>;</span><br></pre></td></tr></table></figure><h3 id="Trick-2：std-thread的move操作"><a href="#Trick-2：std-thread的move操作" class="headerlink" title="Trick 2：std::thread的move操作"></a>Trick 2：<code>std::thread</code>的move操作</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">some_function</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">some_other_function</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function">std::thread <span class="title">t1</span><span class="params">(some_function)</span></span>;<span class="comment">// constructor</span></span><br><span class="line">std::thread t2 = std::<span class="built_in">move</span>(t1);<span class="comment">// move-assignment operator</span></span><br><span class="line">t1 = std::<span class="built_in">thread</span>(some_other_function);<span class="comment">// constructor, then move-assignment operator</span></span><br><span class="line">std::thread t3;<span class="comment">// default constructor</span></span><br><span class="line">t3 = std::<span class="built_in">move</span>(t2);<span class="comment">// move-assignment operator</span></span><br><span class="line">t1 = std::<span class="built_in">move</span>(t3);<span class="comment">// Error: std::terminate()</span></span><br></pre></td></tr></table></figure><p>上述程序的最后一行中，对象t1已经与一个正在运行的线程互相绑定，不能接受<code>move</code>的对象，因此整个程序会调用 <code>std::terminate()</code> 退出。</p><p>不能 <code>move</code> 给已经绑定了线程的对象。</p><h3 id="Trick-3：在函数传参和返回时使用转移std-thread的所有权"><a href="#Trick-3：在函数传参和返回时使用转移std-thread的所有权" class="headerlink" title="Trick 3：在函数传参和返回时使用转移std::thread的所有权"></a>Trick 3：在函数传参和返回时使用转移<code>std::thread</code>的所有权</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::thread <span class="title">f</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">some_function</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">thread</span>(some_function);<span class="comment">// 自动调用move</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">std::thread <span class="title">g</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">some_other_function</span><span class="params">(<span class="type">int</span>)</span></span>;</span><br><span class="line">    <span class="function">std::thread <span class="title">t</span><span class="params">(some_other_function, <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="keyword">return</span> t;<span class="comment">// 自动调用move</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">f</span><span class="params">(std::thread t)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">g</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">some_function</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="built_in">f</span>(std::<span class="built_in">thread</span>(some_function));<span class="comment">// 自动调用move</span></span><br><span class="line">    <span class="function">std::thread <span class="title">t</span><span class="params">(some_function)</span></span>;</span><br><span class="line">    <span class="built_in">f</span>(std::<span class="built_in">move</span>(t));<span class="comment">// 显式调用move</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Trick-4：运行时确定新开线程的个数"><a href="#Trick-4：运行时确定新开线程的个数" class="headerlink" title="Trick 4：运行时确定新开线程的个数"></a>Trick 4：运行时确定新开线程的个数</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">unsigned</span> <span class="type">long</span> hardware_threads = std::thread::<span class="built_in">hardware_concurrency</span>();</span><br></pre></td></tr></table></figure><h3 id="Trick-5：获取线程id"><a href="#Trick-5：获取线程id" class="headerlink" title="Trick 5：获取线程id"></a>Trick 5：获取线程id</h3><p>线程id有个单独定义的类型，<code>std::thread::id</code> ，该类对象有如下性质：</p><ul><li>调用 <code>std::thread</code> 对象的 <code>get_id()</code> 方法可以得到一个 <code>std::thread::id</code> 类型对象</li><li><code>std::thread::id</code> 支持大小比较和相等判断，<ul><li>相等即为同一线程</li><li>若a&lt;b，b&lt;c，那么a&lt;c</li></ul></li><li>如果当前对象不与任何正在运行的线程绑定，那么 <code>get_id()</code> 返回一个默认构造的 <code>std::thread::id</code> 对象</li><li><code>get_id()</code> 可以被 <code>std::cout</code> 打印出来，但它的值没有任何具体意义，标准库也不对它的具体实现类型作保证</li></ul><h2 id="参考来源"><a href="#参考来源" class="headerlink" title="参考来源"></a>参考来源</h2><ul><li>C++ Concurrency in Action, 2nd Edition</li></ul>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;lt-thread-gt-头文件的作用&quot;&gt;&lt;a href=&quot;#lt-thread-gt-头文件的作用&quot; class=&quot;headerlink&quot; title=&quot;&amp;lt;thread&amp;gt;头文件的作用&quot;&gt;&lt;/a&gt;&lt;code&gt;&amp;lt;thread&amp;gt;&lt;/code&gt;头文件的作用&lt;/h2&gt;&lt;p&gt;&lt;code&gt;&amp;lt;thread&amp;gt;&lt;/code&gt;  是C++11新引入标准库基础设施，提供对多线程操作的支持。&lt;/p&gt;
&lt;p&gt;我们可以用 &lt;code&gt;std::thread&lt;/code&gt; 来控制线程的创建、运行、回收。&lt;/p&gt;
&lt;p&gt;学习 &lt;code&gt;std::thread&lt;/code&gt; 的用法是了解C++多线程编程的第一步。&lt;/p&gt;</summary>
    
    
    
    <category term="Reading Notes" scheme="http://xinlu.cool/categories/Reading-Notes/"/>
    
    
    <category term="C++" scheme="http://xinlu.cool/tags/C/"/>
    
    <category term="Concurrency" scheme="http://xinlu.cool/tags/Concurrency/"/>
    
    <category term="C++ Concurrency in Action" scheme="http://xinlu.cool/tags/C-Concurrency-in-Action/"/>
    
  </entry>
  
</feed>
