<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>xinlu&#39;s blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://xinlu.cool/"/>
  <updated>2021-04-25T03:51:26.486Z</updated>
  <id>http://xinlu.cool/</id>
  
  <author>
    <name>xinlu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>zkLedger Privacy-Preserving Auditing for Distributed Ledger论文摘要</title>
    <link href="http://xinlu.cool/Papers/paper-zkledger/"/>
    <id>http://xinlu.cool/Papers/paper-zkledger/</id>
    <published>2021-04-25T03:37:21.000Z</published>
    <updated>2021-04-25T03:51:26.486Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h2><div class="table-container"><table><thead><tr><th>会议/期刊</th><th>NSDI</th></tr></thead><tbody><tr><td>年份</td><td>2018</td></tr><tr><td>机构</td><td>MIT Media Lab</td></tr><tr><td>一作</td><td>Neha Narula</td></tr><tr><td>领域</td><td>Blockchain，Zero Knowledge Proof，Auditing</td></tr></tbody></table></div><h2 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h2><p>本文提出了一种<a href="https://www.usenix.org/conference/nsdi18/presentation/narula">支持对链上密文数据进行实时审计的区块链系统zkledger</a>。zkledger上记录着多个银行间进行场外交易的交易记录，链上记录的交易内容是加密的。通过zkledger提出的审计协议，审计方可以实时地对任意银行进行质询，以验证银行间的交易行为符合监管当局的规定和法律要求。zkledger的证明机制确保银行无法向审计方撒谎，也无法合谋转移资产。</p><a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="为什么要用区块链平台做审计？"><a href="#为什么要用区块链平台做审计？" class="headerlink" title="为什么要用区块链平台做审计？"></a>为什么要用区块链平台做审计？</h3><p>传统审计方式的缺点：</p><ul><li>劳累、耗时，而且监管方没有办法实时地获取信息</li><li>审计方可能出错，造成巨大损失</li></ul><p>区块链审计的优点：</p><ul><li>减少验证（审计方的人力消耗）和协调（审计方和被审计方的交互）的开销</li><li>支持实时验证</li><li>区块链本身的优势：避免单点故障、匿名性、不可伪造、不可抵赖……</li></ul><h3 id="已有的区块链平台做审计有哪些缺陷？"><a href="#已有的区块链平台做审计有哪些缺陷？" class="headerlink" title="已有的区块链平台做审计有哪些缺陷？"></a>已有的区块链平台做审计有哪些缺陷？</h3><p>早期工作（不支持加密数据的区块链审计系统）的缺点：</p><ul><li>可能暴露交易方的关系</li><li>缺乏对隐私信息（GDPR规定的隐私信息、知识产权等）的保护</li></ul><p>支持加密数据的区块链审计方法：</p><ul><li>要么只用区块链记录交易的hash，而导致无法对链上数据进行审计</li><li>要么在链上记录加密数据，但可能暴露交易图，被攻击后可能被注入恶意交易记录</li><li>以上两种方法都不支持实时审计</li></ul><h2 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h2><h3 id="平台"><a href="#平台" class="headerlink" title="平台"></a>平台</h3><p>本文认为，审计本身的作用是，引入被信任的第三方来证明自己的行为合法合规。因此，zkledger假设该区块链平台可以运行在某个受信任的第三方上，节点之间的通信或与外部的通信在点对点加密信道上完成。</p><p>zkledger假设系统的参与方既包括投资银行Bank1，Bank2，Bank3，…，Bankn，又包括审计方Auditor。其中，Auditor的角色是不定的，Bank也可以承担Auditor的职责。系统内的节点允许动态地增加/减少。</p><p>zkledger的Bank参与方允许向区块链平台发起交易，Auditor参与方允许对其他Bank发起质询，并将质询结果与链上数据对比，确保Bank没有撒谎。另外，zkledger还允许外部用户Depositor从Bank中取钱/向Bank中存钱，而内部的参与方却不能修改某项资产的总量（没有外部输入输出的情况下，内部资产既不能凭空增加，也不能凭空消失）。</p><h3 id="交易"><a href="#交易" class="headerlink" title="交易"></a>交易</h3><p>在审计业务中，区块链作为交易数据的分布式账本，应该记录的是资产法定保管权的变更，而不是所有权的变更。</p><p><strong>一条zkledger的交易表示为：Banki向Bankj转移v股t资产。</strong>而在zkledger链上记录的交易信息里，交易的参与方和资产数量是隐藏的，而交易发生的时间和资产类型是公开的。另外，交易的拓扑顺序也是隐藏的。</p><p>zkledger使用<strong>Pedersen Commitments</strong>来对交易的资产数量进行加密。Pedersen Commitments满足additively comitment的性质。大概可以表示为，对资产数量v（非负整数）和随机数r，用以下方式加密：</p><script type="math/tex; mode=display">cm := COMM(v, r) = g^v h^r</script><p>zkledger中所有的交易记录合在一起，可以看做是以交易为行，以Bank为列的表，这种设计下，在表中查询某Bank的资产持有量会非常方便（相比比特币采用的UTXO机制，zkledger的方法更加适合审计场景）。</p><p>虽然每笔交易一般只与两个Bank有关（spender Bank和receive Bank，其中spender Bank负责向区块链发起交易），但在每个zkledger的交易行中，会包含所有Bank的entry和所有Bank的证明信息（因为不能暴露交易的参与方）。</p><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><p>当交易由某个Bank发起并对外广播后，其他节点需要验证交易的合法性和准确性，通过验证的交易才能被加到链上。</p><p><strong>Proof of Balance</strong>：由于交易不能创建新的资产、也不能销毁现有的资产，因此节点需要验证交易内的总资产变化之和为0。</p><p><strong>Proof of Assets</strong>：交易的spender Bank手中已有的资产必须要&gt;=此次交易所花费的资产，这一操作可以通过遍历spender Bank的column里所有对应资产之和来计算出spender Bank账上的资产余额。</p><p><strong>Range Proof</strong>：交易的资产数量要比密码体制规定的取模运算的底数小，防止恶意节点利用计算溢出导致资产的总量发生变化。</p><h3 id="审计"><a href="#审计" class="headerlink" title="审计"></a>审计</h3><p>审计行为和交易的广播、验证行为都涉及节点之间的交互，为了节省交互行为的开销，zkledger采用了<strong>Non-interactive Zero-knowledge Proof（NIZK）</strong>技术，在每笔交易行中的每个entry上加入多个proof来保证交易的准确性和完整性。</p><p>在zkledger上，审计协议可以保证Bank无法向Auditor隐藏已有的交易记录，因为Auditor可以访问table中Bank对应的整个列。而且Bank之间难以做到合谋，因为Auditor可以检查过去任意时刻的记录，而合谋掩盖资产转移的行为也只能掩盖一时。</p><p><strong>审计在数学上可以被归纳为，对某项资产数据进行求和、滑动平均、方差、标准差、比例等运算。</strong>zkledger采用的Pedersen Commitments天然支持加减法运算。每种审计操作可以看做是多个加减法运算通过乘除组合在一起。其中，加减法运算在链上，由Auditor和Bank之间的交互来完成，并且与链上数据对比来验证，而乘除运算由Auditor在本地完成。（这一段是我在强行解释，目前还完全不懂零知识证明orz）</p><p><strong>Token机制</strong>：由于记账操作只需要spender来完成，因此可能有恶意的spender在未告知receiver的情况下进行交易，从而导致receiver的本地数据与链上数据不一致。为防止这种情况，zkledger要求spender在交易中，为每个Bank对应的entry都增加一个公共可见的token，这样的话其他bank就可以通过该token来核查自己在交易后的资产变化/资产总量。</p><p><strong>Proof of Consistency</strong>：审计行为需要Auditor和Bank之间的交互，而Bank并不想让Auditor知道自己每笔交易的资产转移数目的细节，只想让Auditor知道最后运算得到的结果（可以理解为，如果Auditor向知道sum=v1+v2+v3+…+vn，但是Bank只会帮Auditor算好sum，并不想让Auditor知道v1、v2、v3…的具体值）。为了达到这个目的，bank就不能把它所使用的随机数r告诉Auditor，而只会把自己过去每笔相关交易所使用的随机数r的和暴露给Auditor，因此在每个Bank的entry中的token项会被利用起来，token中蕴含了随机数的和的相关性质。为了防止恶意节点伪造这个信息，还需要在entry中引入一个新的证明，证明token中蕴含的随机数和之前使用过的随机数是一致的。</p><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p>为了提高审计过程的效率，zkledger为每个节点都设计了cache，cache中存储了节点所属的Bank当前的资产余额信息，以及Bank参与的交易信息。当Auditor向Bank发起质询时，Bank可以利用cache快速回答。</p><p>zkledger在工程实现上还引入了Map-Reduce的方法。因为Auditor可能想知道Bank平均每笔交易的信息，而Bank无法直接证明是否具体参与了某项交易。因此，审计过程被分成map和reduce两阶段。以下假设Auditor想知道Bank参与的交易总数。</p><p><strong>map阶段</strong>：Bank对自己是否参与某笔交易做出NIZK证明。</p><p><strong>reduce阶段</strong>：Bank在本地计算出NIZK证明的同态加密之和，并且只公开该证明内蕴含的交易总数信息。</p><p>之后，Bank将参与的交易信息、NIZK证明、参与交易的数目和随机数r发送给Auditor，Auditor负责与链上数据对比，验证准确性。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;基本信息&quot;&gt;&lt;a href=&quot;#基本信息&quot; class=&quot;headerlink&quot; title=&quot;基本信息&quot;&gt;&lt;/a&gt;基本信息&lt;/h2&gt;&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;会议/期刊&lt;/th&gt;
&lt;th&gt;NSDI&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;年份&lt;/td&gt;
&lt;td&gt;2018&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;机构&lt;/td&gt;
&lt;td&gt;MIT Media Lab&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;一作&lt;/td&gt;
&lt;td&gt;Neha Narula&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;领域&lt;/td&gt;
&lt;td&gt;Blockchain，Zero Knowledge Proof，Auditing&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;h2 id=&quot;主要贡献&quot;&gt;&lt;a href=&quot;#主要贡献&quot; class=&quot;headerlink&quot; title=&quot;主要贡献&quot;&gt;&lt;/a&gt;主要贡献&lt;/h2&gt;&lt;p&gt;本文提出了一种&lt;a href=&quot;https://www.usenix.org/conference/nsdi18/presentation/narula&quot;&gt;支持对链上密文数据进行实时审计的区块链系统zkledger&lt;/a&gt;。zkledger上记录着多个银行间进行场外交易的交易记录，链上记录的交易内容是加密的。通过zkledger提出的审计协议，审计方可以实时地对任意银行进行质询，以验证银行间的交易行为符合监管当局的规定和法律要求。zkledger的证明机制确保银行无法向审计方撒谎，也无法合谋转移资产。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Papers" scheme="http://xinlu.cool/categories/Papers/"/>
    
    
      <category term="Blockchain" scheme="http://xinlu.cool/tags/Blockchain/"/>
    
      <category term="Auditing" scheme="http://xinlu.cool/tags/Auditing/"/>
    
      <category term="Zero-knowledge Proof" scheme="http://xinlu.cool/tags/Zero-knowledge-Proof/"/>
    
  </entry>
  
  <entry>
    <title>A Geometry-Inspired Decision-Based Attack论文摘要</title>
    <link href="http://xinlu.cool/Papers/paper-qfool-attack/"/>
    <id>http://xinlu.cool/Papers/paper-qfool-attack/</id>
    <published>2021-03-24T05:57:05.000Z</published>
    <updated>2021-03-24T06:04:18.928Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h2><div class="table-container"><table><thead><tr><th><strong>会议/期刊</strong></th><th>ICCV</th></tr></thead><tbody><tr><td><strong>年份</strong></td><td>2019</td></tr><tr><td><strong>机构</strong></td><td>EPFL</td></tr><tr><td><strong>一作</strong></td><td>Yujia Liu</td></tr><tr><td><strong>领域</strong></td><td>Adversarial Example, Decision-based Black-box Attack</td></tr></tbody></table></div><h2 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h2><p>本文提出了一种新型<a href="https://arxiv.org/abs/1903.10826">黑盒对抗样本生成算法qFool</a>。该算法不依赖模型输出的概率分布，仅<strong>利用Top-1预测结果</strong>就能构造出对抗样本。qFool算法的特点是<strong>查询次数较少</strong>，其变种qFool-subspace算法还能<strong>将对抗样本限制在输入的低频子空间中</strong>，在<strong>计算上更加高效</strong>。</p><a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="早期工作"><a href="#早期工作" class="headerlink" title="早期工作"></a>早期工作</h3><p>对抗样本攻击算法根据攻击设定可分为白盒与黑盒两种。黑盒攻击假设攻击者不知道模型的内部细节（架构、参数、损失、梯度…），仅仅知道模型的输出结果。黑盒攻击又可以细分为Score-based和Decision-based。Scored-based攻击假设攻击者能知道模型输出的各类别概率分布，而Decision-based攻击假设攻击者只知道模型输出的Top1预测结果。</p><p>Decision-based黑盒攻击的早期工作包括Additive Gaussian Attack、Boundary Attack等。Additive Gaussian Attack生成的对抗样本对人眼来说太过于明显。Boundary Attack利用神经网络的决策边界的几何性质来构造对抗样本，方法颇为巧妙。Boundary Attack的另一大主要贡献还在于确立了<strong>黑盒攻击领域最主流的技术框架</strong>：先找到原始对抗样本，再用逼近法找到边界对抗样本，然后利用边界对抗样本的种种性质来寻找新的对抗样本，之后再逼近、寻找、…以此循环往复。</p><p>在技术路线上，Decision-based黑盒攻击的难点在于缺少模型的梯度信息（个人认为梯度方向和所谓模型决策边界信息在黑盒对抗领域其实是一回事），而<strong>模型的逆梯度方向是构造对抗样本的关键</strong>。目前已知的解决这一问题的方法包括Transfer-based和Sample-based。Transfer-based方法根据对抗样本在不同模型之间的迁移性，假设不同模型之间的梯度方向相似，先在本地训练替代模型，然后利用替代模型的梯度来<strong>代替未知的目标模型梯度</strong>。Sample-based方法利用模型决策边界附近的一些特殊性质，<strong>构造边界附近的梯度估计量</strong>，然后用蒙特卡洛采样法来<strong>计算出梯度的估计</strong>。</p><p>已有的Decision-based黑盒攻击方法的主要缺陷在于<strong>query次数过多</strong>，生成一张对抗样本图片普遍需要10000+次查询操作，这在实际攻击场景中是不现实的。在“减少query次数”这一方向上已经有了一些探索性的工作，例如引入主动学习框架、对特征进行筛选和降维等。</p><p>本文提出的qFool算法是Decision-based黑盒攻击领域在2019年的重要工作。qFool一方面继承了Boundary Attack的攻击框架，另一方面引入子空间采样的方法创新性地解决了查询次数过高的难题。在实验部分，qFool算法在攻击Google商业图片识别服务时仅用了~1500次查询。</p><h3 id="灵感来源"><a href="#灵感来源" class="headerlink" title="灵感来源"></a>灵感来源</h3><p>该算法的灵感来源于一篇发表于NIPS2016的对抗样本理论工作：Robustness of classifiers: from adversarial to random noise。早期工作中指出，对抗样本附近的决策边界的曲面很小。</p><blockquote><p>Fawzi et al. [7] have shown that the decision boundary has a quite small curvature in the vicinity of adversarial examples.</p></blockquote><p>根据这一发现，如果在对抗样本附近的决策边界上找到“边界对抗样本”，那么<strong>对抗样本的梯度方向与邻近区域的边界对抗样本的梯度方向几乎一样</strong>。</p><p>因此，只要找到了边界对抗样本（较容易），就可以依循梯度方向来找到附近的对抗样本（较困难）。（把难题简单化）</p><h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2><p>从查询效率上看，qFool超过了经典的Boundary Attack算法，仅利用~1500次查询就成功地攻击了Google商业图片识别服务。</p><p>从实验成果上看，qFool用实验证明了边界对抗样本附近的梯度和邻域内的对抗样本梯度几乎一样的性质，并且验证了在子空间内采样生成对抗扰动这条降维的技术路线确实可行。</p><p>2020年的很多黑盒攻击的工作在方案的复杂性和理论的严密性上超越了qFool算法。</p><h2 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h2><h3 id="算法框架"><a href="#算法框架" class="headerlink" title="算法框架"></a>算法框架</h3><p>这里只关心适用最广泛的targeted attack场景，伪代码如下：</p><p>输入：原始图片 <code>x_0</code>，目标图片 <code>x_t</code>，每次更新估计量所需的查询次数 <code>nu</code>，控制内循环查询次数的超参数 <code>threshold</code><br>输出：对抗样本 <code>x_adv</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">二分搜索寻找边界对抗样本</span><br><span class="line"><span class="keyword">while</span> 已消耗查询次数 &lt; 总查询次数：</span><br><span class="line">为本轮迭代分配查询次数</span><br><span class="line"><span class="keyword">while</span> 对抗样本更新幅度满足预设条件 <span class="keyword">and</span> 总查询次数未耗尽：</span><br><span class="line">    在边界对抗样本上施加随机扰动（可以在频率子空间上施加扰动），查询 nu 次</span><br><span class="line">        利用内部循环产生的所有查询结果来构造梯度的估计量</span><br><span class="line">        新对抗样本 = 边界对抗样本 + 步长 * 梯度的估计量</span><br><span class="line">        二分搜索，更新新对抗样本</span><br><span class="line">    边界对抗样本 = 新对抗样本</span><br></pre></td></tr></table></figure><p>算法中需要详细分析的有三点：</p><ul><li>怎么估计边界对抗样本上的梯度？</li><li>总查询次数如何分配？</li><li>如何在子空间上进行采样？</li></ul><h3 id="梯度的估计"><a href="#梯度的估计" class="headerlink" title="梯度的估计"></a>梯度的估计</h3><p>假设算法每轮迭代时向模型查询n次，那么每次构造n个随机噪声向量，采样后进行归一化，</p><script type="math/tex; mode=display">\{\mathbf{\eta}_i\} \sim N(0, \mathbf{1}_n)</script><p>将噪声叠加到边界对抗样本P上，得到n个查询结果，</p><script type="math/tex; mode=display">z_i = \left\{ \begin{array}{rcl}-1 & f(\mathcal{P}+\mathbf{\eta}_i)=f(\mathbf{x}_0) \\+1 & f(\mathcal{P}+\mathbf{\eta}_i) \neq f(\mathbf{x}_0)\end{array}\right., \;\;\; i=1,2,...,n</script><p>构造边界对抗样本附近的梯度的估计量，</p><script type="math/tex; mode=display">\nabla f(\mathcal{x}_0) \approx \nabla f(\mathcal{P}) \approx \mathbf{\xi} = \frac{\sum^n_{i=1}{z_i \mathbf{\eta}_i}}{\|\sum^n_{i=1}{z_i \mathbf{\eta}_i}\|_2}</script><h3 id="查询次数的分配策略"><a href="#查询次数的分配策略" class="headerlink" title="查询次数的分配策略"></a>查询次数的分配策略</h3><p>在理想的情况下，采样次数 <code>n</code> 充分大，采样得到的随机向量在决策边界两遍分布均匀，这样的话，算法利用 <code>n</code> 次查询得到的结果构造的统计量就能精确估计梯度。</p><p>但考虑到实际情况中，用户并不知道 <code>n</code> 的合适大小，采样得到的随机向量也可能分布并不充分均匀，就会为后续的梯度估计步骤引入误差，或者产生很大的对抗扰动。</p><p>论文还指出，初始对抗样本与原始样本之间的距离对最终生成的对抗样本质量有很大影响，因此算法更希望在前期找到尽可能好的对抗样本。（意味着前几轮的查询总次数更多）</p><p>为了避免以上情况，qFool算法提出了一种渐进的、贪心的分配策略：</p><ul><li>固定每次查询/采样数目为 <code>nu</code></li><li>多次查询组成算法的一轮迭代 （每轮迭代的查询次数 = 查询次数 * <code>nu</code>）</li><li>每轮迭代中，控制生成的扰动大小，控制方法是尽可能生成距离边界对抗样本更近的对抗样本</li><li>迭代轮数受查询的总次数限制</li></ul><p>迭代进行的判定条件具体如下，</p><script type="math/tex; mode=display">\frac{\|x^{(i)}_{adv} - \mathcal{P}_i\|}{n^{(i)}}\leq\epsilon \;\; \frac{\|x^{(i-1)}_{adv} - \mathcal{P}_i\|}{n^{(i-1)}}\;\;\;\;and\;\;\;\;\sum^i_{j=0}{n^{(j)}} < n</script><h3 id="子空间采样"><a href="#子空间采样" class="headerlink" title="子空间采样"></a>子空间采样</h3><p>本论文对图像进行离散余弦变换（DCT），变换后的频率图的左上部分表示的是原图的低频部分。</p><p>qFool算法在低频部分截取维度大小为 <code>m</code> 的子空间，在这个空间范围内施加对抗扰动，然后用反离散余弦变换（IDCT）还原成对抗图片。</p><p>缩小维度让采样得到的随机噪声在决策边界的分布更加均匀，根据随机噪声估计得到的梯度方向也就更加精确，最终可以让生成的对抗扰动更小、更不易被察觉。在subspace内采样所需的查询次数更少。</p><p>相比之下，在full space内采样得到的噪声分布得极为稀疏，沿决策边界均匀分布的可能性也更低。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;基本信息&quot;&gt;&lt;a href=&quot;#基本信息&quot; class=&quot;headerlink&quot; title=&quot;基本信息&quot;&gt;&lt;/a&gt;基本信息&lt;/h2&gt;&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;会议/期刊&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;ICCV&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;年份&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;2019&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;机构&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;EPFL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;一作&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Yujia Liu&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;领域&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Adversarial Example, Decision-based Black-box Attack&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;h2 id=&quot;主要贡献&quot;&gt;&lt;a href=&quot;#主要贡献&quot; class=&quot;headerlink&quot; title=&quot;主要贡献&quot;&gt;&lt;/a&gt;主要贡献&lt;/h2&gt;&lt;p&gt;本文提出了一种新型&lt;a href=&quot;https://arxiv.org/abs/1903.10826&quot;&gt;黑盒对抗样本生成算法qFool&lt;/a&gt;。该算法不依赖模型输出的概率分布，仅&lt;strong&gt;利用Top-1预测结果&lt;/strong&gt;就能构造出对抗样本。qFool算法的特点是&lt;strong&gt;查询次数较少&lt;/strong&gt;，其变种qFool-subspace算法还能&lt;strong&gt;将对抗样本限制在输入的低频子空间中&lt;/strong&gt;，在&lt;strong&gt;计算上更加高效&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Papers" scheme="http://xinlu.cool/categories/Papers/"/>
    
    
      <category term="Machine Learning" scheme="http://xinlu.cool/tags/Machine-Learning/"/>
    
      <category term="Adversarial Example" scheme="http://xinlu.cool/tags/Adversarial-Example/"/>
    
      <category term="Black-box Attack" scheme="http://xinlu.cool/tags/Black-box-Attack/"/>
    
  </entry>
  
  <entry>
    <title>A Gift from Knowledge Distillation Fast Optimization, Network Minimization and Transfer Learning论文摘要</title>
    <link href="http://xinlu.cool/Papers/paper-a-gift-from-knowledge-distillation/"/>
    <id>http://xinlu.cool/Papers/paper-a-gift-from-knowledge-distillation/</id>
    <published>2021-03-08T13:33:20.000Z</published>
    <updated>2021-03-24T05:53:41.290Z</updated>
    
    <content type="html"><![CDATA[<p>本文提出了一种新的卷积网络权重初始化方法，它的思路是利用FSP矩阵来表示相邻两层输出之间的关系，这种关系能告诉我们“神经网络解决问题的思路”，然后训练学生网络来最小化FSP矩阵的L2距离，以此初始化学生网络权重，之后再接着训练。该方法在cifar10、cifar100数据集上被证明具有收敛快、精度高、适于迁移学习的效果。</p><a id="more"></a><h2 id="一、基本信息"><a href="#一、基本信息" class="headerlink" title="一、基本信息"></a>一、基本信息</h2><div class="table-container"><table><thead><tr><th>会议/期刊</th><th>CVPR</th></tr></thead><tbody><tr><td>年份</td><td>2017</td></tr><tr><td>机构</td><td>KAIST</td></tr><tr><td>一作</td><td>Junho Yim，Donggyu Joo，Junmo Kim</td></tr><tr><td>领域</td><td>Knowledge Distillation，Transfer Learning</td></tr></tbody></table></div><h2 id="二、做了什么？针对什么应用场景？"><a href="#二、做了什么？针对什么应用场景？" class="headerlink" title="二、做了什么？针对什么应用场景？"></a>二、做了什么？针对什么应用场景？</h2><p>本文提出了一种新的卷积网络权重初始化方法，它的思路是利用FSP矩阵来表示相邻两层输出之间的关系，这种关系能告诉我们“神经网络解决问题的思路”，然后训练学生网络来minimize L2(FSP_teacher, FSP_student)，以此初始化学生网络权重，之后再接着训练。该方法在cifar10、cifar100数据集上被证明具有收敛快、精度高、适于迁移学习的效果。</p><p>主要针对场景：<br>    1）手上有一个超大的模型，但部署环境不支持计算量/存储/功耗，因此需要训练一个小一点的模型or多个小型模型的集成，<br>    2）手上有一个预训练模型，但新任务样本量较少、从头训练效果不好，因此需要在新任务上进行fine-tune，<br>    3）追求模型的快速收敛，需要好的初始化策略，</p><h2 id="三、这么做有什么好处？（纵向比较）"><a href="#三、这么做有什么好处？（纵向比较）" class="headerlink" title="三、这么做有什么好处？（纵向比较）"></a>三、这么做有什么好处？（纵向比较）</h2><p>第一次从“flow of solving problems”的角度看待知识蒸馏，具有启发意义。（之前的方法过于注重让student模仿</p><p>将知识蒸馏技术引入了迁移学习领域。</p><h2 id="四、为什么做这个工作？（横向比较）"><a href="#四、为什么做这个工作？（横向比较）" class="headerlink" title="四、为什么做这个工作？（横向比较）"></a>四、为什么做这个工作？（横向比较）</h2><p>vs 普通的KD（Romero/FitNets）：</p><ul><li><p>其他知识蒸馏方法只追求student模仿teacher的结果输出/中间层输出，只重视结果而不重视解决问题的过程，</p></li><li><p>训练过程低效，本方法多个模块可以独立训练，效果仍然很好，</p></li><li><p>不利于产生迁移性好的学生网络，因为没有学习过程只强调模仿</p></li></ul><p>vs 其他快速收敛的方法：选择一个好的初始化策略能使深度网络优化地更快，选择一个好的优化器能使深度网络更易于达到全局/局部最优</p><ul><li><p>simple init：Gaussian noise、Xavier</p></li><li><p>complicated init：he normal、he uniform</p></li><li><p>optimizer：sgd、adam</p></li></ul><h2 id="五、方法上有什么创新之处？（实验方法-评价指标-谋篇布局-制图）"><a href="#五、方法上有什么创新之处？（实验方法-评价指标-谋篇布局-制图）" class="headerlink" title="五、方法上有什么创新之处？（实验方法/评价指标/谋篇布局/制图）"></a>五、方法上有什么创新之处？（实验方法/评价指标/谋篇布局/制图）</h2><p>核心问题：</p><ol><li>如何定义teacher网络所含的信息？ =&gt; FSP矩阵</li><li>如何让student网络学习到teacher所含信息？ =&gt; 最小化两个网络的FSP矩阵距离</li><li>如何减少students之前的关联性、引入差异性？（好做集成分类器） =&gt; 打乱teacher网络的通道，生成新的FSP matrices</li><li>如何比较初始化策略 vs 简单的知识迁移？=&gt; 用相同的架构做kd，一种init student=trained teacher，另一种init student=FSP trained(trained  teacher)</li><li>怎么证明收敛更快？=&gt; student只用 1/3 的迭代次数，达到和teacher相似的精确度</li></ol><h2 id="六、思路上有什么创新之处？（新发现-新论断-新猜想）"><a href="#六、思路上有什么创新之处？（新发现-新论断-新猜想）" class="headerlink" title="六、思路上有什么创新之处？（新发现/新论断/新猜想）"></a>六、思路上有什么创新之处？（新发现/新论断/新猜想）</h2><ul><li>定义了一种high level knowledge =&gt; flow of solving problems =&gt; relationship between outputs of 2 connected layers</li><li>借鉴了Gramian matrix的思想（A neural algorithm of artistic style），提出了FSP矩阵（flow of solving problems）</li></ul><h2 id="七、有什么我可以借鉴的？"><a href="#七、有什么我可以借鉴的？" class="headerlink" title="七、有什么我可以借鉴的？"></a>七、有什么我可以借鉴的？</h2><p>对CIFAR10数据集，可以先padding到40x40再训练。</p><h2 id="八、缺点有哪些？"><a href="#八、缺点有哪些？" class="headerlink" title="八、缺点有哪些？"></a>八、缺点有哪些？</h2><p>语言描述过于累赘，实验部分思路不够清晰。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文提出了一种新的卷积网络权重初始化方法，它的思路是利用FSP矩阵来表示相邻两层输出之间的关系，这种关系能告诉我们“神经网络解决问题的思路”，然后训练学生网络来最小化FSP矩阵的L2距离，以此初始化学生网络权重，之后再接着训练。该方法在cifar10、cifar100数据集上被证明具有收敛快、精度高、适于迁移学习的效果。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Papers" scheme="http://xinlu.cool/categories/Papers/"/>
    
    
      <category term="Machine Learning" scheme="http://xinlu.cool/tags/Machine-Learning/"/>
    
      <category term="Knowledge Distillation" scheme="http://xinlu.cool/tags/Knowledge-Distillation/"/>
    
  </entry>
  
  <entry>
    <title>HopSkipJumpAttack论文分析</title>
    <link href="http://xinlu.cool/Papers/paper-hsja/"/>
    <id>http://xinlu.cool/Papers/paper-hsja/</id>
    <published>2021-01-19T07:36:29.000Z</published>
    <updated>2021-03-24T05:53:30.256Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1904.02144">HopSkipJumpAttack</a>是发表于2020年S&amp;P的论文，提出了一种新型黑盒对抗攻击的方法，利用采样+逼近的思路来生成对抗样本，理论基础完备，实验效果达到了SOTA。</p><a id="more"></a><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><h3 id="被攻击模型的定义"><a href="#被攻击模型的定义" class="headerlink" title="被攻击模型的定义"></a>被攻击模型的定义</h3><p>定义神经网络为以下函数</p><script type="math/tex; mode=display">F: \mathbb{R}^d \rightarrow \mathbb{R}^m</script><p>函数的输入为区间[0, 1]上的d维向量</p><script type="math/tex; mode=display">x \in [0, 1]^d</script><p>函数的输出为[0, 1]上的m维概率分布向量，满足全概率公式</p><script type="math/tex; mode=display">y \in \Delta_m := \{y \in [0, 1]^m \: | \:  \Sigma^m_{c=1} \: y_c = 1\}</script><p>m同时也是神经网络输出类别的总个数，c用来指代任意一个类别，神经网络输出的所有类别标签的集合即为</p><script type="math/tex; mode=display">[m] = {1,...,m}</script><p>将函数的输出写成向量的形式为</p><script type="math/tex; mode=display">y = (F_1(x),...,F_m(x))</script><p>基于以上函数的分类器可以表示为</p><script type="math/tex; mode=display">C(x) := \underset{c \in [m]}{\operatorname{argmax}}F_c (x)</script><h3 id="对抗攻击的定义"><a href="#对抗攻击的定义" class="headerlink" title="对抗攻击的定义"></a>对抗攻击的定义</h3><p>untarget attack的目标是让分类器的输出类别从</p><script type="math/tex; mode=display">c^* := C(x^*)</script><p>变成与原来类别不同的任何类别</p><script type="math/tex; mode=display">c \in [m] - \{c^*\}</script><p>targeted attack的目标是让分类器的输出类别变成某个预先定义好的类别</p><script type="math/tex; mode=display">c^{\dagger} \in [m] - \{c^*\}</script><p>定义函数S，S与攻击者的攻击目标有关，可以判定当前生成的对抗样本是否满足攻击目标</p><script type="math/tex; mode=display">S_{x^*}(x'):= \left \{ \begin{array}{rcl}\operatorname{max}_{c \neq c^*} F_c(x')-F_{c^*}(x') & (Untargeted) \\F_{c^\dagger}(x')-\operatorname{max}_{c \neq c^\dagger}F_c(x') & (Targeted)\end{array}\right.</script><p>对于任意对抗样本x’而言，只要满足S(x’)&gt;0，就可以认为攻击成功</p><h3 id="边界上的对抗样本集合"><a href="#边界上的对抗样本集合" class="headerlink" title="边界上的对抗样本集合"></a>边界上的对抗样本集合</h3><p>当S(x’)=0时，对抗攻击正好处在成功与失败的边界上，定义边界上的对抗样本构成的集合为</p><script type="math/tex; mode=display">bd(S_{x^*}):=\{ z \in [0, 1]^d \: | \: S_{x^*}(z)=0 \}</script><h3 id="攻击成功的判定函数"><a href="#攻击成功的判定函数" class="headerlink" title="攻击成功的判定函数"></a>攻击成功的判定函数</h3><p>构造sign函数如下</p><script type="math/tex; mode=display">\phi_{x^*}(x'):=\operatorname{sign}(S_{x^*}(x'))= \left \{ \begin{array}{rcl}1 & if \; S_{x^*}(x')>0 \\-1 & otherwise\end{array}\right.</script><p>当sign函数取值为+1时，对抗样本攻击即为成功。</p><p>为了实现攻击的隐蔽性，攻击者最终的目标是找到与原始样本距离最小的对抗样本，距离函数一般取0、2、无穷范数。</p><script type="math/tex; mode=display">\operatorname{min}_{x'}\;d(x', x^*) \;\;\;\; s.t.  \phi_{x^*}(x')=1</script><h2 id="算法框架"><a href="#算法框架" class="headerlink" title="算法框架"></a>算法框架</h2><h3 id="迭代更新"><a href="#迭代更新" class="headerlink" title="迭代更新"></a>迭代更新</h3><p>HSJA算法可以用数学公式描述如下</p><script type="math/tex; mode=display">x_{t+1} = \alpha_t x^* + (1 - \alpha_t) \{ x_t + \xi_t \frac{\nabla S_{x^*}(x_t)}{||\nabla S_{x^*}(x_t)||_2} \}</script><p>其中涉及的关键步骤有：</p><ul><li>用<strong>二分搜索</strong>来选取合适的alpha，让新对抗样本逼近边界</li><li>在边界上，用<strong>Monte Carlo采样</strong>得到函数S的梯度的估计，生成对抗扰动</li><li>用<strong>Geometric Progression</strong>来控制扰动的大小，更新对抗样本</li><li>继续用<strong>二分搜索</strong>来选取合适的alpha，让新对抗样本逼近边界</li><li>……</li></ul><h3 id="步长选择"><a href="#步长选择" class="headerlink" title="步长选择"></a>步长选择</h3><p>把梯度估计线性叠加到对抗样本上的公式描述如下</p><script type="math/tex; mode=display">\tilde{x}_t := x_t + \xi_t v_t (x_t, \delta_t)</script><script type="math/tex; mode=display">v_t(x_t, \delta_t) = \left \{ \begin{array}{rcl}\widehat{\nabla S}(x_t, \delta_t) / ||\widehat{\nabla S}(x_t, \delta_t)||_2 & if \;\; p = 2 \\\operatorname{sign}(\widehat{\nabla S}(x_t, \delta_t)) & if \;\; p = \infty\end{array}\right.</script><p>该迭代算法的收敛性与步长的选择直接相关，HSJA将步长初始化如下，如果更新后的对抗样本攻击失败，那么步长减半，以此类推。</p><script type="math/tex; mode=display">\xi_t := ||x_t - x^*||_p / \sqrt{t}</script><h2 id="算法细节"><a href="#算法细节" class="headerlink" title="算法细节"></a>算法细节</h2><h3 id="Lp-projection"><a href="#Lp-projection" class="headerlink" title="Lp-projection"></a>Lp-projection</h3><p>与大多数主流算法相似，HSJA算法给对抗样本到原始样本的距离增加了限制，不能大于epsilon。距离函数取Lp范数，p=2或inf。</p><p>给定对抗样本x，Lp-projection步骤的目的是在对抗样本x上进行裁剪，裁剪后得到的新对抗样本y既要满足到原始样本的距离限制，又要距离原来的对抗样本x尽可能地近。</p><p>Lp-projection步骤在p=1, 2, …, 无穷时都有通解，但本算法重新构造了通解，以便后续进行二分搜索。以下分别为L2和Linf两种情况下的映射公式。</p><p>当p=2时，映射公式如下</p><script type="math/tex; mode=display">\Pi_{x^*,\alpha_t}^2 (x) := \underset{||y-x^*||_2 \leqslant \alpha_t}{\operatorname{argmin}}||y-x||_2 = \alpha_t x^* + (1-\alpha_t)x</script><p>当p=inf时，映射公式如下，值得注意的是，x和x*都是向量，而此处新定义的c是常数。</p><script type="math/tex; mode=display">\Pi_{x^*, \alpha}^\infty (x) := \operatorname{max}\{\operatorname{min}\{x, x^*+c\}, x^*-c\} \;\; (modified)</script><script type="math/tex; mode=display">c := \alpha||x - x^*||_\infty</script><p><strong>原论文在此处的公式可能有误，已知c是个非负数，那么x<em>与x</em>+c的比较就失去了意义，以下给出原论文上的无穷范数映射公式</strong></p><script type="math/tex; mode=display">\Pi_{x^*, \alpha}^\infty (x)_i := \operatorname{max}\{\operatorname{min}\{x_i^*, x_i^*+c\}, x_i-c\}</script><p>无论p=2还是inf，alpha的概念都是统一的：越接近0就离原始样本越近，越接近0就离对抗样本越近。利用概念上的统一性，后续在对alpha在区间[0, 1]上做二分搜索时，也更加方便。</p><p>开源代码库<a href="https://github.com/bethgelab/foolbox/blob/master/foolbox/attacks/hop_skip_jump.py">foolbox</a>给出了Lp-projection的实现，如下所示<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_project</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">    self, originals: ep.Tensor, perturbed: ep.Tensor, epsilons: ep.Tensor</span></span></span><br><span class="line"><span class="function"><span class="params"></span>) -&gt; ep.Tensor:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Clips the perturbations to epsilon and returns the new perturbed</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        originals: A batch of reference inputs.</span></span><br><span class="line"><span class="string">        perturbed: A batch of perturbed inputs.</span></span><br><span class="line"><span class="string">        epsilons: A batch of norm values to project to.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        A tensor like perturbed but with the perturbation clipped to epsilon.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    epsilons = atleast_kd(epsilons, originals.ndim)</span><br><span class="line">    <span class="keyword">if</span> self.constraint == <span class="string">&quot;linf&quot;</span>:</span><br><span class="line">        perturbation = perturbed - originals</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ep.clip does not support tensors as min/max</span></span><br><span class="line">        clipped_perturbed = ep.where(</span><br><span class="line">            perturbation &gt; epsilons, originals + epsilons, perturbed</span><br><span class="line">        )</span><br><span class="line">        clipped_perturbed = ep.where(</span><br><span class="line">            perturbation &lt; -epsilons, originals - epsilons, clipped_perturbed</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> clipped_perturbed</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">1.0</span> - epsilons) * originals + epsilons * perturbed</span><br></pre></td></tr></table></figure></p><h3 id="梯度估计"><a href="#梯度估计" class="headerlink" title="梯度估计"></a>梯度估计</h3><h4 id="估计的成立条件"><a href="#估计的成立条件" class="headerlink" title="估计的成立条件"></a>估计的成立条件</h4><p>HSJA算法需要对函数S在第t次迭代生成的对抗样本xt上求梯度。若要使这一梯度可被估计，需要满足以下假设条件</p><ul><li>函数S<strong>二阶可导</strong>，并且满足<strong>局部Lipschitz约束</strong>，x0是初始对抗样本</li></ul><script type="math/tex; mode=display">\exists L>0, \;\; \forall x,y \in \{z:||z-x^*||_2 \leqslant ||x_0 - x^*||_2 \},</script><script type="math/tex; mode=display">||\nabla S_{x^*}(x) - \nabla S_{x^*}(y)||_2 \leqslant L||x-y||_2</script><ul><li>如果对抗样本xt刚好<strong>处于边界</strong>，即S(xt)=0，那么函数S在xt上的导数一定<strong>存在下界</strong>，并且<strong>下界大于0</strong></li></ul><script type="math/tex; mode=display">\exists \tilde{C} > 0, \;\; \forall z \in bd(S_{x^*})</script><script type="math/tex; mode=display">|| \nabla S_{x^*}(z) || > \tilde{C}</script><ul><li>如果要用对抗样本xt与初始样本x<em>的差来做函数S梯度的<strong>无偏估计</strong>（即下面的函数r=1），那么xt必须要处于HSJA算法优化过程中的<em>*驻点</em></em>上</li></ul><script type="math/tex; mode=display">\begin{align}r(x_t, x^*) :&= cos \angle (x_t - x^*, \nabla S_{x^*}(x_t)) \\& = \frac{<x_t - x^*, \nabla S_{x^*}(x_t)>}{||x_t - x^*||_2 || \nabla S_{x^*}(x_t)||_2}\end{align}</script><ul><li>在上述假设都成立的情况下，在HSJA算法优化过程中<strong>选取合适的步长</strong>，可以保证算法得到的对抗样本xt最终收敛至驻点</li></ul><script type="math/tex; mode=display">\xi_t = || x_t - x^* ||_2 t^{-q} \;\;\;\; for \; q \in (\frac{1}{2},1)</script><script type="math/tex; mode=display">0 \leqslant 1 - r(x_t, x^*) \leqslant ct^{q-1} \;\;\;\; for \; t=1,2,...</script><p>以上分别为步长更新公式和步长对函数r的限制，具体证明过程里用到了二阶泰勒估计。</p><p>上述估计方法也可以推广到p=inf的情况。</p><h4 id="渐进无偏估计量"><a href="#渐进无偏估计量" class="headerlink" title="渐进无偏估计量"></a>渐进无偏估计量</h4><p>对任意位于边界上的xt，可以用以下Monte Carlo采样得到的统计量来估计函数S的梯度</p><script type="math/tex; mode=display">\widetilde{\nabla S}(x_t, \delta) := \frac{1}{B} \sum_{b=1}^{B} \phi_{x^*}(x_t+\delta u_b)u_b,</script><script type="math/tex; mode=display">x_t \in bd(S_{x^*})</script><script type="math/tex; mode=display">i.i.d. \;\{u_b\}_{b=1}^B \sim U(-1, 1)^d</script><p>随机变量ub是独立同分布的d维随机向量，服从均匀分布，B表示样本容量，也是Monte Carlo采样的次数。</p><p>由于引入了delta，导致该估计量是有偏的，但偏差具有下界，可表示为</p><script type="math/tex; mode=display">\cos \angle (\mathbb{E}[ \widetilde{\nabla S} (x_t, \delta)], \nabla S_{x^*}(x_t)) \geqslant1 - \frac{9 L^2 \delta^2 d^2}{8||\nabla S(x_t)||_2^2}</script><p>以上估计量的渐进无偏性可表示为</p><script type="math/tex; mode=display">\lim_{\delta \rightarrow 0} \cos \angle (\mathbb{E}[ \widetilde{\nabla S} (x_t, \delta)], \nabla S_{x^*}(x_t))=1</script><p>一般取delta为1/d，之后会给出一个偏差更小的delta选取方法。</p><h4 id="方差更小的估计量"><a href="#方差更小的估计量" class="headerlink" title="方差更小的估计量"></a>方差更小的估计量</h4><p>由于实验误差的存在，xt不一定恰好在边界上，delta也不总是为0，因此采样得到的新样本在边界两边常常是分布不均匀的，这会产生难以忽视的误差。</p><p>因此HSJA算法提出了一个新的方差更小的估计量。和之前的估计量一样，新估计量也是渐进无偏的。新估计量表示如下</p><script type="math/tex; mode=display">\begin{align}\overline{\phi_{x^*}} & := \frac{1}{B} \sum_{b=1}^{B} \phi_{x^*}(x_t + \delta u_b)\\ \widehat{\nabla S}(x_t, \delta) &:= \frac{1}{B-1} \sum_{b=1}^{B} (\phi_{x^*}(x_t+\delta u_b) - \overline{\phi_{x^*}})u_b\end{align}</script><p>方差上界的证明部分略去。</p><h4 id="Monte-Carlo采样方法的实现"><a href="#Monte-Carlo采样方法的实现" class="headerlink" title="Monte Carlo采样方法的实现"></a>Monte Carlo采样方法的实现</h4><p>开源代码库<a href="https://github.com/bethgelab/foolbox/blob/master/foolbox/attacks/hop_skip_jump.py">foolbox</a>给出了该梯度估计方法的实现，与原论文的代码仓库相比实现更加简洁，但思路比较难理解。</p><p>首先，生成随机张量rv并单位化。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> self.constraint == <span class="string">&quot;l2&quot;</span>:</span><br><span class="line">    rv = ep.normal(x_advs, noise_shape)</span><br><span class="line"><span class="keyword">elif</span> self.constraint == <span class="string">&quot;linf&quot;</span>:</span><br><span class="line">    rv = ep.uniform(x_advs, low=-<span class="number">1</span>, high=<span class="number">1</span>, shape=noise_shape)</span><br><span class="line">rv /= atleast_kd(ep.norms.l2(flatten(rv, keep=<span class="number">1</span>), -<span class="number">1</span>), rv.ndim) + <span class="number">1e-12</span></span><br></pre></td></tr></table></figure></p><p>然后生成扰动图片，即x_adv+delta*rv，图片的值域必须被裁剪到[0, 1]之间。<br>foolbox库要求用户在实例化对象时指明输入的上下界，之后会把所有的输入张量都缩放到[0, 1]之间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scaled_rv = atleast_kd(ep.expand_dims(delta, <span class="number">0</span>), rv.ndim) * rv</span><br><span class="line">perturbed = ep.expand_dims(x_advs, <span class="number">0</span>) + scaled_rv</span><br><span class="line">perturbed = ep.clip(perturbed, <span class="number">0</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>从扰动图片中还原出采样得到的rv，这一步其实有点巧妙，隐式地对采样得到的rv的大小进行了裁剪。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rv = (perturbed - x_advs) / delta</span><br></pre></td></tr></table></figure><p>接下来的步骤需要对pytorch的张量condition操作有一定了解，但这段代码的目的是很明确的，只要生成的扰动图片攻击成功了，multipliers中该扰动图片就对应为1，否则对应为-1。</p><p>perturbed的形状为：<code>(step_size, batch_size, C, H, W)</code>。</p><p>decision的形状为：<code>(step_size, batch_size)</code>，类型为<code>bool</code>。</p><p>multipliers最终的形状为：<code>(step_size, batch_size)</code>，攻击成功对应为1，攻击失败对应为-1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">multipliers_list: List[ep.Tensor] = []</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(steps):</span><br><span class="line">    decision = is_adversarial(perturbed[step])</span><br><span class="line">    multipliers_list.append(</span><br><span class="line">        ep.where(</span><br><span class="line">            decision,</span><br><span class="line">            ep.ones(x_advs, (<span class="built_in">len</span>(x_advs,))),</span><br><span class="line">            -ep.ones(x_advs, (<span class="built_in">len</span>(decision,))),</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line"><span class="comment"># (steps, bs, ...)</span></span><br><span class="line">multipliers = ep.stack(multipliers_list, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>代码还精炼地实现了减少方差的操作，如果所有采样得到的随机扰动都攻击成功/都攻击失败，那么multipliers值不变，否则就需要减去均值来减少估计的方差。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vals = ep.where(</span><br><span class="line">    ep.<span class="built_in">abs</span>(ep.mean(multipliers, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)) == <span class="number">1</span>,</span><br><span class="line">    multipliers,</span><br><span class="line">    multipliers - ep.mean(multipliers, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>),</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>最后求出梯度的估计量，并单位化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grad = ep.mean(atleast_kd(vals, rv.ndim) * rv, axis=<span class="number">0</span>)</span><br><span class="line">grad /= ep.norms.l2(atleast_kd(flatten(grad), grad.ndim)) + <span class="number">1e-12</span></span><br></pre></td></tr></table></figure><h3 id="选择合适的扰动大小"><a href="#选择合适的扰动大小" class="headerlink" title="选择合适的扰动大小"></a>选择合适的扰动大小</h3><p>HSJA论文中这部分证明比较硬核，我所学知识有限，实在无法理解。大概意思是控制扰动大小的参数delta与估计误差有很大关系，因此需要谨慎选择。</p><p>常量gamma的值在论文中并没有，而是作为经验参数，默认为1.0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">select_delta</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">    self, originals: ep.Tensor, distances: ep.Tensor, step: <span class="built_in">int</span></span></span></span><br><span class="line"><span class="function"><span class="params"></span>) -&gt; ep.Tensor:</span></span><br><span class="line">    result: ep.Tensor</span><br><span class="line">    <span class="keyword">if</span> step == <span class="number">0</span>:</span><br><span class="line">        result = <span class="number">0.1</span> * ep.ones_like(distances)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        d = np.prod(originals.shape[<span class="number">1</span>:])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.constraint == <span class="string">&quot;linf&quot;</span>:</span><br><span class="line">            theta = self.gamma / (d * d)</span><br><span class="line">            result = d * theta * distances</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            theta = self.gamma / (d * np.sqrt(d))</span><br><span class="line">            result = np.sqrt(d) * theta * distances</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h3 id="二分搜索逼近边界"><a href="#二分搜索逼近边界" class="headerlink" title="二分搜索逼近边界"></a>二分搜索逼近边界</h3><p>上述梯度估计的重要前提之一是对抗样本xt要刚好处于边界，如果并不处于边界的话，就需要用二分搜索来逼近边界。</p><p>HSJA算法将Lp-projection与二分搜索相结合。在Lp-projection中，参数alpha的值越大，新对抗样本距离原始样本就越远，alpha值越小，新对抗样本距离原始样本就越近。</p><p>以下结合代码来理解该二分搜索的步骤，初始时，设置alpha的上界、下界分别为0、1。（Linf时上界不可能超过当前无穷范数距离，因此上界初始化为Linf的值）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> self.constraint == <span class="string">&quot;linf&quot;</span>:</span><br><span class="line">    highs = linf(originals, perturbed)</span><br><span class="line">    thresholds = highs * self.gamma / (d * d)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    highs = ep.ones(perturbed, <span class="built_in">len</span>(perturbed))</span><br><span class="line">    thresholds = self.gamma / (d * math.sqrt(d))</span><br><span class="line">lows = ep.zeros_like(highs)</span><br></pre></td></tr></table></figure></p><p>当新对抗样本攻击成功时，将上界调低一点；当新对抗样本攻击失败时，将下界调高一点。如果上下界差距超过预先定义的thresholds就停止搜索。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> ep.<span class="built_in">any</span>(highs - lows &gt; thresholds):</span><br><span class="line">    mids = (lows + highs) / <span class="number">2</span></span><br><span class="line">    mids_perturbed = self._project(originals, perturbed, mids)</span><br><span class="line">    is_adversarial_ = is_adversarial(mids_perturbed)</span><br><span class="line"></span><br><span class="line">    highs = ep.where(is_adversarial_, mids, highs)</span><br><span class="line">    lows = ep.where(is_adversarial_, lows, mids)</span><br></pre></td></tr></table></figure></p><p>以上步骤中有一个注意点：用变量highs中存储的所有alpha值来做Lp-projection，都可以攻击成功。利用这个trick，把最终生成的对抗样本再通过highs进行Lp-projection，确保输出的对抗样本都能攻击成功。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">res = self._project(originals, perturbed, highs)</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1904.02144&quot;&gt;HopSkipJumpAttack&lt;/a&gt;是发表于2020年S&amp;amp;P的论文，提出了一种新型黑盒对抗攻击的方法，利用采样+逼近的思路来生成对抗样本，理论基础完备，实验效果达到了SOTA。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Papers" scheme="http://xinlu.cool/categories/Papers/"/>
    
    
      <category term="Machine Learning" scheme="http://xinlu.cool/tags/Machine-Learning/"/>
    
      <category term="Adversarial Example" scheme="http://xinlu.cool/tags/Adversarial-Example/"/>
    
      <category term="Black-box Attack" scheme="http://xinlu.cool/tags/Black-box-Attack/"/>
    
  </entry>
  
  <entry>
    <title>实验室服务器虚拟环境配置日志</title>
    <link href="http://xinlu.cool/Manuals/server-configuration/"/>
    <id>http://xinlu.cool/Manuals/server-configuration/</id>
    <published>2020-12-30T07:36:29.000Z</published>
    <updated>2021-03-24T05:59:48.672Z</updated>
    
    <content type="html"><![CDATA[<p>使用LXD虚拟化技术为实验室服务器配置多用户隔离运行环境。</p><a id="more"></a><h2 id="服务器监控netdata配置"><a href="#服务器监控netdata配置" class="headerlink" title="服务器监控netdata配置"></a>服务器监控netdata配置</h2><ul><li><p><a href="https://learn.netdata.cloud/docs/get">netdata一行命令安装</a></p></li><li><p><a href="https://learn.netdata.cloud/docs/agent/packaging/installer/methods/manual">netdata依赖库安装</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bash &lt;(curl -Ss https://my-netdata.io/kickstart.sh) --stable-channel --disable-telemetry</span><br><span class="line">sudo apt-get install zlib1g-dev uuid-dev libuv1-dev liblz4-dev libjudy-dev libssl-dev libelf-dev libmnl-dev gcc make git autoconf autoconf-archive autogen automake pkg-config curl python cmake</span><br></pre></td></tr></table></figure><ul><li>后续管理命令</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl <span class="built_in">enable</span> netdata <span class="comment"># 注册系统服务</span></span><br><span class="line">sudo systemctl start/stop/status netdata <span class="comment"># 启动/暂停/查看</span></span><br><span class="line">cat /etc/netdata/netdata.conf <span class="comment"># 查看配置文件</span></span><br><span class="line">sudo sh /usr/libexec/netdata/netdata-uninstaller.sh <span class="comment"># 卸载</span></span><br><span class="line">sudo sh /usr/libexec/netdata/netdata-updater.sh <span class="comment"># 更新（默认每天更新）</span></span><br></pre></td></tr></table></figure><ul><li><a href="https://github.com/coraxx/netdata_nv_plugin">n卡监控插件</a>，<a href="https://github.com/coraxx/netdata_nv_plugin">配置文件更新</a></li></ul><h2 id="容器管理LXD配置"><a href="#容器管理LXD配置" class="headerlink" title="容器管理LXD配置"></a>容器管理LXD配置</h2><h3 id="安装容器管理系统lxd、文件系统zfs、网络桥接工具bridge-utils"><a href="#安装容器管理系统lxd、文件系统zfs、网络桥接工具bridge-utils" class="headerlink" title="安装容器管理系统lxd、文件系统zfs、网络桥接工具bridge-utils"></a>安装容器管理系统<code>lxd</code>、文件系统<code>zfs</code>、网络桥接工具<code>bridge-utils</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo snap install lxd</span><br><span class="line">sudo apt install zfsutils-linux bridge-utils</span><br></pre></td></tr></table></figure><h3 id="初始化lxd"><a href="#初始化lxd" class="headerlink" title="初始化lxd"></a>初始化<code>lxd</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">sudo lxd init</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下为初始化配置</span></span><br><span class="line"></span><br><span class="line">Would you like to use LXD clustering? (yes/no) [default=no]:<span class="comment"># 单机部署，不用集群</span></span><br><span class="line">Do you want to configure a new storage pool? (yes/no) [default=yes]:<span class="comment"># 在SSD上新建zfs存储池</span></span><br><span class="line">Name of the new storage pool [default=default]: lxd<span class="comment"># 命名存储池</span></span><br><span class="line">Name of the storage backend to use (btrfs, ceph, dir, lvm, zfs) [default=zfs]:<span class="comment"># zfs是坠吼的</span></span><br><span class="line">Create a new ZFS pool? (yes/no) [default=yes]:<span class="comment"># 二次确认</span></span><br><span class="line">Would you like to use an existing block device? (yes/no) [default=no]:<span class="comment"># 试过点yes，没成功，那算了</span></span><br><span class="line">Size <span class="keyword">in</span> GB of the new loop device (1GB minimum) [default=100GB]: 360GB<span class="comment"># 比SSD总容量小一点就行</span></span><br><span class="line">Would you like to connect to a MAAS server? (yes/no) [default=no]:<span class="comment"># no</span></span><br><span class="line">Would you like to create a new <span class="built_in">local</span> network bridge? (yes/no) [default=yes]:<span class="comment"># 建立容器到主机之间的桥接机制</span></span><br><span class="line">Would you like to configure LXD to use an existing bridge or host interface? (yes/no) [default=no]:<span class="comment"># no</span></span><br><span class="line">Name of the existing bridge or host interface:<span class="comment"># 命名虚拟桥接网卡</span></span><br><span class="line">Would you like LXD to be available over the network? (yes/no) [default=no]:<span class="comment"># 不要暴露容器，访问容器只用端口映射</span></span><br><span class="line">Would you like stale cached images to be updated automatically? (yes/no) [default=yes]<span class="comment"># 定期更新镜像</span></span><br><span class="line">Would you like a YAML <span class="string">&quot;lxd init&quot;</span> preseed to be printed? (yes/no) [default=no]:<span class="comment"># 不保存初始配置</span></span><br></pre></td></tr></table></figure><h3 id="配置lxd的默认profile"><a href="#配置lxd的默认profile" class="headerlink" title="配置lxd的默认profile"></a>配置<code>lxd</code>的默认<code>profile</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc profile edit default</span><br></pre></td></tr></table></figure><h3 id="配置示例（yaml格式）"><a href="#配置示例（yaml格式）" class="headerlink" title="配置示例（yaml格式）"></a>配置示例（yaml格式）</h3><p>注意，块设备<code>nvidia-uvm</code>对容器内访问显卡驱动非常重要</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">config:</span></span><br><span class="line">  <span class="attr">limits.cpu:</span> <span class="string">&quot;32&quot;</span></span><br><span class="line">  <span class="attr">limits.memory:</span> <span class="string">64GB</span></span><br><span class="line">  <span class="attr">security.nesting:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">  <span class="attr">security.privileged:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">Default</span> <span class="string">LXD</span> <span class="string">profile</span></span><br><span class="line"><span class="attr">devices:</span></span><br><span class="line">  <span class="attr">eth0:</span></span><br><span class="line">    <span class="attr">limits.ingress:</span> <span class="string">200Mbit</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">eth0</span></span><br><span class="line">    <span class="attr">nictype:</span> <span class="string">bridged</span></span><br><span class="line">    <span class="attr">parent:</span> <span class="string">lxdbr0</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">nic</span></span><br><span class="line">  <span class="attr">gpu:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">gpu</span></span><br><span class="line">  <span class="attr">nvidia-uvm:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/dev/nvidia-uvm</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">unix-char</span></span><br><span class="line">  <span class="attr">root:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">    <span class="attr">pool:</span> <span class="string">default</span></span><br><span class="line">    <span class="attr">size:</span> <span class="string">30GB</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">disk</span></span><br><span class="line">  <span class="attr">shared-folder:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/usr/local/shared-folder</span></span><br><span class="line">    <span class="attr">source:</span> <span class="string">/usr/local/shared-folder</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">disk</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">used_by:</span> []</span><br></pre></td></tr></table></figure><h3 id="从清华大学镜像加速站点拉取最新的ubuntu-18-04系统镜像"><a href="#从清华大学镜像加速站点拉取最新的ubuntu-18-04系统镜像" class="headerlink" title="从清华大学镜像加速站点拉取最新的ubuntu 18.04系统镜像"></a>从清华大学镜像加速站点拉取最新的<code>ubuntu 18.04</code>系统镜像</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc remote add tuna-images https://mirrors.tuna.tsinghua.edu.cn/lxc-images/ --protocol=simplestreams --public</span><br><span class="line">sudo lxc image list tuna-images:<span class="comment"># 显示可供下载的镜像列表</span></span><br><span class="line">sudo lxc launch tuna-images:&lt;<span class="built_in">hash</span>&gt; &lt;ContianerName&gt;<span class="comment"># 从清华镜像站点拉取镜像，在本地创建容器</span></span><br></pre></td></tr></table></figure><h3 id="安装容器监控设施lxdui，并注册为系统服务"><a href="#安装容器监控设施lxdui，并注册为系统服务" class="headerlink" title="安装容器监控设施lxdui，并注册为系统服务"></a>安装容器监控设施<code>lxdui</code>，并注册为系统服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install -y git build-essential libssl-dev python3-venv python3-pip python3-dev zfsutils-linux bridge-utils</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/AdaptiveScale/lxdui.git</span><br><span class="line"><span class="built_in">cd</span> lxdui</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下用root用户安装（不嫌麻烦的话可以新建一个用户组来管理lxdui）</span></span><br><span class="line"></span><br><span class="line">sudo su</span><br><span class="line">pip3 install .</span><br><span class="line">su &lt;PreviousUserName&gt;</span><br></pre></td></tr></table></figure><p>参考<a href="https://medium.com/@benmorel/creating-a-linux-service-with-systemd-611b5c8b91d6">注册Linux系统服务教程</a>、<a href="https://github.com/AdaptiveScale/lxdui/blob/master/lxdui.service">lxdui官方参考unit文件</a>，创建<code>/etc/systemd/system/lxdui.service</code>文件</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[Unit]</span></span><br><span class="line"><span class="attr">Description</span>=Web UI for the native Linux container technology LXD/LXC</span><br><span class="line"><span class="attr">After</span>=network.target snapd.service</span><br><span class="line"><span class="attr">Requires</span>=snapd.service</span><br><span class="line"></span><br><span class="line"><span class="section">[Service]</span></span><br><span class="line"><span class="attr">Type</span>=simple</span><br><span class="line"><span class="attr">Restart</span>=always</span><br><span class="line"><span class="attr">RestartSec</span>=<span class="number">10</span></span><br><span class="line"><span class="attr">User</span>=root</span><br><span class="line"><span class="attr">PIDFile</span>=/run/lxdui/lxdui.pid</span><br><span class="line"><span class="attr">ExecStart</span>=/usr/local/bin/lxdui start</span><br><span class="line"><span class="attr">ExecStop</span>=/usr/local/bin/lxdui stop</span><br><span class="line"></span><br><span class="line"><span class="section">[Install]</span></span><br><span class="line"><span class="attr">WantedBy</span>=multi-user.target</span><br></pre></td></tr></table></figure><p>启动服务，默认用户名<code>admin</code>，默认密码<code>admin</code>，默认端口<code>15151</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl <span class="built_in">enable</span> lxdui</span><br><span class="line">sudo systemctl start lxdui</span><br><span class="line">sudo ufw allow from &lt;SubnetIPAddress&gt;/&lt;LengthOfSubnetMask&gt; to any port 15151</span><br></pre></td></tr></table></figure><h2 id="配置模板容器GPU环境"><a href="#配置模板容器GPU环境" class="headerlink" title="配置模板容器GPU环境"></a>配置模板容器GPU环境</h2><h3 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc <span class="built_in">exec</span> &lt;ContainerName&gt; -- su --login &lt;UserName&gt;</span><br></pre></td></tr></table></figure><h3 id="配置sudo免密码"><a href="#配置sudo免密码" class="headerlink" title="配置sudo免密码"></a>配置<code>sudo</code>免密码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo su root</span><br><span class="line">visudo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在用户权限配置文件中加以下行</span></span><br><span class="line"></span><br><span class="line">&lt;UserName&gt; ALL=(ALL) NOPASSWD: NOPASSWD: ALL</span><br></pre></td></tr></table></figure><h3 id="参考tuna官方使用帮助，切换apt源到清华大学镜像加速站点"><a href="#参考tuna官方使用帮助，切换apt源到清华大学镜像加速站点" class="headerlink" title="参考tuna官方使用帮助，切换apt源到清华大学镜像加速站点"></a>参考<a href="https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/">tuna官方使用帮助</a>，切换<code>apt</code>源到清华大学镜像加速站点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak</span><br><span class="line">sudo vi /etc/apt/sources.list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下为新的apt源url列表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预发布软件源，不建议启用</span></span><br><span class="line"><span class="comment"># deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse</span></span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse</span></span><br></pre></td></tr></table></figure><h3 id="下载显卡驱动、CUDA-10-1安装包、cuDNN-7-6-5压缩包"><a href="#下载显卡驱动、CUDA-10-1安装包、cuDNN-7-6-5压缩包" class="headerlink" title="下载显卡驱动、CUDA 10.1安装包、cuDNN 7.6.5压缩包"></a>下载显卡驱动、<code>CUDA 10.1</code>安装包、<code>cuDNN 7.6.5</code>压缩包</h3><p><a href="https://www.nvidia.com/en-us/drivers/unix/linux-amd64-display-archive/">NVIDIA Driver Linux x86_64 Archive</a></p><p><a href="https://developer.nvidia.com/cuda-toolkit-archive">CUDA Archive</a></p><p><a href="https://developer.nvidia.com/rdp/cudnn-archive">cuDNN Archive</a></p><h3 id="参考官方文档，配置CUDA-10-1"><a href="#参考官方文档，配置CUDA-10-1" class="headerlink" title="参考官方文档，配置CUDA 10.1"></a>参考<a href="https://docs.nvidia.com/cuda/archive/10.1/">官方文档</a>，配置<code>CUDA 10.1</code></h3><p>检查<code>GPU</code>硬件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install pciutils</span><br><span class="line">lspci | grep -i nvidia</span><br></pre></td></tr></table></figure><p>检查<code>Linux</code>发行版</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uname -m &amp;&amp; cat /etc/*release</span><br></pre></td></tr></table></figure><p>检查<code>gcc</code>是否安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gcc --version</span><br><span class="line">sudo apt install build-essential manpages-dev<span class="comment"># 安装gcc，g++，make以及相关文档</span></span><br></pre></td></tr></table></figure><p>安装<code>Ubuntu</code>系统的内核依赖</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install linux-headers-$(uname -r)</span><br></pre></td></tr></table></figure><p>从下载好的可执行文件安装显卡驱动、<code>CUDA 10.1</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo sh NVIDIA-Linux-x86_64-&lt;DirverVersion&gt;.run --no-kernel-module</span><br><span class="line">sudo sh cuda_&lt;CUDAVersion&gt;_linux.run --no-drm</span><br></pre></td></tr></table></figure><p>添加环境变量到<code>~/.bashrc</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bashrc</span><br><span class="line"></span><br><span class="line"><span class="comment"># CUDA 10.1</span></span><br><span class="line">PATH=/usr/<span class="built_in">local</span>/cuda-10.1/bin:/usr/<span class="built_in">local</span>/cuda-10.1/NsightCompute-2019.1<span class="variable">$&#123;PATH:+:<span class="variable">$&#123;PATH&#125;</span>&#125;</span></span><br><span class="line">LD_LIBRARY_PATH=/usr/<span class="built_in">local</span>/cuda-10.1/lib64<span class="variable">$&#123;LD_LIBRARY_PATH:+:<span class="variable">$&#123;LD_LIBRARY_PATH&#125;</span>&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure><p>最后，检查驱动版本和<code>CUDA</code>版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/driver/nvidia/version</span><br><span class="line">nvcc -V</span><br></pre></td></tr></table></figure><p><strong>[Optional]</strong>编译示例代码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> &lt;SampleRootPath&gt;</span><br><span class="line"><span class="built_in">cd</span> 1_Utilities/deviceQuery</span><br><span class="line">make</span><br><span class="line">./deviceQuery</span><br></pre></td></tr></table></figure><p><strong>[Optional]</strong>开启<code>persistent</code>模式</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /usr/bin/nvidia-persistenced --verbose</span><br></pre></td></tr></table></figure><h3 id="参考官方文档，配置cuDNN-7-6-5"><a href="#参考官方文档，配置cuDNN-7-6-5" class="headerlink" title="参考官方文档，配置cuDNN 7.6.5"></a>参考<a href="https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn_765/cudnn-install/index.html">官方文档</a>，配置<code>cuDNN 7.6.5</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> &lt;CudnnPath&gt;</span><br><span class="line">tar -xzvf cudnn-&lt;CudnnVersion&gt;.tgz</span><br><span class="line">sudo cp cuda/include/cudnn.h /usr/<span class="built_in">local</span>/cuda/include</span><br><span class="line">sudo cp cuda/lib64/libcudnn* /usr/<span class="built_in">local</span>/cuda/lib64</span><br><span class="line">sudo chmod a+r /usr/<span class="built_in">local</span>/cuda/include/cudnn.h /usr/<span class="built_in">local</span>/cuda/lib64/libcudnn*</span><br></pre></td></tr></table></figure><h2 id="配置模板容器Python环境"><a href="#配置模板容器Python环境" class="headerlink" title="配置模板容器Python环境"></a>配置模板容器Python环境</h2><h3 id="下载Python-3-7-9源代码"><a href="#下载Python-3-7-9源代码" class="headerlink" title="下载Python 3.7.9源代码"></a>下载<code>Python 3.7.9</code>源代码</h3><p><a href="https://developer.nvidia.com/rdp/cudnn-archive">Python Source Code Download Page</a></p><h3 id="解压、安装依赖"><a href="#解压、安装依赖" class="headerlink" title="解压、安装依赖"></a>解压、安装依赖</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf Python-3.7.9.tgz</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install -y gcc make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-dev</span><br></pre></td></tr></table></figure><h3 id="配置编译参数"><a href="#配置编译参数" class="headerlink" title="配置编译参数"></a>配置编译参数</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> Python-3.7.9</span><br><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/python3.7 --enable-optimizations</span><br></pre></td></tr></table></figure><h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo make -j 32 &amp;&amp; sudo make install</span><br></pre></td></tr></table></figure><h3 id="添加环境变量"><a href="#添加环境变量" class="headerlink" title="添加环境变量"></a>添加环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bashrc</span><br><span class="line"></span><br><span class="line"><span class="comment"># Python 3.7</span></span><br><span class="line">PATH=/usr/<span class="built_in">local</span>/python3.7/bin<span class="variable">$&#123;PATH:+:<span class="variable">$&#123;PATH&#125;</span>&#125;</span></span><br><span class="line">PATH=/home/ubuntu/.<span class="built_in">local</span>/bin<span class="variable">$&#123;PATH:+:<span class="variable">$&#123;PATH&#125;</span>&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line">sudo chown -R &lt;UserName&gt; ~/.<span class="built_in">local</span></span><br></pre></td></tr></table></figure><h3 id="配置清华大学镜像加速站点pip源"><a href="#配置清华大学镜像加速站点pip源" class="headerlink" title="配置清华大学镜像加速站点pip源"></a>配置清华大学镜像加速站点<code>pip</code>源</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python3.7 -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pip -U --user</span><br><span class="line">python3.7 -m pip config <span class="built_in">set</span> global.index-url https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"></span><br><span class="line"><span class="comment"># 阿里云可能更快一点</span></span><br><span class="line">python3.7 -m pip config <span class="built_in">set</span> global.index-url https://mirrors.aliyun.com/pypi/simple</span><br></pre></td></tr></table></figure><h3 id="举例：如何在用户空间下通过pip安装包（没有必要就不要sudo）"><a href="#举例：如何在用户空间下通过pip安装包（没有必要就不要sudo）" class="headerlink" title="举例：如何在用户空间下通过pip安装包（没有必要就不要sudo）"></a>举例：如何在用户空间下通过<code>pip</code>安装包（没有必要就不要<code>sudo</code>）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3.7 -m pip install numpy virtualenv --user --no-cache-dir</span><br></pre></td></tr></table></figure><h3 id="举例：如何在项目文件夹内配置虚拟环境"><a href="#举例：如何在项目文件夹内配置虚拟环境" class="headerlink" title="举例：如何在项目文件夹内配置虚拟环境"></a>举例：如何在项目文件夹内配置虚拟环境</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">python3.7 -m virtualenv ./.venv/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 激活虚拟环境</span></span><br><span class="line"><span class="built_in">source</span> ./venv/bin/activate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在虚拟环境中运行程序</span></span><br><span class="line">python &lt;PythonFileName&gt;.py</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在虚拟程序中安装包</span></span><br><span class="line">python -m pip install numpy --no-cache-dir</span><br><span class="line"></span><br><span class="line"><span class="comment"># 退出虚拟环境</span></span><br><span class="line">deactivate</span><br></pre></td></tr></table></figure><h3 id="安装pytorch和tensorflow"><a href="#安装pytorch和tensorflow" class="headerlink" title="安装pytorch和tensorflow"></a>安装<code>pytorch</code>和<code>tensorflow</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3.7 -m pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html --user --no-cache-dir</span><br><span class="line">python3.7 -m pip install tensorflow-gpu==2.3.1 --user --no-cache-dir</span><br></pre></td></tr></table></figure><h3 id="测试是否能用GPU"><a href="#测试是否能用GPU" class="headerlink" title="测试是否能用GPU"></a>测试是否能用<code>GPU</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">print(torch.cuda.is_available())</span><br><span class="line">print(torch.cuda.device_count())</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.test.is_gpu_available())</span><br></pre></td></tr></table></figure><h2 id="一键添加-删除用户脚本"><a href="#一键添加-删除用户脚本" class="headerlink" title="一键添加/删除用户脚本"></a>一键添加/删除用户脚本</h2><h3 id="导出模板容器为镜像"><a href="#导出模板容器为镜像" class="headerlink" title="导出模板容器为镜像"></a>导出模板容器为镜像</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo lxc stop &lt;ContainerName&gt;</span><br><span class="line">sudo lxc publish &lt;ContainerName&gt; --<span class="built_in">alias</span> &lt;NewImageName&gt; --public</span><br></pre></td></tr></table></figure><h3 id="服务器端添加用户脚本"><a href="#服务器端添加用户脚本" class="headerlink" title="服务器端添加用户脚本"></a>服务器端添加用户脚本</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;用户名是： &quot;</span><span class="variable">$1</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;该用户的ssh端口是： &quot;</span><span class="variable">$2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从配好的镜像文件中启动新的容器</span></span><br><span class="line">sudo lxc launch &lt;ImageName&gt; <span class="variable">$1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 必须等待容器网络配置好，否则无法安装openssh</span></span><br><span class="line">sleep 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># 挂载固态硬盘</span></span><br><span class="line"><span class="keyword">if</span> [ ! -d /mnt/data/<span class="variable">$&#123;1&#125;</span> ] ; <span class="keyword">then</span></span><br><span class="line">mkdir /mnt/data/<span class="variable">$&#123;1&#125;</span>/</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">sudo lxc config device add <span class="variable">$1</span> data disk <span class="built_in">source</span>=/mnt/data/<span class="variable">$&#123;1&#125;</span>/ path=/mnt/data</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;成功挂载固态硬盘！&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建存放对称秘钥的文件夹</span></span><br><span class="line"><span class="keyword">if</span> [ ! -d /home/<span class="variable">$&#123;ServerUserName&#125;</span>/keys ] ; <span class="keyword">then</span></span><br><span class="line">mkdir /home/<span class="variable">$&#123;ServerUserName&#125;</span>/keys</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -d /usr/<span class="built_in">local</span>/shared-folder/keys ] ; <span class="keyword">then</span></span><br><span class="line">sudo mkdir /usr/<span class="built_in">local</span>/shared-folder/keys</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装容器中的openssh</span></span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo apt update</span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo apt install -y openssh-server</span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo service ssh start</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;容器内的ssh服务已启动！&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 备份原来的sshd配置</span></span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加上写入权限</span></span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo chmod a+w /etc/ssh/sshd_config</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写入新的sshd配置</span></span><br><span class="line">sshd_config=<span class="string">&quot;Port <span class="variable">$&#123;2&#125;</span></span></span><br><span class="line"><span class="string">AddressFamily any</span></span><br><span class="line"><span class="string">ListenAddress 0.0.0.0</span></span><br><span class="line"><span class="string">ListenAddress ::</span></span><br><span class="line"><span class="string">PubkeyAuthentication yes</span></span><br><span class="line"><span class="string">AuthorizedKeysFile      .ssh/authorized_keys</span></span><br><span class="line"><span class="string">PasswordAuthentication no</span></span><br><span class="line"><span class="string">Subsystem       sftp    /usr/lib/openssh/sftp-server</span></span><br><span class="line"><span class="string">AllowUsers ubuntu</span></span><br><span class="line"><span class="string">UsePAM yes&quot;</span></span><br><span class="line"></span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sh -c <span class="string">&quot;cat&gt;/etc/ssh/sshd_config&lt;&lt;EOF</span></span><br><span class="line"><span class="string"><span class="variable">$&#123;sshd_config&#125;</span></span></span><br><span class="line"><span class="string">EOF&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 恢复文件权限</span></span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo chmod 644 /etc/ssh/sshd_config</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;已生成新的sshd配置文件！&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在宿主机上生成rsa-2048密钥</span></span><br><span class="line">ssh-keygen -b 2048 -t rsa -f /home/&lt;UserName&gt;/keys/id_rsa_<span class="variable">$1</span> -q -N <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;新密钥已生成！&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 把公钥拷贝到共享目录下</span></span><br><span class="line">sudo chmod a+r /home/&lt;UserName&gt;/keys/id_rsa_<span class="variable">$1</span></span><br><span class="line">sudo cp /home/&lt;UserName&gt;/keys/id_rsa_<span class="variable">$1</span>.pub /usr/<span class="built_in">local</span>/shared-folder/keys/id_rsa_<span class="variable">$1</span>.pub</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;公钥已写入共享目录下！&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 把公钥写入.ssh文件夹下</span></span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo mkdir /home/ubuntu/.ssh</span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo touch /home/ubuntu/.ssh/authorized_keys</span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo chmod a+w /home/ubuntu/.ssh/authorized_keys</span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sh -c <span class="string">&quot;sudo cat /usr/local/shared-folder/keys/id_rsa_<span class="variable">$1</span>.pub &gt;&gt; /home/ubuntu/.ssh/authorized_keys&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 恢复.ssh目录的属主和文件权限</span></span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo chown -R ubuntu /home/ubuntu/.ssh</span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo chmod 700 /home/ubuntu/.ssh</span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo chmod 644 /home/ubuntu/.ssh/authorized_keys</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;公钥已写入.ssh文件夹！&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启ssh服务</span></span><br><span class="line">sudo lxc <span class="built_in">exec</span> <span class="variable">$1</span> -- sudo service ssh restart</span><br><span class="line"></span><br><span class="line"><span class="comment"># 端口映射</span></span><br><span class="line">sudo lxc config device add <span class="variable">$1</span> port-ssh proxy listen=tcp:0.0.0.0:<span class="variable">$2</span> connect=tcp:127.0.0.1:<span class="variable">$2</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;容器内的ssh服务和端口配置完成！&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启防火墙</span></span><br><span class="line">sudo ufw allow <span class="variable">$2</span>/tcp</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;防火墙端口<span class="variable">$2</span>已放通！&quot;</span></span><br></pre></td></tr></table></figure><h3 id="管理员PC端添加用户脚本"><a href="#管理员PC端添加用户脚本" class="headerlink" title="管理员PC端添加用户脚本"></a>管理员PC端添加用户脚本</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;用户名是： &quot;</span><span class="variable">$1</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;该用户的ssh端口是： &quot;</span><span class="variable">$2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从远端服务器下载私钥</span></span><br><span class="line">scp -P &lt;PortNumber&gt; &lt;UserName&gt;@&lt;ServerIPAddress&gt;:/home/&lt;UserName&gt;/keys/id_rsa_<span class="variable">$1</span> /home/&lt;LocalUserName&gt;/keys/id_rsa_<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ssh密钥权限是600，切记切记 :)</span></span><br><span class="line">sudo chmod 600 /home/&lt;LocalUserName&gt;/keys/id_rsa_<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 尝试连接</span></span><br><span class="line">ssh -i /home/&lt;LocalUserName&gt;/keys/id_rsa_<span class="variable">$1</span> ubuntu@&lt;ServerIPAddress&gt; -p <span class="variable">$2</span></span><br></pre></td></tr></table></figure><h3 id="服务器端删除用户脚本"><a href="#服务器端删除用户脚本" class="headerlink" title="服务器端删除用户脚本"></a>服务器端删除用户脚本</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;即将删除容器 <span class="variable">$1</span> 相关配置，端口号 <span class="variable">$2</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除本地保存的秘钥</span></span><br><span class="line">rm /home/&lt;UserName&gt;/keys/id_rsa_<span class="variable">$1</span>*</span><br><span class="line">sudo rm /usr/<span class="built_in">local</span>/shared-folder/keys/id_rsa_<span class="variable">$1</span>*</span><br><span class="line"></span><br><span class="line"><span class="comment"># 暂停容器</span></span><br><span class="line">sudo lxc stop <span class="variable">$1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除容器</span></span><br><span class="line">sudo lxc delete <span class="variable">$1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除防火墙规则</span></span><br><span class="line">sudo ufw delete allow <span class="variable">$2</span>/tcp</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;容器已经删除！&quot;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用LXD虚拟化技术为实验室服务器配置多用户隔离运行环境。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Manuals" scheme="http://xinlu.cool/categories/Manuals/"/>
    
    
      <category term="LXD" scheme="http://xinlu.cool/tags/LXD/"/>
    
      <category term="Netdata" scheme="http://xinlu.cool/tags/Netdata/"/>
    
      <category term="CUDA" scheme="http://xinlu.cool/tags/CUDA/"/>
    
      <category term="Tensorflow" scheme="http://xinlu.cool/tags/Tensorflow/"/>
    
      <category term="Pytorch" scheme="http://xinlu.cool/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>以std::mutex为基础，探索线程间共享数据的方法</title>
    <link href="http://xinlu.cool/Reading-Notes/cppconcurrency-2/"/>
    <id>http://xinlu.cool/Reading-Notes/cppconcurrency-2/</id>
    <published>2020-07-21T04:17:37.000Z</published>
    <updated>2021-01-20T02:16:14.571Z</updated>
    
    <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>多线程编程的优势之一在于线程间共享数据的开销很小。</p><p>“灵活地在线程间共享数据，最大化地利用并发处理优势“，听起来很美好，实际上处处是坑。</p><a id="more"></a><ul><li>多个线程对同一个数据结构的读写操作，如果处理不好，就会出现“脏读”、“幻读”等bug（借用数据库中的概念）；</li><li>使用锁机制来保护共享的数据，如果多个线程分别持有不同的锁，却互相请求对方持有的锁，就会出现“死锁”bug（极难复现调试）；</li><li>锁的粒度设计太大，就无法充分利用多线程并发的速度优势；</li><li>锁的粒度设计太小，出现bug的可能性也随之增加，逼迫程序员付出大量心智成本；</li></ul><p>C++ Concurrency in Action认为，使用多线程共享数据的坑主要有两个：</p><ul><li>problematic race condition</li><li>deadlock</li></ul><p>如何利用C++ STL和boost中的facilities来规避大坑、并且设计出良好的代码结构，是这里讨论的重点。</p><h1 id="Race-Condition"><a href="#Race-Condition" class="headerlink" title="Race Condition"></a>Race Condition</h1><p>如果数据是read-only的，那么多线程操作不会带来任何问题，但如果可读可写，那么多线程读写的顺序就会带来一系列问题（毕竟，不加锁的情况下，没法控制多个并发线程执行顺序），这里就引入了“线程竞态”（race condition）的概念。</p><h2 id="什么是race-condition，它会给多线程编程带来什么？"><a href="#什么是race-condition，它会给多线程编程带来什么？" class="headerlink" title="什么是race condition，它会给多线程编程带来什么？"></a>什么是race condition，它会给多线程编程带来什么？</h2><p>如果多个线程执行同一操作的结果依赖于多个线程的执行顺序（顺序不同，结果不同），那么这就叫race condition。</p><p>race condition并不一定是坏事，多个用户线程的竞争用在抢票系统、抢红包系统上就没有问题。真正有问题的是<strong>problematic race condition</strong>。C++标准中定义的<strong>data race</strong>就是一种problematic race condition，它表示并发地对同一个对象进行修改，这是一个undefined behavior。</p><p>problematic race condition常常发生在一个操作要修改多个数据的情形下。例如，在删除双向链表中的一个元素时，我们需要对三个链表元素（节点a、待删除节点b、节点c）进行操作，那么在删除的过程中，</p><ol><li>必然会先破坏原有数据结构（节点a的后指针指向节点c，但节点c的前指针还指向待删除的节点b），</li><li>然后再恢复数据结构（节点a、c相连，但节点b的前指针和后指针还没变），</li><li>最后进行删除操作（delete 节点b），</li></ol><p>在这一过程中，其他线程可能在删除操作尚未结束时读取到错误的链表数据。</p><h2 id="如何防止problematic-race-condition"><a href="#如何防止problematic-race-condition" class="headerlink" title="如何防止problematic race condition"></a>如何防止problematic race condition</h2><p>C++ Concurrency in Action介绍了三种防止problematic race condition的方法：</p><ol><li>在数据结构外包裹一层保护机制（protection mechanism）</li><li>修改数据结构的接口，让修改操作原子化（indivisible）</li><li>把修改操作当做“事务”（transaction）来处理，实现all-or-nothing的效果</li></ol><p>利用 <code>std::mutex</code> 的相关机制，可以灵活地选用方法1或方法2，来设计出线程安全的数据结构。</p><h2 id="线程安全的list"><a href="#线程安全的list" class="headerlink" title="线程安全的list"></a>线程安全的list</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;list&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">list</span>&lt;<span class="keyword">int</span>&gt; some_list;</span><br><span class="line"><span class="built_in">std</span>::mutex some_mutex;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">add_to_list</span><span class="params">(<span class="keyword">int</span> new_value)</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">guard</span><span class="params">(some_mutex)</span></span>;</span><br><span class="line">    some_list.push_back(new_value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">list_contains</span><span class="params">(<span class="keyword">int</span> value_to_find)</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">guard</span><span class="params">(some_mutex)</span></span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">std</span>::find(some_list.begin(), some_list.end(), value_to_find) </span><br><span class="line">        != some_list.end();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，被保护的数据结构是 <code>some_list</code> ，<code>some_mutex</code> 被用来标识临界区代码。</p><p>如果某个线程对 <code>some_mutex</code> 上锁，那么其他线程只能等待这个线程解锁，否则无法执行 <code>some_mutex</code> 对应的临界区代码。这样就起到了保护 <code>some_list</code> 内数据不被同时读写的效果。</p><p><code>std::lock_guard&lt;&gt;</code> 对象充分利用了RAII的特性，对象初始化后就上锁，对象被析构时自动解锁，不需要程序员来手动lock和unlock。这是一种好的编程习惯，尽可能地解放程序员，把mutex上锁的周期与另一个对象的生命周期绑定。</p><p>因为C++语言的灵活性，<code>std::mutex</code> 的锁机制并不是一劳永逸的，</p><ul><li>如果被保护的数据被指针传递、引用传递到临界区以外后，就不再受到保护，</li><li>如果临界区代码需要调用用户自定义的函数（恶意地取出数据地址），那么 <code>std::mutex</code> 也无法起到保护作用。</li></ul><h2 id="线程安全的stack"><a href="#线程安全的stack" class="headerlink" title="线程安全的stack"></a>线程安全的stack</h2><p>在讨论线程安全的stack前，有必要回顾一下 <code>std::stack</code> 在设计时避开的坑：为什么 <code>.pop()</code> 操作不返回栈顶元素，而需要让用户先调用 <code>.top()</code> 取出栈顶元素，再 <code>.pop()</code> 出栈？</p><p>为了节约篇幅，这里不作讨论，直接放上结论：</p><ul><li>如果 <code>.pop()</code> 操作允许返回栈顶元素的值，那么必然要把该元素的值copy出来，</li><li>那么，<code>auto a = s.pop()</code> 操作实际上分成了两步：<ul><li>修改 <code>s</code> 的数据结构，去掉栈顶元素，</li><li>调用栈顶元素的 <code>copy assignment operator</code> ，给 <code>a</code> 赋值，</li></ul></li><li>大坑在第二步：如果给 <code>a</code> 赋值的操作 <strong>抛出异常</strong> ，那么就会出现 <strong>栈顶元素已经抛出，但是无法返回</strong> 的情形，那么相当于我们白白丢失了栈顶元素（既不在栈里，也不在栈外），而且没有人知道它的值是啥，这个错误甚至是无法补救的，</li><li>为了防止这个大坑，标准库的设计者把出栈操作设计成两步，让用户先读取，后出栈，</li></ul><p>因此，在 <code>std::stack</code> 的基础上设计线程安全的栈，就是要给 <code>.top() + .pop()</code> 套一层保护机制，既要保护多线程读取的安全性、又要考虑拷贝操作的脆弱性。</p><p>比较直观的方法是逼迫用户只使用copy/move操作不会抛出异常的类，这种方法局限性比较大。以下两种方法更加自然一些。</p><p><strong>方法一：返回一个 <code>std::shared_ptr&lt;&gt;</code></strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::mutex some_mutex;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">stack</span>&lt;T&gt; data;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;T&gt; <span class="title">pop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">guard</span><span class="params">(some_mutex)</span></span>;</span><br><span class="line">    <span class="keyword">if</span> (data.empty()) <span class="keyword">throw</span> empty_stack();</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::shared ptr&lt;T&gt; <span class="keyword">const</span> <span class="title">res</span><span class="params">(<span class="built_in">std</span>::make_shared&lt;T&gt;(data.top()))</span></span>;</span><br><span class="line">    data.pop();</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种方法相当于避开了“拷贝-销毁”的流程，始终只保留一个对象。</p><p><strong>方法二：引用传递</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">pop</span><span class="params">(T&amp; value)</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">guard</span><span class="params">(some_mutex)</span></span>;</span><br><span class="line">    <span class="keyword">if</span> (data.empty()) <span class="keyword">throw</span> empty_stack();</span><br><span class="line">    value = data.top();</span><br><span class="line">    data.pop();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>引用传递的好处是如果copy过程抛出了异常，那么stack就不会被修改。坏处是用户需要提前构造好一个空对象。</p><h1 id="Dead-Lock"><a href="#Dead-Lock" class="headerlink" title="Dead Lock"></a>Dead Lock</h1><p>死锁是一种非常有趣的bug，多个线程在持有锁的同时互相请求对方持有的锁，程序就卡死在这里。</p><p>这个概念第一次在操作系统中学习到，当时探讨了避免死锁、检测死锁、消除死锁的方法，但是在多线程编程中，最好还是从代码设计上根本性地杜绝死锁的产生，毕竟死锁的debug相当相当困难。</p><h2 id="如何防止代码产生死锁？"><a href="#如何防止代码产生死锁？" class="headerlink" title="如何防止代码产生死锁？"></a>如何防止代码产生死锁？</h2><p>死锁一般产生于一个操作需要对多个mutex上锁的场景。C++ Concurrency in Action给出了四条避免死锁的编程指南：</p><ol><li>不要给已经上锁的部分再加锁，</li><li>上锁后避免调用用户自定义的函数，</li><li>如果需要给多个mutex上锁，那就要保证每次操作时加锁的顺序一致，</li><li>将代码按层次切分，每个层次加不同的锁，确保一个固定的顺序（例如，从高层次锁-&gt;低层次锁，否则报错），</li></ol><p>避免死锁需要类的设计者和类的使用者严格地自律、遵守规则。</p><p>以下探讨如何利用C++ STL和Boost的facilities来设计无死锁的代码。</p><h2 id="线程安全的swap-v1-0"><a href="#线程安全的swap-v1-0" class="headerlink" title="线程安全的swap v1.0"></a>线程安全的swap v1.0</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">friend</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(X&amp; lhs, X&amp; rhs)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (&amp;lhs == &amp;rhs) <span class="keyword">return</span>;</span><br><span class="line">    <span class="built_in">std</span>::lock(lhs.m, rhs.m);</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">lock_a</span><span class="params">(lhs.m, <span class="built_in">std</span>::adopt_lock)</span></span>;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">lock_a</span><span class="params">(rhs.m, <span class="built_in">std</span>::adopt_lock)</span></span>;</span><br><span class="line">    swap(lhs.some_detail, rhs.some_detail);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>std::lock()</code>的上锁操作是原子化的，能同时对多个mutex上锁。</p><p>把 <code>std::adopt_lock</code> 作为参数传入 <code>std::lock_guard&lt;&gt;</code> ，就是告诉 <code>lock_a</code> ， <code>lock_b</code> 只需要获得当前mutex的拥有权，不要再给mutex上锁。</p><p>如果 <code>std::lock()</code> 对任何一个mutex上锁失败，那么已经上锁的部分会被释放，实现all-or-nothing的效果。</p><h2 id="层次锁"><a href="#层次锁" class="headerlink" title="层次锁"></a>层次锁</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">hierarchical_mutex <span class="title">high_level_mutex</span><span class="params">(<span class="number">10000</span>)</span></span>;</span><br><span class="line"><span class="function">hierarchical_mutex <span class="title">low_level_mutex</span><span class="params">(<span class="number">5000</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">do_low_level_stuff</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">low_level_func</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::lock_guard&lt;hierarchical_mutex&gt; <span class="title">lk</span><span class="params">(low_level_mutex)</span></span>;</span><br><span class="line">    <span class="keyword">return</span> do_low_level_stuff();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_high_level_stuff</span><span class="params">(<span class="keyword">int</span> some_param)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">high_level_func</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::lock_guard&lt;hierarchical_mutex&gt; <span class="title">lk</span><span class="params">(high_level_mutex)</span></span>;</span><br><span class="line">    do_high_level_stuff(low_level_func());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>把代码分层次，用不同的mutex来控制不同层次的锁。</p><p>当低层次mutex被锁时，高层次mutex不能再上锁，否则在runtime报错。</p><p>10000，5000指的是layer number（第几层），数字越大越先上锁。</p><p>这个 <code>hierarchical_mutex</code> 是自定义的，实现代码比较冗长，这里不展开了。实现的核心是三个变量：</p><ul><li>常量hierarchy_value保存本mutex的层号</li><li>thread_local static变量保存本线程当前运行的层号</li><li>变量previous_hierarchy_value储存本线程之前的层号</li></ul><h2 id="线程安全的swap-v2-0"><a href="#线程安全的swap-v2-0" class="headerlink" title="线程安全的swap v2.0"></a>线程安全的swap v2.0</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">friend</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(X&amp; lhs, X&amp; rhs)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (&amp;lhs == &amp;rhs)<span class="keyword">return</span>;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">lock_a</span><span class="params">(lhs.m, <span class="built_in">std</span>::defer_lock)</span></span>;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">lock_b</span><span class="params">(rhs.m, <span class="built_in">std</span>::defer_lock)</span></span>;</span><br><span class="line">    <span class="built_in">std</span>::lock(lock_a, lock_b);</span><br><span class="line">    swap(lhs.some_detail, rhs.some_detail);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>std::unique_lock</code> 可以不拥有mutex（传入 <code>std::defer_lock</code> 参数），只在需要的时候请求对指定的mutex上锁。</p><p>如果 <code>std::unique_lock</code> 拥有mutex，那么析构时unlock，否则，析构时一定不unlock。</p><p><code>std::unique_lock</code> 对mutex的拥有权可以用过 <code>.owns_lock()</code> 来查询。</p><p><code>std::unique_lock</code> 是典型的可movable不可copyable的类，可以灵活使用它的move semantics来转移mutex的所有权，范例如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">get_lock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">extern</span> <span class="built_in">std</span>::mutex some_mutex;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">lk</span><span class="params">(some_mutex)</span></span>;</span><br><span class="line">    prepare_data();</span><br><span class="line">    <span class="keyword">return</span> lk;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">process_data</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">lk</span><span class="params">(get_lock())</span></span>;</span><br><span class="line">    do_something();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>std::unique_lock</code> 支持灵活地lock与unlock操作，例如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">get_and_process_data</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">my_lock</span><span class="params">(the_mutex)</span></span>;</span><br><span class="line">    some_class data_to_process = get_next_data_chunk();</span><br><span class="line">    my_lock.unlock();</span><br><span class="line">    result_type result = process(data_to_process);</span><br><span class="line">    my_lock.lock();</span><br><span class="line">    write_result(data_to_process, result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="选择合适的锁粒度"><a href="#选择合适的锁粒度" class="headerlink" title="选择合适的锁粒度"></a>选择合适的锁粒度</h1><p>锁的粒度取决于两个因素：</p><ol><li>上锁的时间长短</li><li>对哪些操作上锁</li></ol><p>一般来说，最佳的上锁时长 = 完成指定操作的最小时长。</p><p>另外，应该尽可能避免在已经上锁的情况下进行文件IO或者请求另一个锁（耗时过长）；上锁时长必须覆盖整个操作过程，否则就会产生race condition。</p><h1 id="其他保护数据的机制"><a href="#其他保护数据的机制" class="headerlink" title="其他保护数据的机制"></a>其他保护数据的机制</h1><h2 id="线程安全的对象初始化"><a href="#线程安全的对象初始化" class="headerlink" title="线程安全的对象初始化"></a>线程安全的对象初始化</h2><p>有些对象的初始化操作开销很大，需要耗费很长时间，比如数据库的connection初始化。针对这类对象，我们可以把它们设置成lazy initialization的，不需要的时候（离线访问本地缓存）只要维护一个空的 <code>std::shared_ptr&lt;&gt;</code> 指针，需要的时候（连接远程数据库同步）再给它 <code>new</code> 一个新的对象。</p><p>但在多线程编程中，麻烦就来了：</p><ul><li>对象可能还没初始化、也可能正在初始化过程中、也可能刚刚初始化完毕，而其他线程并不知道，</li><li>如果多个线程对同一个指针执行 <code>new</code> 操作，就可能出现 <strong>data race</strong> （undefined behavior），</li><li>如果要把“对象是否已经被初始化or正在被初始化”这个flag信息在多个线程之间同步，就要引入一个线程安全的bool变量，</li></ul><p>C++ 标准考虑到了这一麻烦之处，并提供了 <code>std::once_flag</code> 和 <code>std::call_once</code> 来实现线程安全的对象初始化。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;some_resource&gt; resource_ptr;</span><br><span class="line"><span class="built_in">std</span>::once_flag resource_flag;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init_resource</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    resource_ptr.reset(<span class="keyword">new</span> some_resource);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::call_once(resource_flag, init_resource);</span><br><span class="line">    resource_ptr-&gt;do_something();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="线程安全的局部静态变量初始化"><a href="#线程安全的局部静态变量初始化" class="headerlink" title="线程安全的局部静态变量初始化"></a>线程安全的局部静态变量初始化</h2><p>局部的static类型变量在C/C++语言中是很有意思的存在，当程序第一次执行到变量声明代码时，该变量即被创建，此后一直不销毁。</p><p>但在多线程编程中，这一特性也引来一个棘手之处：如果多个线程并发执行，怎么保证局部static类型变量只被初始化一次？</p><p>许多古老的C++编译器在这一点上都束手无策，幸好，<strong>C++11强制保证了local static variable的初始化是线程安全的</strong> ，当第一个线程开始初始化时，其他线程自动hang住等待，并且保证只会初始化一次。</p><h2 id="共享锁和排它锁"><a href="#共享锁和排它锁" class="headerlink" title="共享锁和排它锁"></a>共享锁和排它锁</h2><p>对象的读和写频率并不一定是相等的，针对读多写少的对象，我们完全可以允许多个线程对它进行并发地“读“，而只允许一个线程对它进行“写”（此时不允许其他线程读or写）。不难看出，这种情况下读写操作的权重是不一样的，我们需要用两种不同的锁来限制并发读写的权限。</p><p>这里就引入了“共享锁”（shared lock）和“排它锁”（exclusive lock）的概念（数据库中第一次学到）：</p><ul><li>如果任何线程持有共享锁，其他线程对排它锁的请求被阻塞，直到所有的共享锁被释放，</li><li>如果任何线程有排它锁，其他线程就不能再请求排它锁or共享锁，直到排它锁被释放，</li></ul><p>C++ STL暂时还没有共享锁的实现，但可以使用boost库中的 <code>boost::shared_lock&lt;boost::shared_mutex&gt;</code>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;boost/thread/shared_mutex.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">dns_entry</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">dns_cache</span> &#123;</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">map</span>&lt;<span class="built_in">std</span>::<span class="built_in">string</span>, dns_entry&gt; entries;</span><br><span class="line">    <span class="keyword">mutable</span> boost::shared_mutex entry_mutex;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">dns_entry <span class="title">find_entry</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">string</span> <span class="keyword">const</span> &amp;domain)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">        <span class="function">boost::shared_lock&lt;boost::shared_mutex&gt; <span class="title">lk</span><span class="params">(entry_mutex)</span></span>;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">map</span>&lt;<span class="built_in">std</span>::<span class="built_in">string</span>, dns_entry&gt;::const_iterator <span class="keyword">const</span> it = entries.find(domain);</span><br><span class="line">        <span class="keyword">return</span> (it == entries.end()) ? dns_entry(): it-&gt;second;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">update_or_add_entry</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">string</span> <span class="keyword">const</span> &amp;domain, dns_entry <span class="keyword">const</span> &amp;dns_details)</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="built_in">std</span>::lock_guard&lt;boost::shared_mutex&gt; <span class="title">lk</span><span class="params">(entry_mutex)</span></span>;</span><br><span class="line">        entries[domain] = dns_details;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>在以上代码中，</p><ul><li><code>boost::shared_lock&lt;boost::shared_mutex&gt;</code> 实现了对共享锁的加锁，</li><li><code>std::lock_guard&lt;boost::shared_mutex&gt;</code> 实现了对排它锁的加锁。</li></ul><h2 id="可重入的mutex"><a href="#可重入的mutex" class="headerlink" title="可重入的mutex"></a>可重入的mutex</h2><p>C++ STL提供了 <code>std::recursive_mutex</code> ，支持一个线程对它上n次锁，但该线程必须释放n次锁后，其他线程才能对它上锁。</p><p>尽可能不要使用可重入的mutex，这是一种糟糕的设计。</p><h1 id="总结与思考：关于lock-guard和unique-lock"><a href="#总结与思考：关于lock-guard和unique-lock" class="headerlink" title="总结与思考：关于lock_guard和unique_lock"></a>总结与思考：关于lock_guard和unique_lock</h1><p>为了厘清一些叙述上的模糊，有必要再把一些概念拎出来说清楚，以下是我自己的理解。</p><p><strong>为什么要使用它们？</strong></p><p>mutex提供了lock和unlock的操作，程序员的确可以直接对mutex加锁，但是在复杂代码中，unlock操作需要考虑很多情况（异常处理等），使用lock_guard和unique_lock将unlock的控制权交给了析构函数，解放了程序员。</p><p><strong>它们如何与某个mutex绑定？</strong></p><p>lock_guard和unique_lock在初始化时，就与参数中传入的mutex相互绑定（associated）。</p><p><strong>它们如何获得某个mutex的所有权？</strong></p><ul><li><p>对lock_guard来说，在初始化时就获得了mutex的所有权；</p></li><li><p>对unique_lock来说，</p><ul><li>如果初始化时不传入其他参数，即获得mutex的所有权，</li><li>如果初始化时传入 <code>std::defer_lock</code> ，那么只相互绑定，不获取所有权，</li></ul></li></ul><p><strong>它们如何对绑定的mutex加锁？</strong></p><ul><li>对lock_guard来说，有两种加锁方式，<ul><li>先使用 <code>std::lock()</code> 或其他方式加锁，然后初始化lock_guard对象，并传入额外参数 <code>std::adopt_lock</code> 表示只获取所有权，不重复加锁，</li><li>在初始化时不传入额外参数，直接绑定+获取所有权+加锁，</li></ul></li><li>对unique_lock来说，也有两种加锁方式，<ul><li>在初始化时不传入额外参数，直接绑定+获取所有权+加锁，</li><li>在初始化时传入额外参数 <code>std::defer_lock</code> ，表示只相互绑定，不获取所有权，不加锁，之后再使用 <code>std::lock()</code> 或者 <code>.lock()</code> 方法进行加锁（加锁的同时也获得了所有权），</li></ul></li></ul><p><strong>它们如何对绑定的mutex解锁？</strong></p><ul><li>对lock_guard来说，析构时自动对拥有的mutex解锁，</li><li>对unique_lock来说，<ul><li>析构时，如果unique_lock拥有mutex的所有权，那么自动解锁，</li><li>析构时，如果unique_lock不拥有mutex的所有权，那么不解锁，</li><li>程序员可以手动对已经上锁的unique_lock调用 <code>.unlock()</code> ，调用完后解锁+丧失所有权。</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h1&gt;&lt;p&gt;多线程编程的优势之一在于线程间共享数据的开销很小。&lt;/p&gt;
&lt;p&gt;“灵活地在线程间共享数据，最大化地利用并发处理优势“，听起来很美好，实际上处处是坑。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Reading Notes" scheme="http://xinlu.cool/categories/Reading-Notes/"/>
    
    
      <category term="C++" scheme="http://xinlu.cool/tags/C/"/>
    
      <category term="Concurrency" scheme="http://xinlu.cool/tags/Concurrency/"/>
    
      <category term="C++ Concurrency in Action" scheme="http://xinlu.cool/tags/C-Concurrency-in-Action/"/>
    
  </entry>
  
  <entry>
    <title>调包侠工具箱：tf.data.Dataset</title>
    <link href="http://xinlu.cool/API-References/tf-data-Dataset/"/>
    <id>http://xinlu.cool/API-References/tf-data-Dataset/</id>
    <published>2020-06-29T07:36:29.000Z</published>
    <updated>2021-03-24T05:55:53.530Z</updated>
    
    <content type="html"><![CDATA[<h2 id="这是个啥？"><a href="#这是个啥？" class="headerlink" title="这是个啥？"></a>这是个啥？</h2><ul><li>tf.data.Dataset包含数据集导入、预处理、导出的高级api</li><li>适用于数据量可以分批导入内存的场景</li><li>可以通过简单的api实现流水线处理</li><li><strong>这货本质是个封装程度非常高的IO Adapter</strong></li></ul><a id="more"></a><h2 id="Dataset创建"><a href="#Dataset创建" class="headerlink" title="Dataset创建"></a>Dataset创建</h2><h3 id="与导入操作有关的api"><a href="#与导入操作有关的api" class="headerlink" title="与导入操作有关的api"></a>与导入操作有关的api</h3><ul><li>从<code>python list</code>导入</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset = tf.data.Dataset.from_tensor_slices([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><ul><li>从<code>txt</code>文件导入</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dataset = tf.data.TextLineDataset([</span><br><span class="line">  <span class="string">&quot;file1.txt&quot;</span>, </span><br><span class="line">  <span class="string">&quot;file2.txt&quot;</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure><ul><li>从<code>TFRecord</code>导入</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dataset = tf.data.TFRecordDataset([</span><br><span class="line">    <span class="string">&quot;file1.tfrecords&quot;</span>, </span><br><span class="line">    <span class="string">&quot;file2.tfrecords&quot;</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure><ul><li>从多文件导入（正则表达式）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset = tf.data.Dataset.list_files(<span class="string">&quot;/path/*.txt&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li>其他导入方式<ul><li><code>tf.data.FixedLengthRecordDataset</code></li><li><code>tf.data.Dataset.from_generator</code></li></ul></li></ul><h3 id="一些优雅的导入姿势"><a href="#一些优雅的导入姿势" class="headerlink" title="一些优雅的导入姿势"></a>一些优雅的导入姿势</h3><ul><li>导入一个tuple</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Slicing a tuple of 1D tensors produces tuple elements containing scalar tensors.</span></span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices((</span><br><span class="line">  [<span class="number">1</span>, <span class="number">2</span>], </span><br><span class="line">  [<span class="number">3</span>, <span class="number">4</span>], </span><br><span class="line">  [<span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">))</span><br><span class="line"><span class="built_in">list</span>(dataset.as_numpy_iterator())</span><br><span class="line"><span class="comment"># [(1, 3, 5), (2, 4, 6)]</span></span><br></pre></td></tr></table></figure><ul><li>导入两个tuple</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Two tensors can be combined into one Dataset object.</span></span><br><span class="line">features = tf.constant([[<span class="number">1</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">1</span>], [<span class="number">3</span>, <span class="number">3</span>]]) <span class="comment"># ==&gt; 3x2 tensor</span></span><br><span class="line">labels = tf.constant([<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;A&#x27;</span>]) <span class="comment"># ==&gt; 3x1 tensor</span></span><br><span class="line">dataset = Dataset.from_tensor_slices((features, labels))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Both the features and the labels tensors can be converted</span></span><br><span class="line"><span class="comment"># to a Dataset object separately and combined after.</span></span><br><span class="line">features_dataset = Dataset.from_tensor_slices(features)</span><br><span class="line">labels_dataset = Dataset.from_tensor_slices(labels)</span><br><span class="line">dataset = Dataset.<span class="built_in">zip</span>((features_dataset, labels_dataset))</span><br></pre></td></tr></table></figure><h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><h3 id="Dataset级别的api"><a href="#Dataset级别的api" class="headerlink" title="Dataset级别的api"></a>Dataset级别的api</h3><ul><li><p><code>.apply()</code></p><ul><li><p>Args:</p><ul><li>transformation func, from Dataset to Dataset</li></ul></li><li><p>Rets:</p><ul><li>a new Dataset</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dataset_fn</span>(<span class="params">ds</span>):</span></span><br><span class="line">  <span class="keyword">return</span> ds.<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x &lt; <span class="number">5</span>)</span><br><span class="line">dataset = dataset.apply(dataset_fn)</span><br></pre></td></tr></table></figure><ul><li><code>.batch()</code><ul><li>Args:<ul><li>batch_size</li><li>drop_remainder=False</li></ul></li><li>新Dataset输出的数据新增一个维度，大小为batch_size</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset = dataset.batch(<span class="number">3</span>, drop_remainder=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><ul><li><code>.shard()</code><ul><li>Args:<ul><li>num_shards</li><li>index</li></ul></li><li>Rets:<ul><li>一个新的Dataset，只包含原Dataset的<code>1/num_shards</code>数据，而且数据在原Dataset中的下标<code>% num_shards = index</code></li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset_B = dataset_A.shard(num_shards=<span class="number">3</span>, index=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><ul><li><code>.concatenate()</code><ul><li>Args:<ul><li>another Dataset</li></ul></li><li>Rets:<ul><li>a new Dataset</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">4</span>)  <span class="comment"># ==&gt; [ 1, 2, 3 ]</span></span><br><span class="line">b = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">4</span>, <span class="number">8</span>)  <span class="comment"># ==&gt; [ 4, 5, 6, 7 ]</span></span><br><span class="line">ds = a.concatenate(b)</span><br><span class="line"><span class="comment"># ==&gt; [ 1, 2, 3, 4, 5, 6, 7 ]</span></span><br></pre></td></tr></table></figure><ul><li><code>Dataset.zip()</code><ul><li>Args:<ul><li>(Dataset, Dataset, …)</li></ul></li><li>Rets:<ul><li>a new Dataset</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">4</span>)  <span class="comment"># ==&gt; [ 1, 2, 3 ]</span></span><br><span class="line">b = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">4</span>, <span class="number">7</span>)  <span class="comment"># ==&gt; [ 4, 5, 6 ]</span></span><br><span class="line">ds = tf.data.Dataset.<span class="built_in">zip</span>((a, b))</span><br><span class="line"><span class="comment"># ==&gt; [(1, 4), (2, 5), (3, 6)]</span></span><br></pre></td></tr></table></figure><h3 id="字段级别的api"><a href="#字段级别的api" class="headerlink" title="字段级别的api"></a>字段级别的api</h3><ul><li><code>.filter()</code><ul><li>Args:<ul><li>predicate(func)</li></ul></li><li>Rets:<ul><li>a new Dataset, element by predicate is True</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset = dataset.<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x &lt; <span class="number">3</span>)</span><br></pre></td></tr></table></figure><ul><li><code>.map()</code><ul><li>Args:<ul><li>map_func</li><li>num_parallel_calls(=<code>tf.data.experimental.AUTOTUNE</code>)</li><li>deterministic</li></ul></li><li>Rets:<ul><li>a new Dataset</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset = Dataset.<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>)  <span class="comment"># ==&gt; [ 1, 2, 3, 4, 5 ]</span></span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x + <span class="number">1</span>)</span><br></pre></td></tr></table></figure><ul><li><code>interleave()</code><ul><li>Args:<ul><li>map_func</li><li>cycle_length=AUTOTUNE</li><li>block_length=1</li><li>num_parallel_calls(=<code>tf.data.experimental.AUTOTUNE</code>)</li><li>deterministic=None</li></ul></li><li>Rets:<ul><li>a new Dataset</li></ul></li></ul></li></ul><p>如何理解：</p><ol><li>遍历原Dataset，用<code>map_func</code>函数处理每个字段，该过程并行度由<code>cycle_length</code>控制</li></ol><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设cycle_length = 3</span></span><br><span class="line">[map_func(x1), map_func(x2), map_func(x3)] </span><br><span class="line">  =&gt; [res1, res2, res3] </span><br><span class="line">  =&gt; cycle1</span><br><span class="line"></span><br><span class="line">[map_func(x4), map_func(x5), map_func(x6)] </span><br><span class="line">  =&gt; [res4, res5, res6] </span><br><span class="line">  =&gt; cycle2</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">==&gt; cycles = [cycle1, cycle2, cycle3, ...]</span><br></pre></td></tr></table></figure><ol><li>遍历cycles，取每个cycle的<code>block_length</code>个元素后，换下一个cycle继续读取，环形遍历直到所有元素都被取出</li></ol><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设block_length = 2</span></span><br><span class="line"></span><br><span class="line">cycle1 =&gt; [res1, res2]</span><br><span class="line">cycle2 =&gt; [res4, res5]</span><br><span class="line"></span><br><span class="line">cycle1 =&gt; [res3]</span><br><span class="line">cycle2 =&gt; [res6]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终结果被flatten</span></span><br><span class="line">==&gt; [res1, res2, res4, res5, res3, res6]</span><br></pre></td></tr></table></figure><ol><li>最终获得flatten后的新Dataset</li></ol><h2 id="Dataset导出"><a href="#Dataset导出" class="headerlink" title="Dataset导出"></a>Dataset导出</h2><ul><li><code>.prefetch()</code><ul><li>Args:<ul><li>buffer_size</li></ul></li><li>Rets:<ul><li>a new Dataset</li></ul></li></ul></li></ul><p>官方建议在所有Dataset的处理结束后加上<code>.prefetch()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预取两个字段</span></span><br><span class="line">dataset = dataset.prefetch(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预取两个batch</span></span><br><span class="line">dataset = dataset.batch(<span class="number">20</span>).prefetch(<span class="number">2</span>)</span><br></pre></td></tr></table></figure><ul><li><code>.shuffle()</code><ul><li>Args:<ul><li>buffer_size</li><li>seed=None</li><li>reshuffle_each_iteration=None</li></ul></li><li>Rets:<ul><li>a new Dataset</li></ul></li></ul></li></ul><p>官方建议<code>buffer_size</code> &gt;= Dataset数据量</p><ul><li><code>.enumerate()</code><ul><li>Args:<ul><li>start=0</li></ul></li><li>Rets:<ul><li>a new Dataset，每个输出结果多了一个表示索引的维度</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">dataset = tf.data.Dataset.from_tensor_slices([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">dataset = dataset.<span class="built_in">enumerate</span>(start=<span class="number">5</span>)</span><br><span class="line"><span class="keyword">for</span> element <span class="keyword">in</span> dataset.as_numpy_iterator():</span><br><span class="line">  print(element)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(5, 1)</span></span><br><span class="line"><span class="string">(6, 2)</span></span><br><span class="line"><span class="string">(7, 3)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><ul><li><code>.as_numpy_iterator()</code><ul><li>Rets:<ul><li>a new Dataset</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dataset = tf.data.Dataset.from_tensor_slices([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="keyword">for</span> element <span class="keyword">in</span> dataset.as_numpy_iterator():</span><br><span class="line">  print(element)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">1</span></span><br><span class="line"><span class="string">2</span></span><br><span class="line"><span class="string">3</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;这是个啥？&quot;&gt;&lt;a href=&quot;#这是个啥？&quot; class=&quot;headerlink&quot; title=&quot;这是个啥？&quot;&gt;&lt;/a&gt;这是个啥？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;tf.data.Dataset包含数据集导入、预处理、导出的高级api&lt;/li&gt;
&lt;li&gt;适用于数据量可以分批导入内存的场景&lt;/li&gt;
&lt;li&gt;可以通过简单的api实现流水线处理&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;这货本质是个封装程度非常高的IO Adapter&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="API References" scheme="http://xinlu.cool/categories/API-References/"/>
    
    
      <category term="Machine Learning" scheme="http://xinlu.cool/tags/Machine-Learning/"/>
    
      <category term="TensorFlow" scheme="http://xinlu.cool/tags/TensorFlow/"/>
    
      <category term="Keras" scheme="http://xinlu.cool/tags/Keras/"/>
    
  </entry>
  
  <entry>
    <title>C++并发：从std::thread()开始</title>
    <link href="http://xinlu.cool/Reading-Notes/cppconcurrency-1/"/>
    <id>http://xinlu.cool/Reading-Notes/cppconcurrency-1/</id>
    <published>2020-06-19T20:43:36.000Z</published>
    <updated>2020-06-30T16:48:23.501Z</updated>
    
    <content type="html"><![CDATA[<h2 id="lt-thread-gt-头文件的作用"><a href="#lt-thread-gt-头文件的作用" class="headerlink" title="&lt;thread&gt;头文件的作用"></a><code>&lt;thread&gt;</code>头文件的作用</h2><p><code>&lt;thread&gt;</code>  是C++11新引入标准库基础设施，提供对多线程操作的支持。</p><p>我们可以用 <code>std::thread</code> 来控制线程的创建、运行、回收。</p><p>学习 <code>std::thread</code> 的用法是了解C++多线程编程的第一步。</p><a id="more"></a><h2 id="构造std-thread对象"><a href="#构造std-thread对象" class="headerlink" title="构造std::thread对象"></a>构造<code>std::thread</code>对象</h2><ul><li>方法一：传入函数对象</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">background_task</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">        do_something();</span><br><span class="line">        do_something_else();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">background_task f;</span><br><span class="line"><span class="function"><span class="built_in">std</span>::thread <span class="title">my_thread</span><span class="params">(f)</span></span>;</span><br></pre></td></tr></table></figure><p><strong>在这种情况下，函数对象先被 <code>copy</code> 到 <code>std::thread</code> 对象的内部，然后再传参、被调用</strong></p><ul><li>方法二：传入lambda表达式（也是callable对象）</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="built_in">std</span>::thread <span class="title">my_thread</span><span class="params">([]&#123;</span></span></span><br><span class="line"><span class="function"><span class="params">    do_something();</span></span></span><br><span class="line"><span class="function"><span class="params">    do_something_else();</span></span></span><br><span class="line"><span class="function"><span class="params">&#125;)</span></span></span><br></pre></td></tr></table></figure><ul><li>方法三：传入函数指针和参数</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="keyword">int</span> i)</span></span>;</span><br><span class="line"><span class="built_in">std</span>::thread(f, <span class="number">3</span>);</span><br></pre></td></tr></table></figure><ul><li>方法四：传入对象的成员函数</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">X</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">do_lengthy_work</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">X my_x;</span><br><span class="line"><span class="function"><span class="built_in">std</span>::thread <span class="title">t</span><span class="params">(&amp;X::do_lengthy_work, &amp;my_x)</span></span>;<span class="comment">// 后面可以加上一系列参数，如果需要的话</span></span><br></pre></td></tr></table></figure><h2 id="std-thread成员函数"><a href="#std-thread成员函数" class="headerlink" title="std::thread成员函数"></a><code>std::thread</code>成员函数</h2><h3 id="join"><a href="#join" class="headerlink" title=".join()"></a><code>.join()</code></h3><p><strong>作用：</strong></p><ul><li>等待线程执行完毕</li><li>清除对象内部与具体线程相关的内存，当前对象将不再和任何线程相关联</li><li>只能调用一次 <code>.join()</code> ，调用后 <code>.joinable()</code> 将永远返回 <code>false</code></li></ul><p><strong>例子：</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (t.joinable()) &#123;</span><br><span class="line">    t.join();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="detach"><a href="#detach" class="headerlink" title=".detach()"></a><code>.detach()</code></h3><p><strong>作用：</strong></p><ul><li>把线程放在后台运行，线程的所有权和控制权交给 <code>C++ Runtime Library</code></li><li>当前对象将不再和任何线程相关联</li><li>调用后 <code>.joinable()</code> 将永远返回 <code>false</code></li></ul><h2 id="thread-function传参可能遇到的问题"><a href="#thread-function传参可能遇到的问题" class="headerlink" title="thread function传参可能遇到的问题"></a>thread function传参可能遇到的问题</h2><h3 id="问题一：传入临时的callable对象，编译器会误以为是函数声明"><a href="#问题一：传入临时的callable对象，编译器会误以为是函数声明" class="headerlink" title="问题一：传入临时的callable对象，编译器会误以为是函数声明"></a>问题一：传入临时的callable对象，编译器会误以为是函数声明</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Wrong</span></span><br><span class="line"><span class="function"><span class="built_in">std</span>::thread <span class="title">my_thread</span><span class="params">(background_task())</span></span></span><br></pre></td></tr></table></figure><p><strong>解决方案：</strong>用圆括号或者花括号加以说明</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Correct</span></span><br><span class="line"><span class="function"><span class="built_in">std</span>::thread <span class="title">my_thread</span><span class="params">((background_task()))</span></span>;</span><br><span class="line"><span class="built_in">std</span>::thread my_thread&#123;background_task()&#125;;</span><br></pre></td></tr></table></figure><h3 id="问题二：因为传指针or局部变量的引用，导致thread-function可能访问已经被销毁的内容"><a href="#问题二：因为传指针or局部变量的引用，导致thread-function可能访问已经被销毁的内容" class="headerlink" title="问题二：因为传指针or局部变量的引用，导致thread function可能访问已经被销毁的内容"></a>问题二：因为传指针or局部变量的引用，导致thread function可能访问已经被销毁的内容</h3><p><strong>解决方案：</strong></p><ul><li>把需要使用的临时变量<code>copy</code>到<code>std::thread</code>内部，不要和局部上下文共享临时变量</li><li>使用<code>RAII</code>（资源获取即初始化）</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">thread_guard</span> &#123;</span></span><br><span class="line">    <span class="built_in">std</span>::thread &amp;t;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// Constructor</span></span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">thread_guard</span><span class="params">(<span class="built_in">std</span>::thread &amp;t_)</span>: <span class="title">t</span><span class="params">(t_)</span> </span>&#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Destructor</span></span><br><span class="line">    ~thread_guard() &#123;</span><br><span class="line">        <span class="keyword">if</span> (t.joinable()) &#123;</span><br><span class="line">            t.join();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Copy Constructor</span></span><br><span class="line">    thread_guard(<span class="keyword">const</span> thread_guard &amp;) = <span class="keyword">delete</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Copy-assignment Operator</span></span><br><span class="line">    thread_guard&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> thread_guard &amp;) = <span class="keyword">delete</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">func</span>;</span> <span class="comment">// a callable object</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> f &#123;</span><br><span class="line">    <span class="keyword">int</span> some_local_stats = <span class="number">0</span>;</span><br><span class="line">    <span class="function">func <span class="title">my_func</span><span class="params">(some_local_stats)</span></span>;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::thread <span class="title">t</span><span class="params">(my_func)</span></span>;</span><br><span class="line">    <span class="function">thread_guard <span class="title">g</span><span class="params">(t)</span></span>;</span><br><span class="line">    </span><br><span class="line">    do_something_in_current_thread();<span class="comment">// 函数返回时，自动调用thread_guard的析构函数，等待线程join</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="问题三：因为传指针or局部变量的引用，导致在thread-function入参时因强制类型转换而访问已经被销毁的内容"><a href="#问题三：因为传指针or局部变量的引用，导致在thread-function入参时因强制类型转换而访问已经被销毁的内容" class="headerlink" title="问题三：因为传指针or局部变量的引用，导致在thread function入参时因强制类型转换而访问已经被销毁的内容"></a>问题三：因为传指针or局部变量的引用，导致在thread function入参时因强制类型转换而访问已经被销毁的内容</h3><p>理解这个问题之前，需要先梳理一下 <code>std::thread</code> 对象创建后发生了什么：</p><ol><li>原线程：调用 <code>std::thread</code> 的构造函数or拷贝赋值运算符</li><li>原线程：一个callable对象和它的参数被拷贝到新创建的 <code>std::thread</code> 内部</li><li>新线程：之前被拷贝的一系列参数，现在被传入callable对象（发生强制类型转换）</li><li>新线程：调用callable对象</li><li>……</li></ol><p>其中，第3步发生在新线程内，我们只知道它发生在第2步之后，却不知道具体的发生时间。</p><p>如果第3步发生时，原线程已经退出了相关上下文，那么新线程在传参时，可能对已经被销毁的内容进行类型转换操作。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span> &amp;s)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">oops</span><span class="params">(<span class="keyword">int</span> some_param)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> buffer[<span class="number">1024</span>];</span><br><span class="line">    <span class="built_in">sprintf</span>(buffer, <span class="string">&quot;%i&quot;</span>, some_param);</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::thread <span class="title">t</span><span class="params">(f, <span class="number">3</span>, buffer)</span></span>;<span class="comment">// const char*类型的buffer被转换成std::string的时机是未知的</span></span><br><span class="line">    t.detach();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>解决方案：</strong>由程序员显式完成传参操作，避免出现类型转换</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">not_oops</span><span class="params">(<span class="keyword">int</span> some_param)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> buffer[<span class="number">1024</span>];</span><br><span class="line">    <span class="built_in">sprintf</span>(buffer, <span class="string">&quot;%i&quot;</span>, some_param);</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::thread <span class="title">t</span><span class="params">(f, <span class="number">3</span>, <span class="built_in">std</span>::<span class="built_in">string</span>(buffer))</span></span>;<span class="comment">// 避免类型转换</span></span><br><span class="line">    t.detach();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="问题四：callable对象的参数要求传引用，但实际传入的是内部拷贝对象的引用（无法对原来的对象进行修改）"><a href="#问题四：callable对象的参数要求传引用，但实际传入的是内部拷贝对象的引用（无法对原来的对象进行修改）" class="headerlink" title="问题四：callable对象的参数要求传引用，但实际传入的是内部拷贝对象的引用（无法对原来的对象进行修改）"></a>问题四：callable对象的参数要求传引用，但实际传入的是内部拷贝对象的引用（无法对原来的对象进行修改）</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">update_data_for_widget</span><span class="params">(widget_id w, widget_data &amp;data)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">oops_again</span><span class="params">(widget_id w)</span> </span>&#123;</span><br><span class="line">    widget_data data;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::thread <span class="title">t</span><span class="params">(update_data_for_widget, w, data)</span></span>;<span class="comment">// 传入的data被拷贝，拷贝后的临时data的引用被传入update函数</span></span><br><span class="line">    display_status();</span><br><span class="line">    t.join();</span><br><span class="line">    process_widget_data(data);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>解决方案：</strong>使用 <code>std::ref()</code> 声明传引用</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="built_in">std</span>::thread <span class="title">t</span><span class="params">(update_data_for_widget, w, <span class="built_in">std</span>::ref(data))</span></span>;</span><br></pre></td></tr></table></figure><h2 id="使用上的技巧"><a href="#使用上的技巧" class="headerlink" title="使用上的技巧"></a>使用上的技巧</h2><h3 id="Trick-1：传入只可move不可copy的对象"><a href="#Trick-1：传入只可move不可copy的对象" class="headerlink" title="Trick 1：传入只可move不可copy的对象"></a>Trick 1：传入只可move不可copy的对象</h3><p>在这种情况下，如果原对象是无名的临时对象，那么 <code>move</code> 操作是自动完成的。</p><p>如果原对象是命名对象（左值引用），那就需要用 <code>std::move()</code> 来将它转换成（右值引用），之后的的拷贝就自动是 <code>move</code> 完成的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">process_big_object</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;big_object&gt;)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;big_object&gt; <span class="title">p</span><span class="params">(<span class="keyword">new</span> big_object)</span></span>;<span class="comment">// std::unique_ptr是典型的不可copy只能move对象，std::thread也是</span></span><br><span class="line">p-&gt;prepare_data(<span class="number">42</span>);</span><br><span class="line"><span class="function"><span class="built_in">std</span>::thread <span class="title">t</span><span class="params">(process_big_object, <span class="built_in">std</span>::move(p))</span></span>;</span><br></pre></td></tr></table></figure><h3 id="Trick-2：std-thread的move操作"><a href="#Trick-2：std-thread的move操作" class="headerlink" title="Trick 2：std::thread的move操作"></a>Trick 2：<code>std::thread</code>的move操作</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">some_function</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">some_other_function</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="built_in">std</span>::thread <span class="title">t1</span><span class="params">(some_function)</span></span>;<span class="comment">// constructor</span></span><br><span class="line"><span class="built_in">std</span>::thread t2 = <span class="built_in">std</span>::move(t1);<span class="comment">// move-assignment operator</span></span><br><span class="line">t1 = <span class="built_in">std</span>::thread(some_other_function);<span class="comment">// constructor, then move-assignment operator</span></span><br><span class="line"><span class="built_in">std</span>::thread t3;<span class="comment">// default constructor</span></span><br><span class="line">t3 = <span class="built_in">std</span>::move(t2);<span class="comment">// move-assignment operator</span></span><br><span class="line">t1 = <span class="built_in">std</span>::move(t3);<span class="comment">// Error: std::terminate()</span></span><br></pre></td></tr></table></figure><p>上述程序的最后一行中，对象t1已经与一个正在运行的线程互相绑定，不能接受<code>move</code>的对象，因此整个程序会调用 <code>std::terminate()</code> 退出。</p><p>不能 <code>move</code> 给已经绑定了线程的对象。</p><h3 id="Trick-3：在函数传参和返回时使用转移std-thread的所有权"><a href="#Trick-3：在函数传参和返回时使用转移std-thread的所有权" class="headerlink" title="Trick 3：在函数传参和返回时使用转移std::thread的所有权"></a>Trick 3：在函数传参和返回时使用转移<code>std::thread</code>的所有权</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="built_in">std</span>::thread <span class="title">f</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">some_function</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">std</span>::thread(some_function);<span class="comment">// 自动调用move</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="built_in">std</span>::thread <span class="title">g</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">some_other_function</span><span class="params">(<span class="keyword">int</span>)</span></span>;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::thread <span class="title">t</span><span class="params">(some_other_function, <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="keyword">return</span> t;<span class="comment">// 自动调用move</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="built_in">std</span>::thread t)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">g</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">some_function</span><span class="params">()</span></span>;</span><br><span class="line">    f(<span class="built_in">std</span>::thread(some_function));<span class="comment">// 自动调用move</span></span><br><span class="line">    <span class="function"><span class="built_in">std</span>::thread <span class="title">t</span><span class="params">(some_function)</span></span>;</span><br><span class="line">    f(<span class="built_in">std</span>::move(t));<span class="comment">// 显式调用move</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Trick-4：运行时确定新开线程的个数"><a href="#Trick-4：运行时确定新开线程的个数" class="headerlink" title="Trick 4：运行时确定新开线程的个数"></a>Trick 4：运行时确定新开线程的个数</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">long</span> hardware_threads = <span class="built_in">std</span>::thread::hardware_concurrency();</span><br></pre></td></tr></table></figure><h3 id="Trick-5：获取线程id"><a href="#Trick-5：获取线程id" class="headerlink" title="Trick 5：获取线程id"></a>Trick 5：获取线程id</h3><p>线程id有个单独定义的类型，<code>std::thread::id</code> ，该类对象有如下性质：</p><ul><li>调用 <code>std::thread</code> 对象的 <code>get_id()</code> 方法可以得到一个 <code>std::thread::id</code> 类型对象</li><li><code>std::thread::id</code> 支持大小比较和相等判断，<ul><li>相等即为同一线程</li><li>若a&lt;b，b&lt;c，那么a&lt;c</li></ul></li><li>如果当前对象不与任何正在运行的线程绑定，那么 <code>get_id()</code> 返回一个默认构造的 <code>std::thread::id</code> 对象</li><li><code>get_id()</code> 可以被 <code>std::cout</code> 打印出来，但它的值没有任何具体意义，标准库也不对它的具体实现类型作保证</li></ul><h2 id="参考来源"><a href="#参考来源" class="headerlink" title="参考来源"></a>参考来源</h2><ul><li>C++ Concurrency in Action, 2nd Edition</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;lt-thread-gt-头文件的作用&quot;&gt;&lt;a href=&quot;#lt-thread-gt-头文件的作用&quot; class=&quot;headerlink&quot; title=&quot;&amp;lt;thread&amp;gt;头文件的作用&quot;&gt;&lt;/a&gt;&lt;code&gt;&amp;lt;thread&amp;gt;&lt;/code&gt;头文件的作用&lt;/h2&gt;&lt;p&gt;&lt;code&gt;&amp;lt;thread&amp;gt;&lt;/code&gt;  是C++11新引入标准库基础设施，提供对多线程操作的支持。&lt;/p&gt;
&lt;p&gt;我们可以用 &lt;code&gt;std::thread&lt;/code&gt; 来控制线程的创建、运行、回收。&lt;/p&gt;
&lt;p&gt;学习 &lt;code&gt;std::thread&lt;/code&gt; 的用法是了解C++多线程编程的第一步。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Reading Notes" scheme="http://xinlu.cool/categories/Reading-Notes/"/>
    
    
      <category term="C++" scheme="http://xinlu.cool/tags/C/"/>
    
      <category term="Concurrency" scheme="http://xinlu.cool/tags/Concurrency/"/>
    
      <category term="C++ Concurrency in Action" scheme="http://xinlu.cool/tags/C-Concurrency-in-Action/"/>
    
  </entry>
  
</feed>
